<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://davidzhao1015.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://davidzhao1015.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-10-24T23:18:51+00:00</updated><id>https://davidzhao1015.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Introduction to Linear Mixed Models with the limma Package</title><link href="https://davidzhao1015.github.io/blog/2024/linear-mixed-model/" rel="alternate" type="text/html" title="Introduction to Linear Mixed Models with the limma Package"/><published>2024-10-23T00:00:00+00:00</published><updated>2024-10-23T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2024/linear-mixed-model</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2024/linear-mixed-model/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>In the field of bioinformatics and genomics, understanding the variations in gene expression across different experimental conditions is crucial for interpreting biological processes. The limma package is widely recognized for its powerful capabilities in fitting linear models to gene expression data, allowing researchers to evaluate differences due to experimental conditions.</p> <p>However, many experimental designs involve repeated measurements from the same subjects, whether they are animals, human samples, or cells. These repeated measures introduce random effects, which must be accounted for to avoid biased results. Random effects occur when some variability in the data is due to differences between subjects or samples that are not directly related to the experimental conditions being studied.</p> <p>This tutorial provides a step-by-step guide on how to build linear mixed models (LMM) using the limma package to incorporate random effects. You will learn how to adjust for these random variations, ensuring more accurate and reliable conclusions about gene expression.</p> <h2 id="what-is-effect-of-repeated-measures">What is effect of repeated measures?</h2> <p>Repeated measures refer to data collected from the same subjects at multiple time points or under different conditions. These designs result in correlated observations, as repeated measures on the same individual tend to share subject-specific traits. Ignoring this correlation can lead to incorrect conclusions since traditional methods assume independence between observations.</p> <p>The use of repeated measures often reduces variability, as each subject serves as their own control, which increases the sensitivity of the analysis. This can lead to greater statistical power, enabling researchers to detect effects with fewer subjects. To handle the correlation between repeated observations, specialized methods such as Repeated Measures ANOVA, Linear Mixed Models (LMM), or Generalized Estimating Equations (GEE) are typically used.</p> <h2 id="what-can-linear-mixed-effect-model-do">What can linear mixed-effect model do?</h2> <p>A Linear Mixed-Effects Model (LMM) is used to analyze repeated measures data by accounting for both overall effects (like treatments or time) and individual differences between subjects. It helps manage the fact that repeated observations from the same person are related, and it can handle missing data or different time points for each person. This makes it a flexible tool for analyzing complex data.</p> <p>In the context of gene expression analysis, LMMs can be used to model the effects of experimental conditions (e.g., treatment groups) while accounting for individual variability and correlations between repeated measurements. By incorporating random effects, LMMs provide a more accurate representation of the underlying data structure, leading to more reliable results and improved statistical power.</p> <h1 id="prerequisites">Prerequisites</h1> <p>Before proceeding with this tutorial, you should have a basic understanding of linear models, gene expression analysis, and the R programming language. Familiarity with the limma package and its functions is recommended but not required.</p> <p>To follow along with the code examples, you will need to have R and RStudio installed on your computer. You can download R from the Comprehensive R Archive Network (CRAN) and RStudio from the RStudio website. Additionally, you will need to install the limma package, which can be done using the BiocManager package.</p> <p>The R package <code class="language-plaintext highlighter-rouge">limma</code> is used for linear models and differential expression analysis. If you havenâ€™t installed the package yet, you can do so by running the following code:</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Install the biocManager package </span><span class="w">
    </span><span class="c1"># install.packages("BiocManager") </span><span class="w">
    </span><span class="c1"># Install the limma package </span><span class="w">
    </span><span class="c1"># BiocManager::install("limma", force = TRUE)  </span><span class="w">

    </span><span class="n">library</span><span class="p">(</span><span class="n">limma</span><span class="p">)</span><span class="w"> </span><span class="c1"># For linear models and differential expression analysis </span><span class="w">
    </span><span class="n">library</span><span class="p">(</span><span class="n">ggplot2</span><span class="p">)</span><span class="w"> </span><span class="c1"># For data visualization </span><span class="w">
    </span><span class="n">library</span><span class="p">(</span><span class="n">gridExtra</span><span class="p">)</span><span class="w">
</span></code></pre></div></div> <h1 id="code-structure">Code Structure</h1> <p>This tutorial is divided into four main steps:</p> <ol> <li><strong>Simulate Example Data</strong>: We will generate example data with repeated measures to demonstrate the use of linear mixed-effect models with the limma package.</li> <li><strong>Fit Linear Models with limma</strong>: We will fit linear models to the example data using the limma package, considering different model configurations.</li> <li><strong>Evaluate the Block Effect</strong>: We will extract differentially expressed genes and visualize the coefficients and confidence intervals for the fixed effects of treatment on gene expression.</li> <li><strong>Evaluate Model Robustness</strong>: We will evaluate the assumptions of homoscedasticity and linearity by examining the residuals and checking the normality of residuals using Q-Q plots.</li> </ol> <h2 id="step-1---simulate-example-data">Step 1 - Simulate example data</h2> <p>In this step, we will simulate example data to demonstrate the use of linear mixed-effect models with the <code class="language-plaintext highlighter-rouge">limma</code> package.</p> <p>The example data will consist of gene expression data for 10 individuals per group (control and treatment groups), with 2 samples (repeative measures) per individual.</p> <p>We will simulate the following variables for each sample: 1. <code class="language-plaintext highlighter-rouge">people</code>: A numeric variable representing the individual ID 2. <code class="language-plaintext highlighter-rouge">treatment</code>: A factor variable indicating the treatment group (0 = Control, 1 = Treatment) 3. <code class="language-plaintext highlighter-rouge">gender</code>: A factor variable representing</p> <p>We will also simulate gene expression data for 5 genes, from normal distributions with different means and standard deviations for the control and treatment groups.</p> <p>The gene expression data will be combined into a single data frame, with the genes as rows and the samples as columns.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Simulate example data</span><span class="w">
    </span><span class="n">set.seed</span><span class="p">(</span><span class="m">123</span><span class="p">)</span><span class="w">

    </span><span class="c1"># Define variables</span><span class="w">
    </span><span class="n">people</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">),</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="c1"># 10 people, 2 samples per person </span><span class="w">
    </span><span class="n">treatment</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">factor</span><span class="p">(</span><span class="nf">rep</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">))</span><span class="w">  </span><span class="c1"># 0 = Control, 1 = Treatment</span><span class="w">
    </span><span class="n">gender</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">factor</span><span class="p">(</span><span class="n">sample</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s2">"Male"</span><span class="p">,</span><span class="w"> </span><span class="s2">"Female"</span><span class="p">),</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">))</span><span class="w">  </span><span class="c1"># Gender</span><span class="w">
    </span><span class="n">genes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"Gene"</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">)</span><span class="w">

    </span><span class="c1"># Simulate gene expression matrix for treatment group</span><span class="w">
    </span><span class="n">gene_expression_treatment</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="n">rnorm</span><span class="p">(</span><span class="m">50</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">),</span><span class="w"> </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">dimnames</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">genes</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">))</span><span class="w"> 
    </span><span class="n">print</span><span class="p">(</span><span class="n">gene_expression_treatment</span><span class="p">)</span><span class="w">

    </span><span class="c1">##               1         2        3         4         5         6         7         8         9        10</span><span class="w">
    </span><span class="c1">## Gene1 12.448164 13.573826 7.864353  6.626613 10.852928 11.377281  8.610586  7.753783 10.506637 13.032941</span><span class="w">
    </span><span class="c1">## Gene2 10.719628 10.995701 9.564050 11.675574  9.409857 11.107835  9.584165  9.194230  9.942906  6.902494</span><span class="w">
    </span><span class="c1">## Gene3 10.801543  6.066766 7.947991 10.306746 11.790251  9.876177  7.469207  9.066689  9.914259 11.169227</span><span class="w">
    </span><span class="c1">## Gene4 10.221365 11.402712 8.542218  7.723726 11.756267  9.388075 14.337912 11.559930 12.737205 10.247708</span><span class="w">
    </span><span class="c1">## Gene5  8.888318  9.054417 8.749921 12.507630 11.643162  9.239058 12.415924  9.833262  9.548458 10.431883</span><span class="w">

    </span><span class="c1"># Simulate gene expression matrix for control group </span><span class="w">
    </span><span class="n">gene_expression_control</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="n">rnorm</span><span class="p">(</span><span class="m">50</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">),</span><span class="w"> </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">dimnames</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">genes</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">))</span><span class="w"> 
    </span><span class="n">print</span><span class="p">(</span><span class="n">gene_expression_control</span><span class="p">)</span><span class="w">

    </span><span class="c1">##              1        2         3        4        5        6        7        8        9       10</span><span class="w">
    </span><span class="c1">## Gene1 5.759279 5.607057 4.0179377 7.051143 5.011528 5.663564 6.987008 3.799481 3.579187 4.909945</span><span class="w">
    </span><span class="c1">## Gene2 3.995353 5.896420 0.3816622 4.430454 5.770561 7.193678 6.096794 9.374666 5.513767 3.430191</span><span class="w">
    </span><span class="c1">## Gene3 4.333585 5.106008 7.0114770 2.558565 4.258680 5.870363 5.477463 8.065221 4.506616 1.664116</span><span class="w">
    </span><span class="c1">## Gene4 2.962849 6.844535 3.5815985 5.362607 6.288753 4.348137 3.744188 4.528599 4.304915 4.239547</span><span class="w">
    </span><span class="c1">## Gene5 2.856418 9.100169 3.6239828 4.722217 4.559027 7.297615 7.721305 2.947158 3.096763 6.837993</span><span class="w">

    </span><span class="c1"># Combine the gene expression data </span><span class="w">
    </span><span class="n">gene_expression</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">gene_expression_treatment</span><span class="p">,</span><span class="w"> </span><span class="n">gene_expression_control</span><span class="p">)</span><span class="w">

    </span><span class="c1"># Create a data frame with the gene expression data </span><span class="w">
    </span><span class="n">expression_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="n">gene_expression</span><span class="p">,</span><span class="w"> </span><span class="n">row.names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">genes</span><span class="p">)</span><span class="w">
    </span><span class="n">colnames</span><span class="p">(</span><span class="n">expression_data</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"sample"</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">20</span><span class="p">)</span><span class="w"> 

    </span><span class="c1"># Print the expression data</span><span class="w">
    </span><span class="n">print</span><span class="p">(</span><span class="n">expression_data</span><span class="p">)</span><span class="w"> 

    </span><span class="c1">##         sample1   sample2  sample3   sample4   sample5   sample6   sample7   sample8   sample9  sample10 sample11 sample12  sample13 sample14 sample15 sample16 sample17</span><span class="w">
    </span><span class="c1">## Gene1 12.448164 13.573826 7.864353  6.626613 10.852928 11.377281  8.610586  7.753783 10.506637 13.032941 5.759279 5.607057 4.0179377 7.051143 5.011528 5.663564 6.987008</span><span class="w">
    </span><span class="c1">## Gene2 10.719628 10.995701 9.564050 11.675574  9.409857 11.107835  9.584165  9.194230  9.942906  6.902494 3.995353 5.896420 0.3816622 4.430454 5.770561 7.193678 6.096794</span><span class="w">
    </span><span class="c1">## Gene3 10.801543  6.066766 7.947991 10.306746 11.790251  9.876177  7.469207  9.066689  9.914259 11.169227 4.333585 5.106008 7.0114770 2.558565 4.258680 5.870363 5.477463</span><span class="w">
    </span><span class="c1">## Gene4 10.221365 11.402712 8.542218  7.723726 11.756267  9.388075 14.337912 11.559930 12.737205 10.247708 2.962849 6.844535 3.5815985 5.362607 6.288753 4.348137 3.744188</span><span class="w">
    </span><span class="c1">## Gene5  8.888318  9.054417 8.749921 12.507630 11.643162  9.239058 12.415924  9.833262  9.548458 10.431883 2.856418 9.100169 3.6239828 4.722217 4.559027 7.297615 7.721305</span><span class="w">
    </span><span class="c1">##       sample18 sample19 sample20</span><span class="w">
    </span><span class="c1">## Gene1 3.799481 3.579187 4.909945</span><span class="w">
    </span><span class="c1">## Gene2 9.374666 5.513767 3.430191</span><span class="w">
    </span><span class="c1">## Gene3 8.065221 4.506616 1.664116</span><span class="w">
    </span><span class="c1">## Gene4 4.528599 4.304915 4.239547</span><span class="w">
    </span><span class="c1">## Gene5 2.947158 3.096763 6.837993</span><span class="w">
</span></code></pre></div></div> <h2 id="step-2---fit-linear-models-with-limma">Step 2 - Fit linear models with limma</h2> <p>In this step, we will fit linear models to the example data using the <code class="language-plaintext highlighter-rouge">limma</code> package. We will consider three different models:</p> <ol> <li>Model 1: Treatment as the only predictor variable</li> <li>Model 2: Treatment and gender as covariates</li> <li>Model 3: Treatment and gender as covariates with repeated measures</li> </ol> <p>In <code class="language-plaintext highlighter-rouge">limma</code>, block effects can be used to account for non-independent samples, such as technical replicates or paired samples. You can use the <code class="language-plaintext highlighter-rouge">duplicateCorrelation()</code> function to model the correlation between samples within the same block.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1">#------Model 1: Treatment as the only predictor variable------# </span><span class="w">
    </span><span class="c1"># Create model matrix (with treatment as the only predictor variable)  </span><span class="w">
    </span><span class="n">design_1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">model.matrix</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">treatment</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expression_data</span><span class="p">)</span><span class="w"> 
    </span><span class="c1"># Fit the linear model</span><span class="w">
    </span><span class="n">fit_1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lmFit</span><span class="p">(</span><span class="n">expression_data</span><span class="p">,</span><span class="w"> </span><span class="n">design_1</span><span class="p">)</span><span class="w">  
    </span><span class="c1"># Apply empirical Bayes moderation</span><span class="w">
    </span><span class="n">fit_1_ebayes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">eBayes</span><span class="p">(</span><span class="n">fit_1</span><span class="p">)</span><span class="w">


    </span><span class="c1">#------Model 2: Treatment and Gender as covariates------# </span><span class="w">
    </span><span class="c1"># Create design matrix (treatment and gender as covariates)</span><span class="w">
    </span><span class="n">design_2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">model.matrix</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">treatment</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">gender</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expression_data</span><span class="p">)</span><span class="w">
    </span><span class="c1"># Fit the linear model for each gene</span><span class="w">
    </span><span class="n">fit_2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lmFit</span><span class="p">(</span><span class="n">expression_data</span><span class="p">,</span><span class="w"> </span><span class="n">design_2</span><span class="p">)</span><span class="w">
    </span><span class="c1"># Apply empirical Bayes moderation</span><span class="w">
    </span><span class="n">fit_2_ebayes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">eBayes</span><span class="p">(</span><span class="n">fit_2</span><span class="p">)</span><span class="w">


    </span><span class="c1">#------Model 3: Treatment and Gender as covariates with repeated measures------# </span><span class="w">
    </span><span class="c1"># Model the correlation between samples within the same block (repeated measures) </span><span class="w">
    </span><span class="n">corfit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">limma</span><span class="o">::</span><span class="n">duplicateCorrelation</span><span class="p">(</span><span class="n">gene_expression</span><span class="p">,</span><span class="w"> </span><span class="n">design_2</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">people</span><span class="p">)</span><span class="w"> 
    </span><span class="c1"># Incorprate the block effect in the model </span><span class="w">
    </span><span class="n">fit_3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lmFit</span><span class="p">(</span><span class="n">gene_expression</span><span class="p">,</span><span class="w"> </span><span class="n">design_2</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">people</span><span class="p">,</span><span class="w"> </span><span class="n">correlation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">corfit</span><span class="o">$</span><span class="n">consensus</span><span class="p">)</span><span class="w">
    </span><span class="c1"># Apply empirical Bayes moderation</span><span class="w">
    </span><span class="n">fit_3_ebayes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">eBayes</span><span class="p">(</span><span class="n">fit_3</span><span class="p">)</span><span class="w"> 
</span></code></pre></div></div> <p>The <code class="language-plaintext highlighter-rouge">corfit$consensus</code> object contains the correlation structure of the repeated measures, which is used in the <code class="language-plaintext highlighter-rouge">lmFit</code> function to account for the correlation between samples from the same individual. It is an estimate of the average intra-block correlation. If the value is close to zero, the block effect is weak or negligible. A higher value (closer to 1) indicates a stronger correlation within blocks, meaning the block effect is significant.</p> <p>In this case, the block effect is not significant, as the correlation is close to zero (approximately, 0.01).</p> <h2 id="step-3---evaluate-the-block-effect">Step 3 - Evaluate the Block Effect</h2> <p><strong>Extract top differentially expressed genes</strong></p> <p>In this step, we will extract the top differentially expressed genes from the fitted models. We will use the <code class="language-plaintext highlighter-rouge">topTable</code> function to extract the results, including the log fold change, moderated t-statistic, raw p-value, adjusted p-value (FDR), and log-odds that the gene is differentially expressed.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Extract top differentially expressed genes</span><span class="w">
    </span><span class="n">topTable</span><span class="p">(</span><span class="n">fit_1_ebayes</span><span class="p">,</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">Inf</span><span class="p">,</span><span class="w"> </span><span class="n">adjust.method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"BH"</span><span class="p">,</span><span class="w"> </span><span class="n">sort.by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"P"</span><span class="p">)</span><span class="w"> 

    </span><span class="c1">## Removing intercept from test coefficients</span><span class="w">

    </span><span class="c1">##           logFC  AveExpr         t      P.Value    adj.P.Val         B</span><span class="w">
    </span><span class="c1">## Gene4 -6.171139 7.706142 -7.430413 5.986052e-11 2.993026e-10 20.276398</span><span class="w">
    </span><span class="c1">## Gene1 -5.026098 7.751662 -6.051717 3.234941e-08 7.859775e-08 11.366624</span><span class="w">
    </span><span class="c1">## Gene5 -4.954939 7.753734 -5.966037 4.715865e-08 7.859775e-08 10.873058</span><span class="w">
    </span><span class="c1">## Gene2 -4.701290 7.558999 -5.660628 1.776199e-07 2.220249e-07  9.170996</span><span class="w">
    </span><span class="c1">## Gene3 -4.555676 7.163048 -5.485301 3.752867e-07 3.752867e-07  8.234286</span><span class="w">

    </span><span class="c1"># Show results</span><span class="w">
    </span><span class="n">topTable</span><span class="p">(</span><span class="n">fit_2_ebayes</span><span class="p">)</span><span class="w">

    </span><span class="c1">## Removing intercept from test coefficients</span><span class="w">

    </span><span class="c1">##       treatment1  genderMale  AveExpr        F      P.Value    adj.P.Val</span><span class="w">
    </span><span class="c1">## Gene4  -6.174442 -0.03303168 7.706142 27.05854 1.772654e-12 8.863272e-12</span><span class="w">
    </span><span class="c1">## Gene1  -4.913836  1.12261968 7.751662 18.82582 6.668838e-09 1.667210e-08</span><span class="w">
    </span><span class="c1">## Gene5  -5.047809 -0.92870157 7.753734 18.04422 1.457123e-08 2.428538e-08</span><span class="w">
    </span><span class="c1">## Gene2  -4.660927  0.40362347 7.558999 15.81690 1.351472e-07 1.689340e-07</span><span class="w">
    </span><span class="c1">## Gene3  -4.570297 -0.14621287 7.163048 14.76065 3.886259e-07 3.886259e-07</span><span class="w">

    </span><span class="c1"># Show results</span><span class="w">
    </span><span class="n">topTable</span><span class="p">(</span><span class="n">fit_3_ebayes</span><span class="p">)</span><span class="w"> 

    </span><span class="c1">## Removing intercept from test coefficients</span><span class="w">

    </span><span class="c1">##       treatment1  genderMale  AveExpr        F      P.Value    adj.P.Val</span><span class="w">
    </span><span class="c1">## Gene4  -6.173634 -0.02495011 7.706142 26.77375 2.356711e-12 1.178356e-11</span><span class="w">
    </span><span class="c1">## Gene1  -4.914731  1.11367369 7.751662 18.62289 8.169239e-09 2.042310e-08</span><span class="w">
    </span><span class="c1">## Gene5  -5.047331 -0.92392051 7.753734 17.85445 1.761614e-08 2.936023e-08</span><span class="w">
    </span><span class="c1">## Gene2  -4.660333  0.40956206 7.558999 15.65513 1.588780e-07 1.985975e-07</span><span class="w">
    </span><span class="c1">## Gene3  -4.570291 -0.14614599 7.163048 14.60561 4.538018e-07 4.538018e-07</span><span class="w">
</span></code></pre></div></div> <p>Parameters Interpretation: - logFC: Log fold change of the gene expression between conditions. - AveExpr: Average expression of the gene across all samples. - t: Moderated t-statistic. - P.Value: Raw p-value. - adj.P.Val: Adjusted p-value (FDR). - B: Log-odds that the gene is differentially expressed.</p> <p>If including the block effect changes the results substantially (e.g., differentially expressed genes, p-values), then the block effect is important in your model. Otherwise, if there is minimal change, the block effect may not significantly impact the model.</p> <p>In this case, the block effect does not significantly affect the results, as the top differentially expressed genes are similar across the models. In contrast, the covariate, gender has a significant impact on the results, as the top differentially expressed genes differ between Model 1 and Model 2.</p> <p><strong>Visualize the coefficients and CI</strong></p> <p>In this step, we will visualize the coefficients and confidence intervals for the fixed effects of treatment on gene expression. We will compare the results from Model 1, Model 2, and Model 3.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Define a function to extract the coefficients and confidence intervals </span><span class="w">
    </span><span class="n">extract_coef_ci</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="n">coef_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="w">
        </span><span class="n">Gene</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rownames</span><span class="p">(</span><span class="n">fit</span><span class="o">$</span><span class="n">coefficients</span><span class="p">),</span><span class="w">
        </span><span class="n">Estimate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[,</span><span class="w"> </span><span class="s2">"treatment1"</span><span class="p">],</span><span class="w">
        </span><span class="n">CI_Lower</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[,</span><span class="w"> </span><span class="s2">"treatment1"</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1.96</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">stdev.unscaled</span><span class="p">[,</span><span class="w"> </span><span class="s2">"treatment1"</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">sigma</span><span class="p">,</span><span class="w">
        </span><span class="n">CI_Upper</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[,</span><span class="w"> </span><span class="s2">"treatment1"</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1.96</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">stdev.unscaled</span><span class="p">[,</span><span class="w"> </span><span class="s2">"treatment1"</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">sigma</span><span class="w">
      </span><span class="p">)</span><span class="w">
      </span><span class="nf">return</span><span class="p">(</span><span class="n">coef_df</span><span class="p">)</span><span class="w">
    </span><span class="p">}</span><span class="w">

    </span><span class="c1"># Extract coefficients and confidence intervals for Model 1 - 3 </span><span class="w">
    </span><span class="n">coef_df_1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">extract_coef_ci</span><span class="p">(</span><span class="n">fit_1_ebayes</span><span class="p">)</span><span class="w">
    </span><span class="n">coef_df_2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">extract_coef_ci</span><span class="p">(</span><span class="n">fit_2_ebayes</span><span class="p">)</span><span class="w">
    </span><span class="n">coef_df_3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">extract_coef_ci</span><span class="p">(</span><span class="n">fit_3_ebayes</span><span class="p">)</span><span class="w">

    </span><span class="c1"># Prepare the data for plotting </span><span class="w">
    </span><span class="n">coef_df_1</span><span class="o">$</span><span class="n">model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s2">"Model_1"</span><span class="w">
    </span><span class="n">coef_df_2</span><span class="o">$</span><span class="n">model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s2">"Model_2"</span><span class="w"> 
    </span><span class="n">coef_df_3</span><span class="o">$</span><span class="n">model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s2">"Model_3"</span><span class="w"> 

    </span><span class="n">coef_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rbind</span><span class="p">(</span><span class="n">coef_df_1</span><span class="p">,</span><span class="w"> </span><span class="n">coef_df_2</span><span class="p">,</span><span class="w"> </span><span class="n">coef_df_3</span><span class="p">)</span><span class="w"> 
    </span><span class="n">print</span><span class="p">(</span><span class="n">coef_df</span><span class="p">)</span><span class="w">  

    </span><span class="c1">##         Gene  Estimate  CI_Lower  CI_Upper   model</span><span class="w">
    </span><span class="c1">## Gene1  Gene1 -5.026098 -6.710451 -3.341746 Model_1</span><span class="w">
    </span><span class="c1">## Gene2  Gene2 -4.701290 -6.404071 -2.998508 Model_1</span><span class="w">
    </span><span class="c1">## Gene3  Gene3 -4.555676 -6.179768 -2.931585 Model_1</span><span class="w">
    </span><span class="c1">## Gene4  Gene4 -6.171139 -7.610268 -4.732010 Model_1</span><span class="w">
    </span><span class="c1">## Gene5  Gene5 -4.954939 -6.629405 -3.280472 Model_1</span><span class="w">
    </span><span class="c1">## Gene11 Gene1 -4.913836 -6.572943 -3.254729 Model_2</span><span class="w">
    </span><span class="c1">## Gene21 Gene2 -4.660927 -6.411613 -2.910241 Model_2</span><span class="w">
    </span><span class="c1">## Gene31 Gene3 -4.570297 -6.248554 -2.892041 Model_2</span><span class="w">
    </span><span class="c1">## Gene41 Gene4 -6.174442 -7.662748 -4.686136 Model_2</span><span class="w">
    </span><span class="c1">## Gene51 Gene5 -5.047809 -6.722954 -3.372663 Model_2</span><span class="w">
    </span><span class="c1">## Gene12 Gene1 -4.914731 -6.578634 -3.250828 Model_3</span><span class="w">
    </span><span class="c1">## Gene22 Gene2 -4.660333 -6.417573 -2.903094 Model_3</span><span class="w">
    </span><span class="c1">## Gene32 Gene3 -4.570291 -6.258486 -2.882096 Model_3</span><span class="w">
    </span><span class="c1">## Gene42 Gene4 -6.173634 -7.668705 -4.678563 Model_3</span><span class="w">
    </span><span class="c1">## Gene52 Gene5 -5.047331 -6.737661 -3.357000 Model_3</span><span class="w">
</span></code></pre></div></div> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Plot the fixed effects with confidence intervals, comparing Model 1 - 3 </span><span class="w">
    </span><span class="n">pd</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">position_dodge</span><span class="p">(</span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.2</span><span class="p">)</span><span class="w"> </span><span class="c1"># Position dodge for better visualization </span><span class="w">

    </span><span class="n">ggplot</span><span class="p">(</span><span class="n">coef_df</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Gene</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Estimate</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
      </span><span class="n">geom_point</span><span class="p">(</span><span class="n">position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pd</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
      </span><span class="n">geom_errorbar</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">ymin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CI_Lower</span><span class="p">,</span><span class="w"> </span><span class="n">ymax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CI_Upper</span><span class="p">),</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.2</span><span class="p">,</span><span class="w"> </span><span class="n">position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pd</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="c1"># Error bars for confidence intervals </span><span class="w">
      </span><span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Fixed Effects of Treatment on Gene Expression"</span><span class="p">,</span><span class="w">
           </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Gene"</span><span class="p">,</span><span class="w">
           </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Estimate (Treatment Effect)"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
      </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
      </span><span class="n">theme</span><span class="p">(</span><span class="n">legend.position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"top"</span><span class="p">)</span><span class="w"> 
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/linear-mixed-model_files/figure-markdown_strict/unnamed-chunk-3-1.png" sizes="95vw"/> <img src="/assets/img/linear-mixed-model_files/figure-markdown_strict/unnamed-chunk-3-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>The plot shows the fixed effects of treatment on gene expression, with confidence intervals for Model 1 - 3. The coefficients represent the estimated treatment effect on gene expression, and the confidence intervals indicate the uncertainty around the estimates.</p> <p>The gene expression of Genes 1 - 5 are significantly downregulated in the treatment group compared to the control group, as the confidence interval does not include zero. The confidence intervals provide a range of plausible values for the treatment effect, taking into account the uncertainty in the estimates.</p> <h2 id="step-4---evaluate-model-robustness">Step 4 - Evaluate model robustness</h2> <p>This step evaluates the assumptions of homoscedasticity and linearity by examining the residuals. If the residuals are randomly distributed around zero and show no clear patterns, the assumptions are met. If there are patterns or trends in the residuals, further investigation may be needed to address model assumptions.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Plot the residuals</span><span class="w">

    </span><span class="c1"># Create a functiont to plot fitted values vs residuals </span><span class="w">
    </span><span class="n">plot_residuals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="n">residuals_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="w">
        </span><span class="n">Residuals</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">as.vector</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data</span><span class="p">)),</span><span class="w"> 
        </span><span class="n">Fitted</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">as.vector</span><span class="p">(</span><span class="n">fitted</span><span class="p">(</span><span class="n">fit</span><span class="p">))</span><span class="w">
      </span><span class="p">)</span><span class="w"> 
      
      </span><span class="n">ggplot</span><span class="p">(</span><span class="n">residuals_df</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Fitted</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Residuals</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
        </span><span class="n">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
        </span><span class="n">geom_hline</span><span class="p">(</span><span class="n">yintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"dashed"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
        </span><span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Residuals vs Fitted Values"</span><span class="p">,</span><span class="w">
             </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Fitted Values"</span><span class="p">,</span><span class="w">
             </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Residuals"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
        </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w">
    </span><span class="p">}</span><span class="w">

    </span><span class="c1"># Combine the residual plots for Model 1 - 3</span><span class="w">
    </span><span class="n">grid.arrange</span><span class="p">(</span><span class="n">plot_residuals</span><span class="p">(</span><span class="n">fit_1</span><span class="p">,</span><span class="w"> </span><span class="n">expression_data</span><span class="p">),</span><span class="w"> 
                 </span><span class="n">plot_residuals</span><span class="p">(</span><span class="n">fit_2</span><span class="p">,</span><span class="w"> </span><span class="n">expression_data</span><span class="p">),</span><span class="w"> 
                 </span><span class="n">plot_residuals</span><span class="p">(</span><span class="n">fit_3</span><span class="p">,</span><span class="w"> </span><span class="n">gene_expression</span><span class="p">),</span><span class="w"> 
                 </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w"> 
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/linear-mixed-model_files/figure-markdown_strict/unnamed-chunk-4-1.png" sizes="95vw"/> <img src="/assets/img/linear-mixed-model_files/figure-markdown_strict/unnamed-chunk-4-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>In this case, the residual plots show no clear patterns or trends, indicating that the assumptions of homoscedasticity and linearity are met for Model 1 - 3.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Check the normality of residuals using Q-Q plots </span><span class="w">
    </span><span class="n">par</span><span class="p">(</span><span class="n">mfrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">))</span><span class="w"> 
    </span><span class="n">qqnorm</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit_1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expression_data</span><span class="p">))</span><span class="w"> 
    </span><span class="n">qqline</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit_1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expression_data</span><span class="p">))</span><span class="w"> 

    </span><span class="n">qqnorm</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit_2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expression_data</span><span class="p">))</span><span class="w"> 
    </span><span class="n">qqline</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit_2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expression_data</span><span class="p">))</span><span class="w">

    </span><span class="n">qqnorm</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit_3</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gene_expression</span><span class="p">))</span><span class="w"> 
    </span><span class="n">qqline</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit_3</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gene_expression</span><span class="p">))</span><span class="w"> 
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/linear-mixed-model_files/figure-markdown_strict/unnamed-chunk-5-1.png" sizes="95vw"/> <img src="/assets/img/linear-mixed-model_files/figure-markdown_strict/unnamed-chunk-5-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>The residuals are randomly distributed around zero, with no systematic deviations from the assumptions.</p> <h1 id="conclusion">Conclusion</h1> <p>In this tutorial, we demonstrated how to fit linear mixed-effect models with the <code class="language-plaintext highlighter-rouge">limma</code> package in R. We simulated example data with repeated measures and applied linear models with different covariates and block effects. We evaluated the block effect, extracted differentially expressed genes, visualized the coefficients, and assessed model robustness.</p> <p>Linear mixed-effect models are useful for analyzing data with repeated measures or nested structures, where samples are not independent. By incorporating random effects and block effects, we can account for the correlation between samples and improve the accuracy of the statistical analysis.</p> <p>This tutorial is for demonstration purpose, although the block efffect is not significant. You can apply similar steps to analyze your own data with linear mixed-effect models using the <code class="language-plaintext highlighter-rouge">limma</code> package in R.</p> <h1 id="sessoin-info">Sessoin Info</h1> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="n">sessionInfo</span><span class="p">()</span><span class="w">

    </span><span class="c1">## R version 4.3.3 (2024-02-29)</span><span class="w">
    </span><span class="c1">## Platform: aarch64-apple-darwin20 (64-bit)</span><span class="w">
    </span><span class="c1">## Running under: macOS 15.0</span><span class="w">
    </span><span class="c1">## </span><span class="w">
    </span><span class="c1">## Matrix products: default</span><span class="w">
    </span><span class="c1">## BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib </span><span class="w">
    </span><span class="c1">## LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0</span><span class="w">
    </span><span class="c1">## </span><span class="w">
    </span><span class="c1">## locale:</span><span class="w">
    </span><span class="c1">## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8</span><span class="w">
    </span><span class="c1">## </span><span class="w">
    </span><span class="c1">## time zone: America/Edmonton</span><span class="w">
    </span><span class="c1">## tzcode source: internal</span><span class="w">
    </span><span class="c1">## </span><span class="w">
    </span><span class="c1">## attached base packages:</span><span class="w">
    </span><span class="c1">## [1] stats     graphics  grDevices utils     datasets  methods   base     </span><span class="w">
    </span><span class="c1">## </span><span class="w">
    </span><span class="c1">## other attached packages:</span><span class="w">
    </span><span class="c1">## [1] rmarkdown_2.26 gridExtra_2.3  limma_3.58.1   shiny_1.9.1    ggplot2_3.5.0  bookdown_0.41 </span><span class="w">
    </span><span class="c1">## </span><span class="w">
    </span><span class="c1">## loaded via a namespace (and not attached):</span><span class="w">
    </span><span class="c1">##  [1] sass_0.4.9          utf8_1.2.4          generics_0.1.3      digest_0.6.35       magrittr_2.0.3      evaluate_0.23       grid_4.3.3          fastmap_1.2.0      </span><span class="w">
    </span><span class="c1">##  [9] jsonlite_1.8.8      promises_1.2.1      BiocManager_1.30.25 fansi_1.0.6         scales_1.3.0        jquerylib_0.1.4     cli_3.6.2           rlang_1.1.3        </span><span class="w">
    </span><span class="c1">## [17] munsell_0.5.0       withr_3.0.0         cachem_1.1.0        yaml_2.3.8          tools_4.3.3         memoise_2.0.1       dplyr_1.1.4         colorspace_2.1-1   </span><span class="w">
    </span><span class="c1">## [25] httpuv_1.6.15       vctrs_0.6.5         R6_2.5.1            mime_0.12           lifecycle_1.0.4     pkgconfig_2.0.3     pillar_1.9.0        bslib_0.6.2        </span><span class="w">
    </span><span class="c1">## [33] later_1.3.2         gtable_0.3.4        glue_1.7.0          Rcpp_1.0.12         statmod_1.5.0       xfun_0.48           tibble_3.2.1        tidyselect_1.2.1   </span><span class="w">
    </span><span class="c1">## [41] highr_0.10          rstudioapi_0.16.0   knitr_1.45          farver_2.1.1        xtable_1.8-4        htmltools_0.5.8     labeling_0.4.3      compiler_4.3.3</span><span class="w">
</span></code></pre></div></div>]]></content><author><name></name></author><category term="statistics"/><category term="data-analysis,"/><category term="limma,"/><category term="linear-mixed-models,"/><category term="gene-expression"/><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Choosing the Right Dimensionality Reduction in Metabolomics: Navigating Common Pitfalls</title><link href="https://davidzhao1015.github.io/blog/2024/choose-dimension-reduction/" rel="alternate" type="text/html" title="Choosing the Right Dimensionality Reduction in Metabolomics: Navigating Common Pitfalls"/><published>2024-10-18T00:00:00+00:00</published><updated>2024-10-18T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2024/choose-dimension-reduction</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2024/choose-dimension-reduction/"><![CDATA[<h2 id="challenges-of-dimensionality-reduction-in-metabolomics-studies">Challenges of Dimensionality Reduction in Metabolomics Studies</h2> <p>Struggling to choose the right dimensionality reduction method for your metabolomics data? Youâ€™re not alone. One of the biggest challenges in data analysis is selecting an appropriate technique to handle high-dimensional datasets without losing valuable information. In this post, weâ€™ll dive into practical solutions to make that decision easier and more effective.</p> <h2 id="types-of-metabolomics-studies">Types of Metabolomics Studies</h2> <p>Metabolomics research typically serves three primary purposes: <strong>exploration</strong>, <strong>association</strong>, and <strong>prediction</strong>.</p> <ul> <li> <p><strong>Exploration</strong> aims to discover patterns in high-dimensional datasets using unsupervised methods like Principal Component Analysis (PCA) and clustering techniques.</p> </li> <li> <p><strong>Association</strong> category focuses on identifying relationships between metabolites and biological factors, employing statistical methods such as correlation analysis, ANOVA, and linear regression.</p> </li> <li> <p><strong>Prediction</strong> involves developing models to classify or predict outcomes based on metabolite profiles, utilizing supervised methods like logistic regression and Random Forest.</p> </li> </ul> <p>These classifications guide study design and the selection of appropriate statistical techniques.</p> <hr/> <h2 id="overview-of-popular-methods-in-chemometrics-analysis">Overview of Popular Methods in Chemometrics Analysis</h2> <p>This table provides a comprehensive overview of each methodâ€™s essential characteristics, facilitating a clearer understanding of their applications and limitations in the context of chemometrics and other fields.</p> <table> <thead> <tr> <th style="text-align: left"><strong>Method</strong></th> <th style="text-align: left"><strong>Description</strong></th> <th style="text-align: left"><strong>Purpose</strong></th> <th style="text-align: left"><strong>Assumptions</strong></th> <th style="text-align: left"><strong>Advantages</strong></th> <th style="text-align: left"><strong>Disadvantages</strong></th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><strong>Principal Component Analysis (PCA)</strong></td> <td style="text-align: left">A linear technique that reduces dimensionality by transforming original variables into a smaller set of uncorrelated components.</td> <td style="text-align: left">Dimensionality Reduction</td> <td style="text-align: left">Linearity, Multivariate normality</td> <td style="text-align: left">Effective in simplifying data, capturing variance.</td> <td style="text-align: left">Assumes linear relationships; sensitive to outliers.</td> </tr> <tr> <td style="text-align: left"><strong>Partial Least Squares (PLS)</strong></td> <td style="text-align: left">A regression technique that models relationships between predictor and response variables, reducing dimensionality.</td> <td style="text-align: left">Supervised Regression &amp; Dimensionality Reduction</td> <td style="text-align: left">Linearity, Multicollinearity</td> <td style="text-align: left">Handles collinearity well; good for small sample sizes.</td> <td style="text-align: left">Can overfit with small datasets; requires careful model validation.</td> </tr> <tr> <td style="text-align: left"><strong>Sparse Partial Least Squares (sPLS)</strong></td> <td style="text-align: left">A variant of PLS that incorporates sparsity for feature selection along with dimensionality reduction.</td> <td style="text-align: left">Supervised Regression &amp; Feature Selection</td> <td style="text-align: left">Linearity, Multicollinearity</td> <td style="text-align: left">Simultaneously reduces dimensionality and selects features.</td> <td style="text-align: left">May overlook relevant features if sparsity is too high.</td> </tr> <tr> <td style="text-align: left"><strong>Independent Component Analysis (ICA)</strong></td> <td style="text-align: left">A method that separates a multivariate signal into additive independent components.</td> <td style="text-align: left">Signal Processing &amp; Dimensionality Reduction</td> <td style="text-align: left">Statistical independence of components</td> <td style="text-align: left">Captures non-Gaussian features, useful for separating signals.</td> <td style="text-align: left">Sensitive to noise; requires independent sources.</td> </tr> <tr> <td style="text-align: left"><strong>Multivariate Curve Resolution (MCR)</strong></td> <td style="text-align: left">A method for resolving overlapping signals in complex data matrices into pure components.</td> <td style="text-align: left">Signal Resolution</td> <td style="text-align: left">Linearity, Known number of components</td> <td style="text-align: left">Effective for spectral data; interpretable results.</td> <td style="text-align: left">Requires prior knowledge about the number of components.</td> </tr> <tr> <td style="text-align: left"><strong>Orthogonal Partial Least Squares (OPLS)</strong></td> <td style="text-align: left">An extension of PLS that separates predictive variance from orthogonal (noise) variance.</td> <td style="text-align: left">Supervised Regression &amp; Dimensionality Reduction</td> <td style="text-align: left">Linearity, Multicollinearity</td> <td style="text-align: left">Improved interpretability by filtering out noise.</td> <td style="text-align: left">Still sensitive to overfitting; complex model selection.</td> </tr> <tr> <td style="text-align: left"><strong>Non-negative Matrix Factorization (NMF)</strong></td> <td style="text-align: left">A matrix factorization technique that decomposes data into non-negative components.</td> <td style="text-align: left">Dimensionality Reduction &amp; Feature Extraction</td> <td style="text-align: left">Non-negativity of data</td> <td style="text-align: left">Produces interpretable, additive components.</td> <td style="text-align: left">Sensitive to initialization; may not converge to global optimum.</td> </tr> <tr> <td style="text-align: left"><strong>Factor Analysis (FA)</strong></td> <td style="text-align: left">A technique for modeling the underlying factors that explain observed correlations among variables.</td> <td style="text-align: left">Exploratory Data Analysis</td> <td style="text-align: left">Linearity, Multivariate normality</td> <td style="text-align: left">Identifies latent structures; interpretable results.</td> <td style="text-align: left">Requires a large sample size; assumes linearity.</td> </tr> <tr> <td style="text-align: left"><strong>Multidimensional Scaling (MDS)</strong></td> <td style="text-align: left">A technique that visualizes the similarity or dissimilarity of data points in lower-dimensional space.</td> <td style="text-align: left">Visualization</td> <td style="text-align: left">Preservation of distances</td> <td style="text-align: left">Effective for visualizing high-dimensional data.</td> <td style="text-align: left">Sensitive to noise; may produce misleading results with many dimensions.</td> </tr> <tr> <td style="text-align: left"><strong>Kernel Principal Component Analysis (Kernel PCA)</strong></td> <td style="text-align: left">An extension of PCA that uses kernel methods to capture non-linear relationships.</td> <td style="text-align: left">Dimensionality Reduction</td> <td style="text-align: left">Non-linear structure in data</td> <td style="text-align: left">Captures complex structures not visible in linear PCA.</td> <td style="text-align: left">Computationally intensive; choice of kernel can affect results.</td> </tr> <tr> <td style="text-align: left"><strong>t-Distributed Stochastic Neighbor Embedding (t-SNE)</strong></td> <td style="text-align: left">A non-linear dimensionality reduction technique primarily used for visualization.</td> <td style="text-align: left">Visualization</td> <td style="text-align: left">Locality preservation in high-dimensional space</td> <td style="text-align: left">Excellent for visualizing clusters in high dimensions.</td> <td style="text-align: left">Computationally expensive; not suitable for large datasets.</td> </tr> <tr> <td style="text-align: left"><strong>Autoencoders (Neural Network-based)</strong></td> <td style="text-align: left">Neural networks used for unsupervised learning that compress data into lower dimensions.</td> <td style="text-align: left">Dimensionality Reduction &amp; Feature Extraction</td> <td style="text-align: left">Non-linearity, sufficient data for training</td> <td style="text-align: left">Captures complex patterns; can be tailored for specific tasks.</td> <td style="text-align: left">Requires careful tuning; sensitive to overfitting.</td> </tr> <tr> <td style="text-align: left"><strong>Self-Organizing Maps (SOM)</strong></td> <td style="text-align: left">An unsupervised neural network that projects high-dimensional data onto a lower-dimensional grid.</td> <td style="text-align: left">Clustering &amp; Visualization</td> <td style="text-align: left">Topological preservation of data relationships</td> <td style="text-align: left">Intuitive visualizations; good for exploring data structure.</td> <td style="text-align: left">Can be sensitive to parameters; requires preprocessing</td> </tr> </tbody> </table> <hr/> <h2 id="practical-guide-to-choosing-a-suitable-method">Practical Guide to Choosing a Suitable Method</h2> <p>When selecting a dimensionality reduction method for metabolomics studies, consider the following criteria:</p> <ol> <li> <p><strong>Data Type and Structure:</strong> Choose methods based on whether the data has linear or non-linear relationships and the type of variables involved.</p> <ul> <li>Linear Data: Use PCA, PLS, or FA for linear relationships.</li> <li>Non-linear Data: Apply Kernel PCA, t-SNE, or autoencoders for non-linear patterns.</li> <li>Variable Type: Use PCA/PLS for continuous variables. For categorical variables, first use Random Forest for feature selection.</li> </ul> </li> <li> <p><strong>Interpretability:</strong> Some methods offer easier-to-interpret results, while others are better suited for complex visualizations.</p> <ul> <li>High Interpretability: PCA, FA, and NMF (for non-negative data) offer clearer results.</li> <li>Low Interpretability: t-SNE and autoencoders excel at visualization but are harder to explain.</li> </ul> </li> <li> <p><strong>Goal of the Analysis:</strong> Select methods based on whether youâ€™re exploring data, selecting features, or reducing noise.</p> <ul> <li>Exploratory Analysis: Use PCA, MDS, or t-SNE to visualize clusters and trends.</li> <li>Feature Selection: Apply sPLS, Random Forest, or NMF to identify key features (e.g., biomarkers).</li> <li>Noise Filtering: Opt for PLS, OPLS, or MCR for noisy data.</li> </ul> </li> <li> <p><strong>Scalability and Dataset Size:</strong> Different methods work better with large datasets or small datasets with many variables.</p> <ul> <li>Large Datasets: Use PCA, PLS, or NMF for computational efficiency. Non-linear methods (t-SNE, Kernel PCA) may struggle.</li> <li>Small Datasets with Many Variables: Use PLS, sPLS, or OPLS to prevent overfitting.</li> </ul> </li> <li> <p><strong>Handling of Missing Data:</strong> Some methods are flexible with missing data, while others require complete datasets.</p> <ul> <li>Missing Data: Use PCA/PLS with imputation. Avoid ICA, which requires complete data. NMF works well for sparse, non-negative data.</li> </ul> </li> <li> <p><strong>Assumptions of the Method:</strong> Each method relies on specific assumptions about the data, which can impact performance.</p> <ul> <li>Linear Assumptions: PCA/FA assume normality and linearity.</li> <li>Non-negative Data: NMF works best with non-negative data.</li> <li>Non-linear Assumptions: Kernel PCA/t-SNE assume non-linear structures.</li> </ul> </li> <li> <p><strong>Overfitting and Generalization:</strong> Overfitting can be a risk, especially with supervised methods and small sample sizes.</p> <ul> <li>High Overfitting Risk: Supervised methods (PLS, OPLS) require cross-validation for small datasets.</li> <li>Low Overfitting Risk: Unsupervised methods (PCA, MDS) are safer but may struggle with complex classification.</li> </ul> </li> <li> <p><strong>Dimensionality and Sparsity:</strong> High-dimensional and sparse datasets require specific methods to reduce dimensionality and select features.</p> <ul> <li>High-Dimensional/Sparse Data: Use sPLS or NMF for dimensionality reduction and feature selection.</li> <li>Non-linear Data: Autoencoders are great for compressing high-dimensional, non-linear datasets.</li> </ul> </li> </ol> <p>By considering these factors, you can choose the most suitable dimensionality reduction method for your metabolomics study, ensuring optimal results and insights from your data.</p> <p>By integrating charactersitics of each method (shown in the table above) with the practical guide, the following table summarizes the key aspects of each method to help you make an informed decision:</p> <table> <thead> <tr> <th><strong>Method</strong></th> <th><strong>Interpretability</strong></th> <th><strong>Goal of analysis</strong></th> <th><strong>Overfitting</strong></th> <th><strong>Missing Data Handling</strong></th> <th><strong>Data Linearity</strong></th> <th><strong>Type of Variables</strong></th> <th><strong>Scalability &amp; Dataset Size</strong></th> <th><strong>Dimensionality &amp; Sparsity</strong></th> </tr> </thead> <tbody> <tr> <td><strong>PCA</strong></td> <td>Moderate</td> <td>Dimensionality reduction</td> <td>Low</td> <td>Imputation</td> <td>Linear</td> <td>Continuous</td> <td>Efficient for large data</td> <td>Reduces dimensions, handles sparsity</td> </tr> <tr> <td><strong>PLS</strong></td> <td>Moderate</td> <td>Regression &amp; Dimensionality</td> <td>High, needs cross-validation</td> <td>Imputation</td> <td>Linear</td> <td>Continuous</td> <td>Good for large data</td> <td>Reduces dimensions, handles multicollinearity</td> </tr> <tr> <td><strong>sPLS</strong></td> <td>High</td> <td>Regression &amp; Feature Selection</td> <td>Low</td> <td>Imputation</td> <td>Linear with sparsity</td> <td>Continuous</td> <td>Efficient in high-dimensions</td> <td>Selects key features, handles sparsity</td> </tr> <tr> <td><strong>ICA</strong></td> <td>Moderate</td> <td>Signal separation</td> <td>Low</td> <td>Imputation needed</td> <td>Non-Gaussian, Independent</td> <td>Continuous</td> <td>Moderate datasets</td> <td>Separates signals, handles sparsity</td> </tr> <tr> <td><strong>MCR</strong></td> <td>High</td> <td>Signal resolution</td> <td>High</td> <td>ALS optimization</td> <td>Linear</td> <td>Continuous (spectral)</td> <td>Smaller datasets</td> <td>Resolves complex mixtures</td> </tr> <tr> <td><strong>OPLS</strong></td> <td>High</td> <td>Regression &amp; Dimensionality</td> <td>High, needs cross-validation</td> <td>Imputation</td> <td>Linear</td> <td>Continuous</td> <td>Effective for large data</td> <td>Focuses on response-related variation</td> </tr> <tr> <td><strong>NMF</strong></td> <td>High</td> <td>Dimensionality &amp; Feature Extraction</td> <td>Low with regularization</td> <td>Non-negative imputation</td> <td>Non-negative</td> <td>Non-negative continuous</td> <td>Moderate datasets</td> <td>Retains interpretability, non-negative data</td> </tr> <tr> <td><strong>FA</strong></td> <td>Moderate</td> <td>Exploratory analysis</td> <td>High</td> <td>Imputation</td> <td>Linear</td> <td>Continuous</td> <td>Moderate datasets</td> <td>Identifies latent factors</td> </tr> <tr> <td><strong>MDS</strong></td> <td>High</td> <td>Visualization</td> <td>Low</td> <td>Imputation needed</td> <td>Non-linear</td> <td>Continuous &amp; Categorical</td> <td>Moderate datasets</td> <td>Visualizes high-dimensional data</td> </tr> <tr> <td><strong>Kernel PCA</strong></td> <td>Low</td> <td>Dimensionality reduction</td> <td>High</td> <td>Imputation needed</td> <td>Non-linear</td> <td>Continuous</td> <td>Moderate datasets</td> <td>Captures non-linear structure</td> </tr> <tr> <td><strong>t-SNE</strong></td> <td>Low</td> <td>Visualization</td> <td>High</td> <td>Imputation needed</td> <td>Non-linear</td> <td>Continuous</td> <td>Small datasets</td> <td>Visualizes high-dimensional data</td> </tr> <tr> <td><strong>Autoencoders</strong></td> <td>Low</td> <td>Dimensionality &amp; Feature Extraction</td> <td>High</td> <td>Direct reconstruction</td> <td>Linear &amp; Non-linear</td> <td>Continuous</td> <td>Large datasets</td> <td>Compresses and reduces dimensionality</td> </tr> <tr> <td><strong>SOM</strong></td> <td>High</td> <td>Clustering &amp; Visualization</td> <td>Low</td> <td>Imputation needed</td> <td>Non-linear</td> <td>Continuous &amp; Categorical</td> <td>Moderate datasets</td> <td>Preserves relationships, handles sparsity</td> </tr> </tbody> </table> <hr/> <h2 id="take-home-message">Take-Home Message</h2> <p>By understanding the strengths and limitations of each method, you can navigate common pitfalls and make informed decisions to extract meaningful insights from your metabolomics data.</p> <p>Selecting the right method depends on your specific data type, goals (dimensionality reduction, visualization, or feature selection), and the need for interpretability versus capturing complex patterns. Keep these factors in mind when choosing your approach.</p>]]></content><author><name></name></author><category term="statistics"/><category term="metabolomics,"/><category term="data-analysis,"/><category term="dimensionality-reduction"/><summary type="html"><![CDATA[Challenges of Dimensionality Reduction in Metabolomics Studies]]></summary></entry><entry><title type="html">Annotating Carbohydrate-Active Enzymes in Bacterial Genomes with Python</title><link href="https://davidzhao1015.github.io/blog/2024/cazyme-annotate/" rel="alternate" type="text/html" title="Annotating Carbohydrate-Active Enzymes in Bacterial Genomes with Python"/><published>2024-10-09T00:00:00+00:00</published><updated>2024-10-09T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2024/cazyme-annotate</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2024/cazyme-annotate/"><![CDATA[<div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/annotate-bacteria-genomes.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div>]]></content><author><name></name></author><category term="genomics"/><category term="gene_annotation,"/><category term="bacterial_functions,"/><category term="carbohydrate-active_enzymes,"/><category term="jupyter_notebook"/><summary type="html"><![CDATA[{::nomarkdown}]]></summary></entry></feed>