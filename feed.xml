<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://davidzhao1015.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://davidzhao1015.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-29T23:29:07+00:00</updated><id>https://davidzhao1015.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Comparing Methods for Estimating 95% Confidence Intervals of Proportions: Wald, Wilson, and Equal-Tailed Jeffreys Prior</title><link href="https://davidzhao1015.github.io/blog/2025/benchmark-interval-prop/" rel="alternate" type="text/html" title="Comparing Methods for Estimating 95% Confidence Intervals of Proportions: Wald, Wilson, and Equal-Tailed Jeffreys Prior"/><published>2025-03-25T00:00:00+00:00</published><updated>2025-03-25T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2025/benchmark-interval-prop</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2025/benchmark-interval-prop/"><![CDATA[<blockquote> <p><strong>How much can you trust a number when dealing with rare events?</strong></p> <p>In statistics, it’s not just about getting an estimate — it’s about knowing how uncertain that estimate really is.</p> </blockquote> <h2 id="introduction"><strong>Introduction</strong></h2> <p>Estimating confidence intervals (CIs) for proportions is a fundamental task in statistical analysis, particularly in fields like epidemiology, public health, and rare disease research.</p> <p>Confidence intervals provide a measure of uncertainty around point estimates like incidence rates, prevalence, and response rates, helping researchers and decision-makers gauge the reliability of their findings.</p> <p>However, constructing accurate confidence intervals for proportions is not always straightforward—especially when dealing with small sample sizes or rare events, where traditional methods may fall short.</p> <p>In this post, we focus on three widely used methods for estimating 95% confidence intervals for proportions:</p> <ul> <li> <p><strong>Wald Method:</strong></p> <p>A traditional approach based on the normal approximation, known for its simplicity but prone to inaccuracies in small samples or when proportions are close to 0 or 1.</p> </li> <li> <p><strong>Wilson Method:</strong></p> <p>An improved frequentist method that adjusts for the shortcomings of Wald, offering more reliable intervals that stay within logical bounds.</p> </li> <li> <p><strong>Equal-Tailed Jeffreys Prior Method:</strong></p> <p>A Bayesian approach using a non-informative prior, known for its excellent frequentist properties and particularly strong performance in rare event settings.</p> </li> </ul> <p>Through simulations designed to mimic rare disease scenarios, we will benchmark these methods, providing both empirical insights and practical Python code to guide method selection in real-world analyses.</p> <h2 id="purpose-of-the-post">Purpose of the post</h2> <p>Which method gives the most reliable confidence interval for proportions? The short answer: it depends. As highlighted by the classic review by Brown et al., the performance of CI estimation methods can vary based on factors like sample size and how close the true proportion is to 0 or 1.</p> <p>This post puts three popular methods—Wald, Wilson, and the equal-tailed Jeffreys prior—to the test using simulated data. By benchmarking their performance, especially in rare disease contexts where small samples are common, we aim to provide practical guidance for choosing the right method—along with reusable Python code for each.</p> <hr/> <h2 id="understanding-confidence-intervals-for-proportions"><strong>Understanding Confidence Intervals for Proportions</strong></h2> <p>In statistical analysis, a <strong>confidence interval (CI)</strong> provides a range of plausible values for an unknown population parameter based on observed data.</p> <p>When estimating a <strong>proportion</strong>—such as the incidence of a rare disease, the prevalence of a microbial species, or a treatment success rate—the confidence interval quantifies the uncertainty around the point estimate.</p> <p>Rather than relying solely on a single value (e.g., “2% prevalence”), a 95% confidence interval might tell us that the true prevalence is likely between 1.5% and 2.7%, offering a more complete picture of the estimate’s reliability.</p> <p>Mathematically, a 95% CI means that if we were to repeat the study many times under the same conditions, about 95% of the constructed intervals would contain the true proportion.</p> <hr/> <h3 id="why-accurate-interval-estimation-matters"><strong>Why Accurate Interval Estimation Matters</strong></h3> <p>Accurate estimation of confidence intervals is critically important in fields like <strong>epidemiology</strong> and <strong>microbiome research</strong>, where:</p> <ul> <li> <p><strong>Rare Disease Studies:</strong></p> <p>Small sample sizes and extremely low event rates are common. Overly narrow or inaccurate intervals can falsely suggest high precision, leading to misguided conclusions about disease risk, treatment efficacy, or healthcare burden.</p> </li> <li> <p><strong>Microbiome Studies:</strong></p> <p>The presence or abundance of microbial taxa can be rare or highly variable. Reliable intervals help interpret findings with appropriate caution, avoiding overinterpretation of noisy or sparse data.</p> </li> </ul> <p>Poorly constructed intervals—especially those that underestimate uncertainty—can mislead both researchers and policymakers, leading to flawed decision-making, missed treatment opportunities, or inappropriate resource allocation.</p> <p>Thus, selecting a method that maintains valid coverage while offering reasonable precision is not merely a technical preference; it is essential for trustworthy science.</p> <hr/> <h2 id="overview-of-the-methods"><strong>Overview of the Methods</strong></h2> <p>Building on insights from Brown et al., here’s a practical overview of the Wald, Wilson, and Jeffreys methods—covering key concepts, formulas, and typical use cases.</p> <h3 id="wald-method"><strong>Wald Method</strong></h3> <ul> <li> <p><strong>Formula:</strong></p> \[\hat{p} \pm z_{\alpha/2} \sqrt{\frac{\hat{p}(1 - \hat{p})}{n}}\] <p></p> </li> <li> <p><strong>Summary:</strong></p> <p>Simple and widely taught, but often inaccurate—especially with small samples or proportions near 0 or 1.</p> </li> <li> <p><strong>Limitations:</strong></p> <p>Poor coverage, unstable even with moderate to large samples; not recommended for rare event settings.</p> </li> </ul> <h3 id="wilson-method"><strong>Wilson Method</strong></h3> <ul> <li> <p><strong>Formula:</strong></p> \[\frac{\hat{p} + \frac{z^2}{2n} \pm z \sqrt{ \frac{\hat{p}(1 - \hat{p})}{n} + \frac{z^2}{4n^2} }}{1 + \frac{z^2}{n}}\] <p></p> </li> <li> <p><strong>Summary:</strong></p> <p>A corrected method that improves coverage and keeps intervals within [0,1].</p> </li> <li> <p><strong>Advantages:</strong></p> <p>Reliable even with small samples; recommended for real-world use over Wald.</p> </li> </ul> <h3 id="jeffreys-method"><strong>Jeffreys Method</strong></h3> <ul> <li> <p><strong>Formula:</strong></p> <p>Based on Beta posterior:</p> \[\text{Beta}(X+0.5, n-X+0.5)\] <p></p> </li> <li> <p><strong>Summary:</strong></p> <p>A Bayesian-based method with strong frequentist performance, especially for rare events.</p> </li> <li> <p><strong>Advantages:</strong></p> <p>Excellent coverage, stable near boundaries, highly suitable for small sample and rare event studies.</p> </li> </ul> <hr/> <h2 id="estimating-confidence-intervals-a-hands-on-example"><strong>Estimating Confidence Intervals: A Hands-On Example</strong></h2> <p>Before diving into large-scale simulations, let’s first walk through a simple example to see how the three methods—Wald, Wilson, and Jeffreys—work in practice.</p> <p>We’ll assume:</p> <ul> <li><strong>Sample size (n):</strong> 2000</li> <li><strong>Number of cases (x):</strong> 1</li> </ul> <p>Using Python’s statsmodels package, we can easily calculate the 95% confidence intervals for the proportion estimate using each method.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">statsmodels.stats.proportion</span> <span class="kn">import</span> <span class="n">proportion_confint</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Set the random seed for reproducibility
</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>

<span class="c1"># Define parameters
</span><span class="n">cases</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">2000</span>

<span class="c1"># 1. Wald method
</span><span class="n">ci_wald_estimate</span> <span class="o">=</span> <span class="nf">proportion_confint</span><span class="p">(</span><span class="n">cases</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="sh">'</span><span class="s">normal</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">95% Wald CI: [</span><span class="si">{</span><span class="n">ci_wald_estimate</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">ci_wald_estimate</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">]</span><span class="sh">'</span><span class="p">)</span> 

<span class="c1"># 2. Wilson method
</span><span class="n">ci_wilson_estimate</span> <span class="o">=</span> <span class="nf">proportion_confint</span><span class="p">(</span><span class="n">cases</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="sh">'</span><span class="s">wilson</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">95% Wilson CI: [</span><span class="si">{</span><span class="n">ci_wilson_estimate</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">ci_wilson_estimate</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">]</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># 3. Jeffreys method
</span><span class="n">ci_jeffreys_estimate</span> <span class="o">=</span> <span class="nf">proportion_confint</span><span class="p">(</span><span class="n">cases</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="sh">'</span><span class="s">jeffreys</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">95% Jeffreys CI: [</span><span class="si">{</span><span class="n">ci_jeffreys_estimate</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">ci_jeffreys_estimate</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">]</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <h3 id="output">Output:</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">95</span><span class="o">%</span> <span class="n">Wald</span> <span class="n">CI</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.0015</span><span class="p">]</span>
<span class="mi">95</span><span class="o">%</span> <span class="n">Wilson</span> <span class="n">CI</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.0028</span><span class="p">]</span>
<span class="mi">95</span><span class="o">%</span> <span class="n">Jeffreys</span> <span class="n">CI</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.0023</span><span class="p">]</span>
</code></pre></div></div> <h3 id="key-observations">Key Observations</h3> <ul> <li><strong>Wald method</strong> technically stays within the [0,1] range, but its lower bound rounds to zero, reflecting how poorly it behaves for very small proportions.</li> <li><strong>Wilson method</strong> corrects for this issue and offers a wider, safer interval that remains fully positive.</li> <li><strong>Jeffreys method</strong> also produces a valid and slightly narrower interval compared to Wilson, benefiting from Bayesian adjustments that naturally avoid the zero-boundary problem.</li> </ul> <p>This small example already shows a clear trend: for rare events (like in rare disease epidemiology), robust methods like Wilson and Jeffreys provide more reliable and interpretable intervals than the traditional Wald method.</p> <p>In the next section, we’ll benchmark these methods more systematically using simulated datasets across a range of sample sizes and true proportions.</p> <hr/> <h2 id="comparing-the-methods"><strong>Comparing the Methods</strong></h2> <p>To systematically evaluate the performance of the Wald, Wilson, and Jeffreys methods, we conducted a benchmark analysis using simulated data designed to mimic real-world rare disease studies.</p> <p>We intentionally defined:</p> <ul> <li><strong>Sample sizes</strong> ranging from 30 to 30,000, representing single-center cohorts up to large national registries.</li> <li><strong>True event proportions</strong> ranging from 0.0005 to 0.02, reflecting the extremely low rates typical in rare diseases.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define simulation parameters
</span><span class="n">sample_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">30000</span><span class="p">]</span>
<span class="n">true_proportion</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0005</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.005</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">]</span>
<span class="n">n_simulations</span> <span class="o">=</span> <span class="mi">1000</span>
</code></pre></div></div> <h3 id="performance-metrics"><strong>Performance Metrics</strong></h3> <p>We evaluated each method based on two key metrics:</p> <ul> <li><strong>Coverage Probability:</strong> How often the 95% confidence interval contains the true proportion (i.e., accuracy).</li> <li><strong>Average Confidence Interval Width:</strong> Reflecting the precision of the estimate (narrower is better, assuming coverage is adequate).</li> </ul> <p>This setup allows us to explore an important practical question:</p> <blockquote> <p>Which method strikes the best balance between accuracy and precision, especially under challenging rare disease conditions?</p> </blockquote> <hr/> <h3 id="coverage-probability"><strong>Coverage Probability</strong></h3> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/barplot_coverage_facet_tall.png" sizes="95vw"/> <img src="/assets/img/barplot_coverage_facet_tall.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>The figure above shows how the coverage probability varies across different sample sizes and true proportions for the three methods: Wald, Wilson, and Jeffreys. The dashed red line marks the target 95% coverage.</p> <h4 id="key-observations-1"><strong>Key Observations:</strong></h4> <ul> <li><strong>Jeffreys Method:</strong> <ul> <li>Jeffreys consistently maintains or exceeds 95% coverage across all combinations of sample sizes and true proportions.</li> <li>Even in very small samples (e.g., n=30) and extremely low proportions (e.g., 0.0005), Jeffreys remains robust.</li> <li>This highlights its strength for rare event scenarios where maintaining coverage is critical.</li> </ul> </li> <li><strong>Wilson Method:</strong> <ul> <li>Wilson performs comparably to Jeffreys in many scenarios, particularly as sample size increases.</li> <li>However, at very small sample sizes (e.g., n=30, 100) and very rare proportions (e.g., 0.0005–0.001), Wilson coverage sometimes drops slightly below 95%.</li> <li>It becomes increasingly reliable as sample size grows.</li> </ul> </li> <li><strong>Wald Method:</strong> <ul> <li>Wald shows poor coverage in almost all small-to-moderate sample size settings, often falling far below the 95% target.</li> <li>At very low true proportions (e.g., 0.005 or lower), even increasing sample size to 1000 does not fully rescue the Wald method.</li> <li>Only with very large sample sizes (n=30,000) and higher true proportions (e.g., 0.02) does Wald approach acceptable coverage.</li> </ul> </li> </ul> <h4 id="additional-nuances"><strong>Additional Nuances:</strong></h4> <ul> <li><strong>Effect of True Proportion:</strong> <ul> <li>Lower true proportions (e.g., 0.0005, 0.001) make it harder for methods to maintain ideal coverage, especially noticeable for Wald and, to a lesser extent, Wilson.</li> <li>As true proportion increases (e.g., 0.02), all methods tend to perform better, but differences still remain.</li> </ul> </li> <li><strong>Effect of Sample Size:</strong> <ul> <li>Larger sample sizes systematically improve coverage for all methods, but Wald still lags behind unless the sample size is very large.</li> </ul> </li> </ul> <h4 id="practical-implications"><strong>Practical Implications:</strong></h4> <ul> <li><strong>Jeffreys method</strong> is the most dependable choice for rare event settings where preserving nominal confidence levels is crucial.</li> <li><strong>Wilson method</strong> is a strong practical alternative, especially in moderate-to-large sample settings, offering better behavior than Wald.</li> <li><strong>Wald method</strong> should generally be avoided for rare disease applications unless working with extremely large cohorts and relatively higher event proportions.</li> </ul> <hr/> <h3 id="average-confidence-interval-width"><strong>Average Confidence Interval Width</strong></h3> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/barplot_precision_facet.png" sizes="95vw"/> <img src="/assets/img/barplot_precision_facet.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>95% CI width by methods controlling for the sample sizes and true proportions</p> <p>The figure above illustrates the average length of 95% confidence intervals across different sample sizes and true proportions, comparing the Wald, Wilson, and Jeffreys methods.</p> <h4 id="key-observations-2"><strong>Key Observations:</strong></h4> <ul> <li><strong>Wald Method:</strong> <ul> <li>Wald consistently produces the narrowest confidence intervals across all settings.</li> <li>However, given Wald’s poor coverage performance (as seen in the previous figure), these narrower intervals are misleading — they falsely suggest higher precision while actually underestimating the true uncertainty.</li> <li>Thus, the apparent precision of Wald should be interpreted with caution: it’s a <em>false sense</em> of accuracy.</li> </ul> </li> <li><strong>Wilson and Jeffreys Methods:</strong> <ul> <li>Wilson intervals are wider than Jeffreys across almost all settings, particularly noticeable when both sample size is small and true proportion is low.</li> <li>Jeffreys consistently achieves <strong>slightly narrower intervals</strong> than Wilson while still maintaining better or comparable coverage.</li> <li>This suggests Jeffreys method offers <strong>superior precision among the reliable methods</strong>.</li> </ul> </li> <li><strong>Effect of Sample Size:</strong> <ul> <li>As sample size increases, the width of the confidence intervals shrinks for all methods, as expected.</li> <li>When sample size reaches 30,000, all methods yield very narrow intervals, and differences between methods become minimal.</li> </ul> </li> <li><strong>Effect of True Proportion:</strong> <ul> <li>Larger true proportions (e.g., 0.02) generally lead to wider intervals compared to extremely low proportions (e.g., 0.0005), because variance is inherently higher when the probability is farther from 0 or 1.</li> </ul> </li> </ul> <hr/> <h2 id="practical-considerations"><strong>Practical Considerations</strong></h2> <p>When selecting a method to construct confidence intervals for proportions—especially in rare disease contexts—it is crucial to match the method to the study’s characteristics. Below are key guidelines and common pitfalls to watch for:</p> <p><strong>Choosing the Appropriate Method</strong></p> <table> <thead> <tr> <th><strong>Scenario</strong></th> <th><strong>Recommended Method</strong></th> <th><strong>Reason</strong></th> </tr> </thead> <tbody> <tr> <td>Very small sample size (n ≤ 100) and rare events</td> <td>Jeffreys</td> <td>Best coverage; robust even with extreme rarity</td> </tr> <tr> <td>Moderate sample size (n ~ 300–1000), low prevalence</td> <td>Jeffreys or Wilson</td> <td>Both offer reliable coverage; Jeffreys slightly narrower intervals</td> </tr> <tr> <td>Large sample size (n ≥ 10,000), moderate proportions (e.g., 0.01–0.02)</td> <td>Wilson or Jeffreys</td> <td>Minor differences; both safe choices</td> </tr> <tr> <td>Extremely large sample size (n ≥ 30,000) with not-so-rare events</td> <td>Wilson (or even Wald)</td> <td>Wald acceptable only under these conditions</td> </tr> </tbody> </table> <h3 id="potential-pitfalls-and-how-to-avoid-them"><strong>Potential Pitfalls and How to Avoid Them</strong></h3> <ul> <li><strong>Pitfall 1: Blindly Using the Wald Method</strong> <ul> <li><strong>Issue:</strong> Wald intervals can be too narrow and may miss the true proportion, especially with small samples or low event rates.</li> <li><strong>Solution:</strong> Prefer Wilson or Jeffreys methods for rare events or small sample studies.</li> </ul> </li> <li><strong>Pitfall 2: Overemphasizing Narrow Intervals</strong> <ul> <li><strong>Issue:</strong> A narrow interval is meaningless if coverage probability is poor (i.e., interval doesn’t capture the true proportion reliably).</li> <li><strong>Solution:</strong> Prioritize methods with strong coverage (like Jeffreys and Wilson) before focusing on interval width.</li> </ul> </li> <li><strong>Pitfall 3: Assuming “One Size Fits All”</strong> <ul> <li><strong>Issue:</strong> The best method depends on both sample size and true event rate.</li> <li><strong>Solution:</strong> Tailor your method choice based on study characteristics (refer to the table above).</li> </ul> </li> </ul> <hr/> <h2 id="conclusion"><strong>Conclusion</strong></h2> <p>Choosing the right method to estimate confidence intervals for proportions is critical—especially when studying rare events in small cohorts, as is often the case in rare disease research.</p> <p>This analysis highlights that:</p> <ul> <li><strong>Jeffreys method</strong> consistently delivers the best balance: reliable coverage and high precision across challenging scenarios.</li> <li><strong>Wilson method</strong> remains a strong, practical alternative, particularly when ease of interpretation or computational simplicity is needed.</li> <li><strong>Wald method</strong>, despite its simplicity, should be avoided unless working with extremely large samples and relatively high event rates.</li> </ul> <p>In rare disease studies where sample sizes are often small and events are extremely rare, robust methods like <strong>Jeffreys</strong> or <strong>Wilson</strong> are not just preferable—they are essential for trustworthy statistical inference.</p> <p>When precision matters, and lives or health policy decisions could depend on these estimates, <strong>choose your method thoughtfully</strong>.</p> <p>Good science begins with good measurement.</p> <hr/> <h2 id="putting-it-into-practice"><strong>Putting It Into Practice</strong></h2> <p>To help you apply these methods in your own work, I’ve prepared clean, reusable Python code that:</p> <ul> <li>Calculates Wald, Wilson, and Jeffreys confidence intervals</li> <li>Benchmarks performance across different sample sizes and true proportions</li> <li>Summarizes key metrics like coverage probability and interval width</li> </ul> <p>You can easily adapt the code to:</p> <ul> <li>Analyze your own datasets</li> <li>Test other confidence levels (e.g., 90%, 99%)</li> <li>Extend the benchmarking to new methods</li> </ul> <p>Whether you’re working on rare disease epidemiology, microbiome studies, or any research involving proportions, these code snippets are ready to plug into your analysis.</p> <p>Access the full code <a href="https://github.com/davidzhao1015/interval-estimate-benchmark/blob/main/compare-interval-est-methods.py">here</a>.</p>]]></content><author><name></name></author><category term="statistics"/><category term="confidence-intervals,"/><category term="statistics,"/><category term="proportions,"/><category term="methods-comparison"/><summary type="html"><![CDATA[How much can you trust a number when dealing with rare events? In statistics, it’s not just about getting an estimate — it’s about knowing how uncertain that estimate really is.]]></summary></entry><entry><title type="html">Modeling Diagnostic Delays in Rare Disease: A Survival Analysis Case Study in Python</title><link href="https://davidzhao1015.github.io/blog/2025/delay-diganosis-survival-analysis/" rel="alternate" type="text/html" title="Modeling Diagnostic Delays in Rare Disease: A Survival Analysis Case Study in Python"/><published>2025-03-03T00:00:00+00:00</published><updated>2025-03-03T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2025/delay-diganosis-survival-analysis</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2025/delay-diganosis-survival-analysis/"><![CDATA[<h1 id="introduction-why-survival-analysis">Introduction: Why Survival Analysis?</h1> <p>Rare diseases often come with a hidden burden—the <strong>delay in diagnosis</strong>. For patients with <strong>acid sphingomyelinase deficiency (ASMD)</strong>, a genetic disorder with highly variable onset and progression, the diagnostic journey can be long and uncertain. Those with <strong>chronic neurovisceral ASMD (NPD A/B)</strong> and <strong>chronic visceral ASMD (NPD B)</strong> may face <strong>years</strong> before receiving a definitive diagnosis, impacting their treatment options and long-term health outcomes.</p> <p>But how long do these delays typically last? Can we <strong>quantify</strong> the diagnostic journey and predict the likelihood of diagnosis at different time points?</p> <p>This is where <strong>survival analysis</strong> comes in. By modeling <strong>time-to-diagnosis</strong>, we can estimate <strong>median diagnostic timelines</strong>, compare different patient subgroups, and even predict when a patient is most likely to receive a diagnosis based on their clinical history. In this article, I’ll walk through the <strong>fundamentals of survival analysis</strong> and share how I applied it to ASMD patient data using Python.</p> <p>You can explore the full <a href="https://github.com/davidzhao1015/survival-analysis-case-example/blob/main/survival-analysis-ASMD-example.ipynb">notebook</a> and <a href="https://github.com/davidzhao1015/survival-analysis-case-example/blob/main/age-at-diagnosis-asmd.xlsx">dataset</a> to try the analysis yourself 🚀</p> <h2 id="my-learning-journey-in-survival-analysis">My Learning Journey in Survival Analysis</h2> <h3 id="why-i-started-exploring-survival-analysis">Why I started exploring survival analysis</h3> <p>I became interested in survival analysis because it answers a critical question: <strong>How likely is an event (such as diagnosis) to occur at a given time point, considering different covariates?</strong></p> <p>This type of analysis is widely used in: • <strong>Disease progression modeling</strong> – Understanding how long it takes for a condition to worsen. • <strong>Precision medicine</strong> – Predicting patient outcomes based on medical history. • <strong>Clinical trials</strong> – Estimating time-to-recovery, disease recurrence, or survival rates.</p> <p>Unlike conventional regression models, <strong>survival analysis can handle censored data</strong>—cases where the event of interest hasn’t occurred yet by the time of data collection. This makes it a powerful tool in both medical research and epidemiology.</p> <h3 id="key-takeaways-from-my-learning-process">Key takeaways from my learning process</h3> <p>As I explored survival analysis, I focused on three major areas:</p> <ol> <li><strong>Understanding the statistical foundations</strong> <ul> <li>The concept of <strong>censored data</strong> and why it’s important.</li> <li>Common survival models: <strong>Kaplan-Meier curves, parametric regression models, and Cox proportional hazards models</strong>.</li> <li><strong>Model selection</strong> using AIC to determine the best fit.</li> </ul> </li> <li><strong>Implementing survival analysis in Python</strong> <ul> <li>Learning by reproducing examples from <strong>tutorials and documentation</strong>.</li> <li>Using the <strong>lifelines</strong> library for survival modeling and visualization.</li> <li>Writing clean, reusable code for different types of survival models.</li> </ul> </li> <li><strong>Applying knowledge to a real-world case study</strong> <ul> <li>Choosing the right statistical models: <strong>non-parametric, semi-parametric, or parametric</strong>.</li> <li>Interpreting model coefficients <strong>in the context of a medical study</strong>.</li> <li>Creating <strong>effective and insightful plots</strong> to communicate results.</li> </ul> </li> </ol> <h3 id="how-this-method-applies-beyond-asmd">How this method applies beyond ASMD</h3> <p>While this case study focuses on <strong>time-to-diagnosis in ASMD</strong>, the approach can be generalized to many other scenarios:</p> <ul> <li>The <strong>analysis workflow</strong> can be applied to different time-to-event studies.</li> <li>The <strong>parametric models</strong> used in survival analysis can be adjusted for other medical research questions.</li> <li>The <strong>Python code</strong> can be repurposed for different datasets with minimal modifications.</li> </ul> <h3 id="what-this-post-covers">What this post covers</h3> <p>In this blog post, I’ll share:</p> <p>✅ A <strong>beginner-friendly introduction</strong> to survival analysis.</p> <p>✅ <strong>Helpful resources</strong> for learning survival analysis and Python implementation.</p> <p>✅ A <strong>step-by-step case study</strong> using ASMD diagnosis data.</p> <p>🚀 For the full code and interactive analysis, check out my <a href="https://github.com/davidzhao1015/survival-analysis-case-example/blob/main/survival-analysis-ASMD-example.ipynb">Jupyter Notebook</a></p> <p>Let’s dive in!</p> <h1 id="fundamentals-of-survival-analysis">Fundamentals of Survival Analysis</h1> <h2 id="what-is-survival-analysis">What is survival analysis?</h2> <p>Survival analysis is a statistical approach used to model <strong>time-to-event data</strong>—where the outcome of interest is the time until an event occurs. This event could be <strong>time to disease relapse</strong>, <strong>time until a diagnosis</strong>, or even <strong>time to treatment failure</strong>. Despite the name, survival analysis isn’t just about survival—it’s about understanding when an event is likely to happen.</p> <p>One of the key advantages of survival analysis is its ability to handle <strong>censored data</strong>—cases where:</p> <ul> <li><strong>Left censoring</strong> occurs when the event happened before the study began, but the exact time is unknown.</li> <li><strong>Right censoring</strong> happens when the event has not yet occurred by the end of the study period.</li> </ul> <p>Traditional regression models struggle with these challenges, but survival models are specifically designed to <strong>account for incomplete data</strong>, making them essential in epidemiology, clinical research, and beyond.</p> <h2 id="key-concepts-explained-simply">Key concepts explained simply</h2> <p><strong>Censoring</strong>: Not every subject in a study experiences the event of interest. Censoring allows us to <strong>include incomplete observations</strong>, making survival analysis more robust than conventional regression methods.</p> <p><strong>Kaplan-Meier Curve</strong>: A <strong>Kaplan-Meier curve</strong> provides a visual representation of survival probabilities over time. It plots:</p> <ul> <li><strong>Time (X-axis)</strong> vs. <strong>Probability of event-free survival (Y-axis)</strong>.</li> <li>It helps estimate how likely the event (e.g., diagnosis) will occur by a given time.</li> </ul> <p><strong>Log-Rank Test</strong>: A statistical test used to <strong>compare survival distributions</strong> between two or more independent groups. For example, it helps determine whether patients with different ASMD subtypes experience significantly different diagnostic delays.</p> <p><strong>Cox Proportional Hazards Model</strong>: A regression model that evaluates the <strong>effect of multiple variables</strong> on survival time. It helps answer questions like:</p> <ul> <li>Do certain clinical factors increase or decrease the likelihood of earlier diagnosis?</li> <li>How do different ASMD subtypes compare in terms of diagnostic delay?</li> </ul> <h2 id="resources-i-found-helpful">Resources I found helpful</h2> <p>If you’re new to survival analysis, these resources helped me grasp the fundamentals and apply them in Python:</p> <p>📺 <strong>Video Tutorial Series:</strong> <a href="https://www.youtube.com/watch?v=Wo9RNcHM_bs">Survival Analysis by DATAtab</a></p> <p>📖 <strong>Python Documentation:</strong> <a href="https://lifelines.readthedocs.io/">Lifelines Survival Analysis Library</a></p> <h1 id="asmd-case-study-analyzing-time-to-diagnosis">ASMD Case Study: Analyzing Time-to-Diagnosis</h1> <h2 id="understanding-the-dataset">Understanding the dataset</h2> <p>For this analysis, the age-at-diagnosis data derived from a <a href="https://www.sciencedirect.com/science/article/pii/S1096719216300580">scientific publication</a> by Cassiman et al. (2016) on ASMD patient outcomes.</p> <p>Each row in the dataset represents an <strong>individual patient</strong>, with the following key variables:</p> <ul> <li><strong>Time since birth (years):</strong> Age at which an event (diagnosis) occurs.</li> <li><strong>Diagnosis (event):</strong> Binary indicator of whether the patient was diagnosed (<strong>1 = diagnosed, 0 = censored</strong>).</li> <li><strong>AB subtype:</strong> Indicates disease type (<strong>0 = Type B, 1 = Type AB</strong>).</li> <li><strong>CH subtype:</strong> Indicates age group (<strong>0 = Child, 1 = Adult</strong>).</li> </ul> <p>Since some patients remained undiagnosed at the time of data collection, <strong>censored data</strong> is present—making survival analysis an ideal approach for estimating diagnostic timelines.</p> <p>👉 Next, we apply survival analysis techniques to uncover diagnostic trends and patterns.</p> <h2 id="why-survival-analysis-fits-this-problem">Why survival analysis fits this problem</h2> <p>One of the key challenges in studying <strong>diagnostic delays in ASMD</strong> is that different patient subgroups likely experience <strong>varying timelines</strong> before receiving a diagnosis. Some individuals may be diagnosed early, while others remain undiagnosed for an extended period. This variability makes it difficult to analyze the data using conventional statistical methods.</p> <p>Additionally, not all patients in the dataset have received a diagnosis at the time of study. These <strong>“still undiagnosed”</strong> cases are what we call <strong>censored data</strong>—we know that their diagnosis hasn’t happened yet, but we don’t know exactly when it will occur. Traditional regression models struggle to handle this type of incomplete data, which is where <strong>survival analysis excels</strong>.</p> <ul> <li><strong>Captures time-to-event data:</strong> Instead of treating diagnosis as a simple yes/no outcome, survival analysis allows us to model <strong>when</strong> the diagnosis occurs.</li> <li><strong>Handles censored data effectively:</strong> Patients who haven’t been diagnosed yet aren’t excluded from the analysis—they are incorporated appropriately using survival functions.</li> <li><strong>Compares different patient subgroups:</strong> By applying Kaplan-Meier curves and Cox regression models, we can compare <strong>diagnostic delays</strong> between ASMD subtypes.</li> </ul> <p>By leveraging survival analysis, we can <strong>estimate the probability of diagnosis over time</strong>, understand which patients face the longest delays, and potentially identify clinical factors that contribute to earlier or later diagnosis.</p> <h2 id="applying-survival-analysis-to-asmd-data">Applying Survival Analysis to ASMD Data</h2> <h3 id="step-by-step-survial-analysis-in-python">Step-by-Step Survial Analysis in Python</h3> <p><strong>🗃️ Data Loading and Exploration</strong></p> <ul> <li>Loaded age-at-diagnosis data from Excel using pandas.</li> <li>Each row represented a patient, with columns for age at diagnosis, event occurrence (diagnosed or not), and ASMD subtype indicators (AB, CH).</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">diagnosis_age_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_excel</span><span class="p">(</span><span class="sh">"</span><span class="s">age-at-diagnosis-asmd.xlsx</span><span class="sh">"</span><span class="p">)</span>
<span class="n">diagnosis_age_df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div> <table> <thead> <tr> <th>Time since birth (year)</th> <th>Diagnosis</th> <th>AB</th> <th>CH</th> </tr> </thead> <tbody> <tr> <td>0.10</td> <td>1</td> <td>1</td> <td>0</td> </tr> <tr> <td>0.28</td> <td>1</td> <td>1</td> <td>0</td> </tr> <tr> <td>0.36</td> <td>1</td> <td>1</td> <td>0</td> </tr> <tr> <td>0.45</td> <td>1</td> <td>1</td> <td>0</td> </tr> <tr> <td>0.45</td> <td>1</td> <td>1</td> <td>0</td> </tr> </tbody> </table> <p>📊 <strong>Kaplan-Meier Survival Curves</strong></p> <ul> <li>Used lifelines’ KaplanMeierFitter to visualize survival (i.e., undiagnosed) probability over time.</li> <li>Stratified patients by subtype: <ul> <li>Type B Adult: AB = 0, CH = 0</li> <li>Type B Child: AB = 0, CH = 1</li> <li>Type AB: AB = 1</li> </ul> </li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">lifelines</span> <span class="kn">import</span> <span class="n">KaplanMeierFitter</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">kmf</span> <span class="o">=</span> <span class="nc">KaplanMeierFitter</span><span class="p">()</span>

<span class="n">T</span> <span class="o">=</span> <span class="n">diagnosis_age_df</span><span class="p">[</span><span class="sh">"</span><span class="s">Time since birth (year)</span><span class="sh">"</span><span class="p">]</span>
<span class="n">E</span> <span class="o">=</span> <span class="n">diagnosis_age_df</span><span class="p">[</span><span class="sh">"</span><span class="s">Diagnosis</span><span class="sh">"</span><span class="p">]</span>

<span class="n">type_b_adult</span> <span class="o">=</span> <span class="p">(</span><span class="n">diagnosis_age_df</span><span class="p">[</span><span class="sh">"</span><span class="s">AB</span><span class="sh">"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">diagnosis_age_df</span><span class="p">[</span><span class="sh">"</span><span class="s">CH</span><span class="sh">"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">type_b_child</span> <span class="o">=</span> <span class="p">(</span><span class="n">diagnosis_age_df</span><span class="p">[</span><span class="sh">"</span><span class="s">AB</span><span class="sh">"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">diagnosis_age_df</span><span class="p">[</span><span class="sh">"</span><span class="s">CH</span><span class="sh">"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">type_ab</span> <span class="o">=</span> <span class="p">(</span><span class="n">diagnosis_age_df</span><span class="p">[</span><span class="sh">"</span><span class="s">AB</span><span class="sh">"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">()</span>

<span class="n">kmf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">type_b_adult</span><span class="p">],</span> <span class="n">E</span><span class="p">[</span><span class="n">type_b_adult</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Type B Adult</span><span class="sh">"</span><span class="p">).</span><span class="nf">plot_survival_function</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">kmf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">type_b_child</span><span class="p">],</span> <span class="n">E</span><span class="p">[</span><span class="n">type_b_child</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Type B Child</span><span class="sh">"</span><span class="p">).</span><span class="nf">plot_survival_function</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">kmf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">type_ab</span><span class="p">],</span> <span class="n">E</span><span class="p">[</span><span class="n">type_ab</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Type AB</span><span class="sh">"</span><span class="p">).</span><span class="nf">plot_survival_function</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Kaplan-Meier Curve of Age at Diagnosis by Subtypes</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Time since birth (year)</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Survival Probability</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/survival_KM_curve.png" sizes="95vw"/> <img src="/assets/img/survival_KM_curve.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Figure 1. The Kaplan-Meier plot for the three subtypes (Type B Adult, Type B Child, Type AB)</p> <p>Key observations:</p> <ul> <li>Type AB and Type B Child are diagnosed early: <ul> <li>Steep drop in survival curves before age 5</li> <li>Most diagnoses occur in early childhood</li> </ul> </li> <li>Type B Adult experiences delayed diagnosis: <ul> <li>Gradual decline in survival curve over several decades</li> <li>Many are diagnosed in middle age or later</li> </ul> </li> <li>Subtypes show clear separation: <ul> <li>Distinct survival curves across groups</li> <li>Statistically significant differences confirmed by log-rank test</li> </ul> </li> </ul> <p>📈 <strong>Statistical Comparison</strong></p> <p>Conducted a log-rank test to compare survival curves between subtypes and assess whether diagnostic delays differed significantly.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">lifelines</span> <span class="kn">import</span> <span class="n">WeibullFitter</span><span class="p">,</span> <span class="n">ExponentialFitter</span><span class="p">,</span> <span class="n">LogNormalFitter</span>

<span class="n">models</span> <span class="o">=</span> <span class="p">[</span>
    <span class="nc">WeibullFitter</span><span class="p">().</span><span class="nf">fit</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">E</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Weibull</span><span class="sh">"</span><span class="p">),</span>
    <span class="nc">ExponentialFitter</span><span class="p">().</span><span class="nf">fit</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">E</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Exponential</span><span class="sh">"</span><span class="p">),</span>
    <span class="nc">LogNormalFitter</span><span class="p">().</span><span class="nf">fit</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">E</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Log-Normal</span><span class="sh">"</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">()</span>

<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">plot_survival_function</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">aic</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">AIC_</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mf">0.8</span> <span class="o">-</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">models</span><span class="p">.</span><span class="nf">index</span><span class="p">(</span><span class="n">model</span><span class="p">),</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">_label</span><span class="si">}</span><span class="s"> AIC: </span><span class="si">{</span><span class="n">aic</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Model Comparison by AIC</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Time since birth (year)</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Survival Probability</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/survival_AIC.png" sizes="95vw"/> <img src="/assets/img/survival_AIC.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Figure 2. The survival functions overlaid with AIC values.</p> <p>🧮 <strong>Parametric Model Fitting</strong></p> <ul> <li>Fit various models including Weibull, Log-Normal, Exponential, Log-Logistic, and Generalized Gamma.</li> <li>Compared model fit using AIC (Akaike Information Criterion).</li> <li>Selected Log-Normal AFT as the best-performing model.</li> </ul> <p>🔍 <strong>Prediction by Subtype</strong></p> <ul> <li>Applied the best model to predict survival (undiagnosed) probability curves for each subtype across a 0–100 year timespan.</li> <li>Visualized predictions with subtype-specific curves—helpful for clinicians and researchers interpreting diagnosis timelines.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">lifelines</span> <span class="kn">import</span> <span class="n">LogNormalAFTFitter</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">lognorm_aft</span> <span class="o">=</span> <span class="nc">LogNormalAFTFitter</span><span class="p">()</span>
<span class="n">lognorm_aft</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">diagnosis_age_df</span><span class="p">,</span> <span class="n">duration_col</span><span class="o">=</span><span class="sh">"</span><span class="s">Time since birth (year)</span><span class="sh">"</span><span class="p">,</span> <span class="n">event_col</span><span class="o">=</span><span class="sh">"</span><span class="s">Diagnosis</span><span class="sh">"</span><span class="p">)</span>

<span class="n">new_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">"</span><span class="s">AB</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="sh">"</span><span class="s">CH</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]})</span>
<span class="n">times</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="n">survival_probs</span> <span class="o">=</span> <span class="n">lognorm_aft</span><span class="p">.</span><span class="nf">predict_survival_function</span><span class="p">(</span><span class="n">new_data</span><span class="p">,</span> <span class="n">times</span><span class="o">=</span><span class="n">times</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">survival_probs</span><span class="p">.</span><span class="nf">plot</span><span class="p">()</span>

<span class="n">ax</span><span class="p">.</span><span class="nf">legend</span><span class="p">([</span><span class="sh">"</span><span class="s">Type B Adult</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Type B Child</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Type AB</span><span class="sh">"</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Predicted Survival Curve – Log-Normal AFT</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Time since birth (year)</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Survival Probability</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/survival_prediction.png" sizes="95vw"/> <img src="/assets/img/survival_prediction.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Figure 3. The predicted survival function showing how diagnosis probability changes by subtype.</p> <h2 id="findings--implications">Findings &amp; Implications</h2> <p>This analysis showed clear differences in time-to-diagnosis across ASMD subtypes. Kaplan-Meier curves revealed that Type AB and childhood-onset Type B patients were diagnosed earlier, while adult-onset Type B cases experienced the longest delays. The Log-Normal AFT model provided the best fit for modeling these differences and enabled prediction of diagnosis probabilities by subtype.</p> <p>While this example focuses on ASMD, the same survival modeling techniques can be adapted to other rare diseases to quantify diagnostic delays, compare patient subgroups, or support screening research. The methods demonstrated here—handling censored data, fitting multiple survival models, and interpreting time-to-event probabilities—are broadly useful in medical data analysis.</p> <h1 id="4-key-learning--takeaways">4. Key learning &amp; takeaways</h1> <p>Here are some key lessons I gained while working through this survival analysis project:</p> <p>What I Learned About Survival Analysis</p> <ul> <li>There are three major categories of survival models: <ul> <li>Non-parametric (e.g., Kaplan-Meier): flexible, assumption-free, and good for descriptive analysis</li> <li>Parametric (e.g., Weibull, Log-Normal): useful for prediction and interpretation when assumptions are met</li> <li>Semi-parametric (e.g., Cox regression): interpretable and flexible for covariates, without requiring full distributional assumptions</li> </ul> </li> <li>AIC (Akaike Information Criterion) is a valuable tool for selecting the best-fit model among several options.</li> <li>When visualizing survival curves with lifelines, it’s helpful to: <ul> <li>Include 95% confidence intervals to convey uncertainty</li> <li>Display at-risk tables to show how many events (diagnoses or censored cases) are observed over time</li> </ul> </li> </ul> <p>Practical Challenges and How I Overcame Them</p> <ul> <li>Survival analysis differs conceptually from typical regression. Grasping its unique assumptions and knowing how to interpret coefficients was essential to making sense of the results.</li> <li>Implementing survival models in Python involved trial and error. I relied on: <ul> <li>lifelines documentation</li> <li>Reproducing basic examples</li> <li>Experimentation and patience when adapting methods to real-world data, which is often messier than toy examples</li> </ul> </li> </ul> <p>Tips for Beginners</p> <ul> <li>Start with the fundamentals: understand basic statistical concepts and what survival analysis is trying to solve.</li> <li>Gain working knowledge of key survival algorithms (Kaplan-Meier, Cox, Log-Normal, etc.).</li> <li>Be patient—coding survival models takes attention to detail and a willingness to try, tweak, and retry. Real-world datasets rarely behave like textbook examples, so iteration is part of the process.</li> </ul>]]></content><author><name></name></author><category term="statistics"/><category term="survival-analysis;"/><category term="rare-disease;"/><category term="ASMD;"/><category term="python"/><summary type="html"><![CDATA[Introduction: Why Survival Analysis?]]></summary></entry><entry><title type="html">From Microbiology to Bioinformatics: How Embracing New Skills Transformed My Career</title><link href="https://davidzhao1015.github.io/blog/2025/my-career-journey/" rel="alternate" type="text/html" title="From Microbiology to Bioinformatics: How Embracing New Skills Transformed My Career"/><published>2025-02-22T00:00:00+00:00</published><updated>2025-02-22T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2025/my-career-journey</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2025/my-career-journey/"><![CDATA[<div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/career-transform-infographics.png" sizes="95vw"/> <img src="/assets/img/career-transform-infographics.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h2 id="introduction"><strong>Introduction</strong></h2> <p>Have you ever considered how embracing a new skill set could transform your career?</p> <p>Transitioning from one field to another can be daunting, but it’s also an incredible opportunity to reinvent yourself and explore uncharted territory.</p> <p>For me, the journey from microbiology to bioinformatics has been profoundly transformative, teaching me the power of blending experimental and computational sciences to tackle complex biological challenges.</p> <h2 id="from-microbiology-to-bioinformatics-a-natural-evolution"><strong>From Microbiology to Bioinformatics: A Natural Evolution</strong></h2> <p>My career began with a PhD in Food Science, focusing on the genomic and phenotypic adaptation of <em>Lactobacillus reuteri</em> in fermented foods like sourdough. Early on, I was captivated by how microorganisms influence health and nutrition.</p> <p>This fascination deepened during my PhD, where collaborative comparative genomics projects highlighted the transformative role of bioinformatics in modern research. These experiences sowed the seeds for my eventual shift to computational biology.</p> <h2 id="embracing-change-the-catalyst-for-my-transition"><strong>Embracing Change: The Catalyst for My Transition</strong></h2> <p>A career break for family care and the constraints of the pandemic pushed me to re-evaluate my professional goals. These circumstances highlighted the growing importance of bioinformatics skills, motivating me to embrace this field fully.</p> <p>The transition felt daunting, but it also presented an exciting opportunity to expand my expertise and tackle new challenges.</p> <h2 id="building-skills-through-a-structured-approach"><strong>Building Skills Through a Structured Approach</strong></h2> <p>To bridge the gap, I followed a three-step learning process that I still recommend:</p> <p>1️⃣ <strong>Build the Basics</strong>: I used platforms like Coursera and DataCamp to gain foundational knowledge in R programming and machine learning.</p> <p>2️⃣ <strong>Practice Through Projects</strong>: Guided mini-projects allowed me to apply my skills to real-world problems.</p> <p>3️⃣ <strong>Real-World Applications</strong>: Working on clinical and microbiome datasets helped me tackle unstructured challenges while honing my programming expertise.</p> <p>These steps empowered me to work in areas like microbial genomics, software development for metabolomics, and statistical modeling of complex datasets.</p> <h2 id="bridging-disciplines-where-the-magic-happens"><strong>Bridging Disciplines: Where the Magic Happens</strong></h2> <p>What distinguishes my journey is the ability to bridge microbiology and bioinformatics.</p> <p>My background in experimental microbiology allows me to understand raw data, such as sequencing or qPCR outputs, while my computational skills enable me to derive actionable insights.</p> <p>This interdisciplinary approach has been pivotal in interpreting infant microbiome data and tackling complex research questions.</p> <h2 id="lessons-learned-and-advice-for-aspiring-bioinformaticians"><strong>Lessons Learned and Advice for Aspiring Bioinformaticians</strong></h2> <p>Transitioning to a new field requires resilience and adaptability. Here are my key lessons from this journey:</p> <p>🔑 Start small and maintain consistency in your learning.</p> <p>🔑 Utilize online resources and workshops to gain practical skills.</p> <p>🔑 Embrace your unique background as a strength; diversity in expertise drives innovation.</p> <p>For anyone interested in bioinformatics, this is an exciting time. Regardless of whether you come from a biological, statistical, or computational background, your skills are valuable.</p> <p>The key is to embrace continuous learning and foster interdisciplinary collaboration.</p> <h2 id="what-about-you"><strong>What About You?</strong></h2> <p>Have you ever transitioned to a new field? How did you overcome challenges and embrace new opportunities?</p> <p>I’d love to hear about your journey—please share your experiences in the comments!</p>]]></content><author><name></name></author><category term="career development"/><category term="bionformatics,"/><category term="microbiology,"/><category term="career-transition,"/><category term="learning-journey"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Beyond Heatmaps: Mapping Two Variables with Plotly in Public Health</title><link href="https://davidzhao1015.github.io/blog/2025/plotly-maps-public-health/" rel="alternate" type="text/html" title="Beyond Heatmaps: Mapping Two Variables with Plotly in Public Health"/><published>2025-01-27T00:00:00+00:00</published><updated>2025-01-27T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2025/plotly-maps-public-health</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2025/plotly-maps-public-health/"><![CDATA[<h2 id="background">Background</h2> <p>In public health and epidemiology, data visualization isn’t just about aesthetics—it’s about clarity, impact, and storytelling. Choropleth maps, which color-code geographic areas based on variable intensity, are a go-to tool for illustrating spatial trends in disease burden, health behaviors, or population risk factors.</p> <p>But what if you want to compare <strong>two variables simultaneously</strong> on the same geographic map?</p> <p>This is a common challenge in health data storytelling. For instance, imagine you’re studying the <strong>distribution of a dietary habit</strong> and the <strong>associated disease outcomes</strong>—how do you present this relationship clearly and intuitively?</p> <p><strong>💡 Innovation Highlight</strong> Overlay a <strong>bubble map</strong> on top of a choropleth map. The base layer (choropleth) provides a regional context for one variable, while the overlaid bubbles show the intensity of another, allowing for quick visual comparisons.</p> <p>This post shows how to combine two variables on a single map using a dual-layer approach — choropleth for spatial intensity + bubble size for a second variable. It’s a simple but powerful storytelling technique.</p> <h3 id="-real-world-example">📌 Real-World Example</h3> <p>In 2020, a <a href="https://www.medrxiv.org/content/10.1101/2020.07.06.20147025v1">preprint</a> suggested that <strong>fermented vegetable consumption</strong> might be inversely associated with <strong>COVID-19 mortality</strong> in Europe—even after adjusting for confounding factors. I wanted to explore that hypothesis using public data and an interactive map.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/snapshort_final_map.png" sizes="95vw"/> <img src="/assets/img/snapshort_final_map.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>This interactive map overlays fermented food intake (bubbles) on COVID-19 death rates (color). Scroll down to learn how it’s built.</p> <hr/> <h2 id="-quick-start">📦 <strong>Quick Start</strong></h2> <ol> <li>Install dependencies</li> <li>Download the dataset (<a href="https://github.com/davidzhao1015/plotly-bubble-choropleth/tree/main/input_csv">link</a>)</li> <li>Run the notebook <a href="https://mybinder.org/v2/gh/davidzhao1015/plotly-bubble-choropleth/main?urlpath=%2Fdoc%2Ftree%2Finteractive-map-covid-fermented-food_v3.ipynb"><img src="https://mybinder.org/badge_logo.svg" alt="Binder"/></a></li> <li>Explore the interactive map</li> </ol> <hr/> <h2 id="what-youll-need-to-recreate-this-map"><strong>What You’ll Need to Recreate This Map</strong></h2> <p>To recreate the interactive map and plots in this post, you’ll need a few Python packages commonly used in data science:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Core data handling
</span><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="c1"># Interactive map visualization
</span><span class="kn">import</span> <span class="n">plotly.express</span> <span class="k">as</span> <span class="n">px</span> <span class="c1"># Creating choropleth and scatter_geo maps
</span><span class="kn">import</span> <span class="n">plotly.graph_objects</span> <span class="k">as</span> <span class="n">go</span> <span class="c1"># Overlaying plot layers and annotation
</span>
<span class="c1"># For geospatial data 
</span><span class="kn">import</span> <span class="n">requests</span> <span class="c1"># Fetching GeoJSON data from remote URL 
</span><span class="kn">import</span> <span class="n">json</span> <span class="c1"># Parsing JSON data
</span><span class="kn">import</span> <span class="n">pycountry</span> <span class="c1"># Mapping country names to ISO alpha-3 codes
</span>
<span class="c1"># For exporting maps
</span><span class="kn">import</span> <span class="n">plotly.io</span> <span class="k">as</span> <span class="n">pio</span> <span class="c1"># Exporting Plotly figures as HTML
</span><span class="kn">import</span> <span class="n">kaleido</span>  <span class="c1"># Saving Plotly maps as static images (optional)
</span></code></pre></div></div> <p>💡 <strong>Tip:</strong> This tutorial uses Python packages like pandas, plotly, and pycountry. You can install all dependencies by running:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt
</code></pre></div></div> <p>Or check out the full notebook on <a href="https://github.com/yourusername/repo-name">GitHub</a> to explore the code and interactive map.</p> <h3 id="why-plotlyexpress"><strong>Why plotly.express?</strong></h3> <p>For this project, I used plotly.express to create <strong>interactive choropleth and bubble maps</strong>. Unlike traditional plotting libraries like matplotlib, plotly.express lets you explore maps by hovering, zooming, and clicking — all right inside your browser or Jupyter Notebook.</p> <p>It’s a powerful yet beginner-friendly way to bring geographic data to life.</p> <p>The official tutorials for choropleth are <a href="https://plotly.com/python/choropleth-maps/">here</a>, and for bubble map is <a href="https://plotly.com/python/bubble-maps/">here</a>.</p> <hr/> <h2 id="preparing-the-epidemiological-data"><strong>Preparing the Epidemiological Data</strong></h2> <p>Before visualizing our map, we first need to get the data into the right shape. In this case, we’re combining datasets on:</p> <ul> <li>COVID-19 mortality rates (per million people)</li> <li>Fermented food consumption (e.g. sauerkraut, pickled vegetables)</li> </ul> <p>Let’s walk through the key steps.</p> <p><strong>📂 1. Load Data from CSV</strong></p> <p>We read the data using pandas — a Python package that makes working with tables easy:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># Load COVID-19 mortality rate dataset
</span><span class="n">COVID_death_pop_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">COVID_mortality_rate.csv</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Load fermented vegetables dataset
</span><span class="n">avg_consumption_country</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">fermented_food_consumption.csv</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p><strong>🔄 2. Merge Datasets</strong></p> <p>We then renamed some columns for clarity and merged additional information, like ISO codes and population:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Merge fermented vegetable data with COVID-19 mortality rate data
</span><span class="n">eu_avg_consumption_COVID_death_pop_df</span> <span class="o">=</span> <span class="n">eu_avg_consumption_country</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">COVID_death_pop_df</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="sh">'</span><span class="s">Country</span><span class="sh">'</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Inspect first rows in the merged dataset
</span><span class="n">eu_avg_consumption_COVID_death_pop_df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>   
</code></pre></div></div> <p>The frist rows in the merged dataset:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">Country</span>	<span class="n">Average</span> <span class="n">Consumption</span>	<span class="n">Year</span>	<span class="n">Population</span>	<span class="n">Deaths</span>	<span class="n">Death</span> <span class="n">Rate</span>
<span class="mi">0</span>	<span class="n">France</span>	<span class="mf">1.135681</span>	<span class="mi">2020</span>	<span class="mf">67473651.0</span>	<span class="mf">9284524.0</span>	<span class="mf">0.137602</span>
<span class="mi">1</span>	<span class="n">France</span>	<span class="mf">1.135681</span>	<span class="mi">2021</span>	<span class="mf">67728568.0</span>	<span class="mf">38470807.0</span>	<span class="mf">0.568014</span>
<span class="mi">2</span>	<span class="n">France</span>	<span class="mf">1.135681</span>	<span class="mi">2022</span>	<span class="mf">67957053.0</span>	<span class="mf">54424558.0</span>	<span class="mf">0.800867</span>
<span class="mi">3</span>	<span class="n">France</span>	<span class="mf">1.135681</span>	<span class="mi">2023</span>	<span class="mf">68172977.0</span>	<span class="mf">11230468.0</span>	<span class="mf">0.164735</span>
<span class="mi">4</span>	<span class="n">Czechia</span>	<span class="mf">5.578666</span>	<span class="mi">2020</span>	<span class="mf">10693939.0</span>	<span class="mf">600899.0</span>	<span class="mf">0.056191</span>

</code></pre></div></div> <p><strong>🌍 3. Add Country Codes for Mapping</strong></p> <p>Using pycountry, we convert country names to ISO 3-letter codes so they can be matched to the map:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pycountry</span>

<span class="c1"># List of EU countries
</span><span class="n">eu_countries</span> <span class="o">=</span> <span class="n">eu_avg_consumption_COVID_death_pop_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Country</span><span class="sh">'</span><span class="p">].</span><span class="nf">unique</span><span class="p">().</span><span class="nf">tolist</span><span class="p">()</span>   

<span class="c1"># Dictionary of country names and their corresponding alpha_3 codes
</span><span class="n">country_alpha3</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">country</span> <span class="ow">in</span> <span class="n">eu_countries</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">country_data</span> <span class="o">=</span> <span class="n">pycountry</span><span class="p">.</span><span class="n">countries</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">country</span><span class="p">)</span>
        <span class="c1"># print(country_data.alpha_3)
</span>        <span class="n">country_alpha3</span><span class="p">[</span><span class="n">country</span><span class="p">]</span> <span class="o">=</span> <span class="n">country_data</span><span class="p">.</span><span class="n">alpha_3</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">country</span><span class="si">}</span><span class="s"> not found</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <hr/> <h2 id="how-do-we-get-map-data-in-python"><strong>How Do We Get Map Data in Python?</strong></h2> <p>To create interactive maps, we need two things:</p> <ol> <li>A base map that knows the shape of each country (like a digital atlas 📐)</li> <li>A way to match our data (e.g. COVID deaths, food consumption) to the correct country</li> </ol> <p>In this project, we used two helpful Python tools to achieve that:</p> <p><strong>🧩 1. requests + json: Loading the World Map</strong></p> <p>We downloaded a GeoJSON file — which is a special file format that stores map shapes — using Python’s requests module:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">requests</span>
<span class="kn">import</span> <span class="n">json</span>

<span class="n">url</span> <span class="o">=</span> <span class="sh">'</span><span class="s">https://raw.githubusercontent.com/johan/world.geo.json/master/countries.geo.json</span><span class="sh">'</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">geojson_data</span> <span class="o">=</span> <span class="n">response</span><span class="p">.</span><span class="nf">json</span><span class="p">()</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Filter the geojson for EU 
</span><span class="n">eu_geojson</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">type</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">FeatureCollection</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">features</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span>
        <span class="n">feature</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">geojson_data</span><span class="p">[</span><span class="sh">"</span><span class="s">features</span><span class="sh">"</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">feature</span><span class="p">[</span><span class="sh">"</span><span class="s">properties</span><span class="sh">"</span><span class="p">][</span><span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">]</span> <span class="ow">in</span> <span class="n">targeted_countries</span>
    <span class="p">]</span>
<span class="p">}</span>
</code></pre></div></div> <p><strong>🏷️ 2. pycountry: Matching Country Names to ISO Codes</strong></p> <p>Our datasets (like food consumption) use country names such as “Germany” or “Vietnam”. But map files often use short codes like “DEU” or “VNM”.</p> <p>We used the pycountry module to automatically convert country names into standardized ISO codes:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pycountry</span>

<span class="c1"># List of EU countries
</span><span class="n">eu_countries</span> <span class="o">=</span> <span class="n">eu_avg_consumption_COVID_death_pop_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Country</span><span class="sh">'</span><span class="p">].</span><span class="nf">unique</span><span class="p">().</span><span class="nf">tolist</span><span class="p">()</span>   

<span class="c1"># Dictionary of country names and their corresponding alpha_3 codes
</span><span class="n">country_alpha3</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">country</span> <span class="ow">in</span> <span class="n">eu_countries</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">country_data</span> <span class="o">=</span> <span class="n">pycountry</span><span class="p">.</span><span class="n">countries</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">country</span><span class="p">)</span>
        <span class="c1"># print(country_data.alpha_3)
</span>        <span class="n">country_alpha3</span><span class="p">[</span><span class="n">country</span><span class="p">]</span> <span class="o">=</span> <span class="n">country_data</span><span class="p">.</span><span class="n">alpha_3</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">country</span><span class="si">}</span><span class="s"> not found</span><span class="sh">"</span><span class="p">)</span>
        
 <span class="nf">print</span><span class="p">(</span><span class="n">country_alpha3</span><span class="p">)</span>
</code></pre></div></div> <p>Together, these two steps make it possible to visualize complex health and nutrition data on an interactive world map!</p> <hr/> <h2 id="choropleth-map--background-color-by-average-fermented-vegetables-consumption"><strong>Choropleth Map – Background Color by Average Fermented Vegetables Consumption</strong></h2> <p>This map shows average fermented vegetable consumption by country, shaded by intensity:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create a Choropleth map (for country colors) based on fermented vegetable consumption
</span><span class="n">food_map</span> <span class="o">=</span> <span class="n">px</span><span class="p">.</span><span class="nf">choropleth</span><span class="p">(</span>
    <span class="n">data_map_2020</span><span class="p">,</span>
    <span class="n">locations</span><span class="o">=</span><span class="sh">"</span><span class="s">iso_alpha</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">Average Consumption</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">hover_name</span><span class="o">=</span><span class="sh">"</span><span class="s">Country</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">scope</span><span class="o">=</span><span class="sh">"</span><span class="s">europe</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">projection</span><span class="o">=</span><span class="sh">"</span><span class="s">natural earth</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">color_continuous_scale</span><span class="o">=</span><span class="sh">'</span><span class="s">Plasma</span><span class="sh">'</span>
<span class="p">)</span>
</code></pre></div></div> <p>🖼️ ⬇️ Example Output</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/snapshot_choropleth_map_fermented_food.png" sizes="95vw"/> <img src="/assets/img/snapshot_choropleth_map_fermented_food.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h2 id="bubble-overlay--covid-19-mortality-rates"><strong>Bubble Overlay – COVID-19 mortality rates</strong></h2> <p>We then add circle markers to indicate COVID-19 mortality rates per country. Bigger bubbles = more intake.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">plotly.graph_objects</span> <span class="k">as</span> <span class="n">go</span>

<span class="n">bubble_map</span> <span class="o">=</span> <span class="n">px</span><span class="p">.</span><span class="nf">scatter_geo</span><span class="p">(</span><span class="n">data_map_2020</span><span class="p">,</span>
                            <span class="n">locations</span><span class="o">=</span><span class="sh">"</span><span class="s">iso_alpha</span><span class="sh">"</span><span class="p">,</span>
                            <span class="n">hover_name</span><span class="o">=</span><span class="sh">"</span><span class="s">Country</span><span class="sh">"</span><span class="p">,</span>
                            <span class="n">size</span><span class="o">=</span><span class="sh">"</span><span class="s">Death Rate</span><span class="sh">"</span><span class="p">,</span>
                            <span class="n">scope</span><span class="o">=</span><span class="sh">"</span><span class="s">europe</span><span class="sh">"</span><span class="p">,</span>
                            <span class="n">projection</span><span class="o">=</span><span class="sh">"</span><span class="s">natural earth</span><span class="sh">"</span><span class="p">,</span>
                            <span class="n">opacity</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="c1"># Set opacity level for better visibility
</span>                            <span class="n">size_max</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
                            <span class="n">color_continuous_scale</span><span class="o">=</span><span class="n">px</span><span class="p">.</span><span class="n">colors</span><span class="p">.</span><span class="n">sequential</span><span class="p">.</span><span class="n">Plasma</span><span class="p">)</span>
</code></pre></div></div> <p>🖼️ ⬇️ Example Output:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/snapshot_bubble_map_COVID.png" sizes="95vw"/> <img src="/assets/img/snapshot_bubble_map_COVID.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h2 id="combine-both-layers"><strong>Combine Both Layers</strong></h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Combine both layers
</span><span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="p">.</span><span class="nc">Figure</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">food_map</span><span class="p">.</span><span class="n">data</span> <span class="o">+</span> <span class="n">bubble_map</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
</code></pre></div></div> <p><strong>Why These Steps Matter</strong></p> <p>This combination allows us to visualize two variables on the same map:</p> <ul> <li>Red shading = how much fermented food people eat</li> <li>Bubble size = how bad COVID-19 outcomes were</li> </ul> <p>It opens up exploratory insights like:</p> <blockquote> <p>“Do countries with more fermented vegetable consumption have lower COVID-19 death rates?”</p> </blockquote> <p>This dual-layer approach makes it intuitive to compare variables geographically.</p> <h3 id="fine-tuning-the-map-for-clarity--style"><strong>Fine-Tuning the Map for Clarity &amp; Style</strong></h3> <p>Once we’ve layered the choropleth and bubbles, we fine-tune the map to make it easier to understand and more visually polished.</p> <p>Here are some key adjustments made in the notebook:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Improve layout
</span><span class="n">fig</span><span class="p">.</span><span class="nf">update_geos</span><span class="p">(</span>
    <span class="n">scope</span><span class="o">=</span><span class="sh">"</span><span class="s">europe</span><span class="sh">"</span><span class="p">,</span> <span class="c1"># Only show European countries
</span>    <span class="n">showcoastlines</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
    <span class="n">showland</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
    <span class="n">landcolor</span><span class="o">=</span><span class="sh">"</span><span class="s">lightgray</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">projection_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">update_layout</span><span class="p">(</span>
    <span class="n">coloraxis_colorbar_title</span><span class="o">=</span><span class="sh">"</span><span class="s">Fermented Vegetable Consumption</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">coloraxis_colorscale</span><span class="o">=</span><span class="sh">"</span><span class="s">RdYlBu</span><span class="sh">"</span> <span class="p">,</span> <span class="c1"># Change color scale
</span>    <span class="n">width</span><span class="o">=</span><span class="mi">1200</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">coloraxis_colorbar</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span>
        <span class="n">orientation</span><span class="o">=</span><span class="sh">"</span><span class="s">h</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Set colorbar horizontal
</span>        <span class="n">title</span><span class="o">=</span><span class="sh">"</span><span class="s">Fermented Vegetable Consumption</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">title_side</span><span class="o">=</span><span class="sh">"</span><span class="s">top</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">title_font_size</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">thickness</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>  <span class="c1"># Adjust colorbar width
</span>        <span class="nb">len</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>  <span class="c1"># Adjust colorbar height (relative size)
</span>        <span class="n">x</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>  <span class="c1"># Move colorbar horizontally
</span>        <span class="n">y</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>  <span class="c1"># Move colorbar vertically
</span>    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">update_layout</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span>
        <span class="n">text</span><span class="o">=</span><span class="sh">"</span><span class="s">Fermented Vegetable Consumption and COVID-19 Death Rate in Europe (2020)</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">x</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>  <span class="c1"># Center the title
</span>        <span class="n">y</span><span class="o">=</span><span class="mf">0.98</span><span class="p">,</span>  <span class="c1"># Position it above the colorbar
</span>        <span class="n">xanchor</span><span class="o">=</span><span class="sh">"</span><span class="s">center</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Ensure proper centering
</span>        <span class="n">yanchor</span><span class="o">=</span><span class="sh">"</span><span class="s">top</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Anchor at the top
</span>        <span class="n">font</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span>
            <span class="n">size</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span>  <span class="c1"># Increase font size for better readability
</span>            <span class="n">family</span><span class="o">=</span><span class="sh">"</span><span class="s">Arial, sans-serif</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Use a professional font
</span>            <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">black</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Set color (adjust if needed)
</span>            <span class="n">weight</span><span class="o">=</span><span class="sh">"</span><span class="s">bold</span><span class="sh">"</span>  <span class="c1"># Bolden the title (alternative: use "&lt;b&gt;Title&lt;/b&gt;" in text)
</span>        <span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">update_layout</span><span class="p">(</span>
    <span class="n">coloraxis_colorbar</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span>
        <span class="n">orientation</span><span class="o">=</span><span class="sh">"</span><span class="s">h</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Horizontal colorbar
</span>        <span class="n">x</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">y</span><span class="o">=-</span><span class="mf">0.15</span><span class="p">,</span>  <span class="c1"># Move below the map
</span>        <span class="nb">len</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">thickness</span><span class="o">=</span><span class="mi">10</span>
    <span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div> <p><strong>These tweaks:</strong></p> <ul> <li>Geographic layout</li> <li>Colorbar customization</li> <li>Title configuration</li> <li>Additional colorbar adjustment</li> </ul> <h2 id="annotate-country-names-to-the-map"><strong>Annotate country names to the map</strong></h2> <p>To make the map more professional-looking and easier to interpret, we apply layout settings:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># Create the DataFrame
</span><span class="n">country_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span>
    <span class="sh">"</span><span class="s">Country</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="sh">"</span><span class="s">Austria</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Belgium</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Bulgaria</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Bosnia and Herzegovina</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Germany</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Estonia</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Finland</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">France</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">United Kingdom</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Greece</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Croatia</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Hungary</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Latvia</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Montenegro</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Netherlands</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Poland</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Portugal</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Romania</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Slovenia</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Sweden</span><span class="sh">"</span><span class="p">],</span>
    <span class="sh">"</span><span class="s">ISO3</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="sh">"</span><span class="s">AUT</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">BEL</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">BGR</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">BIH</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">DEU</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">EST</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">FIN</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">FRA</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">GBR</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">GRC</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">HRV</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">HUN</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">LVA</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">MNE</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">NLD</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">POL</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">PRT</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">ROU</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">SVN</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">SWE</span><span class="sh">"</span><span class="p">],</span>
    <span class="sh">"</span><span class="s">Lat</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mf">47.5162</span><span class="p">,</span> <span class="mf">50.5039</span><span class="p">,</span> <span class="mf">42.7339</span><span class="p">,</span> <span class="mf">43.9159</span><span class="p">,</span> <span class="mf">51.1657</span><span class="p">,</span> <span class="mf">58.5953</span><span class="p">,</span> <span class="mf">61.9241</span><span class="p">,</span> <span class="mf">46.6034</span><span class="p">,</span> <span class="mf">55.3781</span><span class="p">,</span> <span class="mf">39.0742</span><span class="p">,</span> <span class="mf">45.1</span><span class="p">,</span> <span class="mf">47.1625</span><span class="p">,</span> <span class="mf">56.8796</span><span class="p">,</span> <span class="mf">42.7087</span><span class="p">,</span> <span class="mf">52.1326</span><span class="p">,</span> <span class="mf">51.9194</span><span class="p">,</span> <span class="mf">39.3999</span><span class="p">,</span> <span class="mf">45.9432</span><span class="p">,</span> <span class="mf">46.1512</span><span class="p">,</span> <span class="mf">60.1282</span><span class="p">],</span>
    <span class="sh">"</span><span class="s">Lon</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mf">14.5501</span><span class="p">,</span> <span class="mf">4.4699</span><span class="p">,</span> <span class="mf">25.4858</span><span class="p">,</span> <span class="mf">17.6791</span><span class="p">,</span> <span class="mf">10.4515</span><span class="p">,</span> <span class="mf">25.0136</span><span class="p">,</span> <span class="mf">25.7482</span><span class="p">,</span> <span class="mf">1.8883</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.4360</span><span class="p">,</span> <span class="mf">21.8243</span><span class="p">,</span> <span class="mf">15.2</span><span class="p">,</span> <span class="mf">19.5033</span><span class="p">,</span> <span class="mf">24.6032</span><span class="p">,</span> <span class="mf">19.3744</span><span class="p">,</span> <span class="mf">5.2913</span><span class="p">,</span> <span class="mf">19.1451</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.2245</span><span class="p">,</span> <span class="mf">24.9668</span><span class="p">,</span> <span class="mf">14.9955</span><span class="p">,</span> <span class="mf">18.6435</span><span class="p">]</span>
<span class="p">})</span>

<span class="kn">import</span> <span class="n">plotly.graph_objects</span> <span class="k">as</span> <span class="n">go</span>

<span class="c1"># Create the country label layer (scattergeo)
</span><span class="n">country_labels</span> <span class="o">=</span> <span class="n">go</span><span class="p">.</span><span class="nc">Scattergeo</span><span class="p">(</span>
    <span class="n">locationmode</span><span class="o">=</span><span class="sh">"</span><span class="s">ISO-3</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">lon</span><span class="o">=</span><span class="n">country_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Lon</span><span class="sh">"</span><span class="p">],</span>
    <span class="n">lat</span><span class="o">=</span><span class="n">country_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Lat</span><span class="sh">"</span><span class="p">],</span>
    <span class="n">text</span><span class="o">=</span><span class="n">country_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Country</span><span class="sh">"</span><span class="p">],</span>  <span class="c1"># Display country names
</span>    <span class="n">mode</span><span class="o">=</span><span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Only text (no markers)
</span>    <span class="n">textfont</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">black</span><span class="sh">"</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="sh">"</span><span class="s">Arial</span><span class="sh">"</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="sh">"</span><span class="s">bold</span><span class="sh">"</span><span class="p">),</span>  <span class="c1"># Adjust font
</span>    <span class="n">textposition</span><span class="o">=</span><span class="sh">"</span><span class="s">top center</span><span class="sh">"</span><span class="p">,</span>  
    <span class="n">showlegend</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span>

<span class="c1"># Add to your existing Plotly figure
</span><span class="n">fig</span><span class="p">.</span><span class="nf">add_trace</span><span class="p">(</span><span class="n">country_labels</span><span class="p">)</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/snapshot_added_country_names.png" sizes="95vw"/> <img src="/assets/img/snapshot_added_country_names.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Explore the full interactive version on <a href="https://davidzhao1015.github.io/plotly-bubble-choropleth/">GitHub</a>.</p> <h2 id="exporting-the-map"><strong>Exporting the Map</strong></h2> <p>Want to save your plot as an image or HTML? Use:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pio</span><span class="p">.</span><span class="nf">write_image</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="sh">'</span><span class="s">fermented_vegetable_consumption_COVID_death_rate_europe_2020.png</span><span class="sh">'</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="sh">'</span><span class="s">png</span><span class="sh">'</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">1200</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>                  <span class="c1"># Save as PNG
</span>
<span class="n">pio</span><span class="p">.</span><span class="nf">write_html</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="nb">file</span><span class="o">=</span><span class="sh">'</span><span class="s">index.html</span><span class="sh">'</span><span class="p">,</span> <span class="n">auto_open</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>       <span class="c1"># Save as interactive webpage
</span></code></pre></div></div> <p>This step is great for sharing visuals in presentations or embedding interactive plots on your own blog or website.</p> <p>Together, these finishing touches elevate your map from “functional” to “insightful and polished.” They also make the visualization more friendly to readers who are new to data exploration or unfamiliar with the dataset.</p> <hr/> <h2 id="what-does-the-map-tell-us"><strong>What Does the Map Tell Us?</strong></h2> <p>As we zoom into this interactive map, a few patterns emerge:</p> <ul> <li>Countries like Hungary and Romania — with relatively high intake of fermented vegetables — show noticeably lower COVID-19 mortality in this 2020 dataset.</li> <li>On the other hand, countries with lower fermented food consumption, such as the UK or Belgium, show higher death rates.</li> <li>While this map doesn’t prove causality, it does support the hypothesis from [the original study] that dietary habits might influence immune resilience — a fascinating intersection of public health and nutrition.</li> </ul> <p>Of course, many other factors (like healthcare infrastructure or testing policies) may also be at play. But that’s the beauty of this kind of map — it opens up questions and encourages deeper exploration.</p>]]></content><author><name></name></author><category term="data-visualization;"/><category term="epidemiology;"/><category term="plolty;"/><category term="choropleth-map;"/><category term="fermented-food;"/><category term="COVID-19"/><summary type="html"><![CDATA[Background In public health and epidemiology, data visualization isn’t just about aesthetics—it’s about clarity, impact, and storytelling. Choropleth maps, which color-code geographic areas based on variable intensity, are a go-to tool for illustrating spatial trends in disease burden, health behaviors, or population risk factors.]]></summary></entry><entry><title type="html">How to Import Excel Files in Python</title><link href="https://davidzhao1015.github.io/blog/2024/import-spreadsheet-python/" rel="alternate" type="text/html" title="How to Import Excel Files in Python"/><published>2024-12-24T00:00:00+00:00</published><updated>2024-12-24T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2024/import-spreadsheet-python</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2024/import-spreadsheet-python/"><![CDATA[<h2 id="purpose">Purpose</h2> <p>Ever struggled to import Excel data into Python for analysis? This post will guide you step-by-step on how to use <strong>Pandas</strong> to handle Excel files effortlessly, even for complex datasets.</p> <hr/> <h2 id="excel-data-essentials">Excel Data Essentials</h2> <p>Excel is a go-to tool for managing and analyzing data. Let’s refresh some key terms to ensure smooth communication:</p> <ul> <li><strong>Workbook</strong>: The entire Excel file.</li> <li><strong>Worksheet</strong>: Individual sheets (or tabs) within the workbook.</li> <li><strong>Header</strong>: Labels at the top defining columns (e.g., A, B, C).</li> <li><strong>Cells</strong>: Data units located at row-column intersections, like A1.</li> </ul> <p>If these terms feel familiar, great! If not, think of them as the building blocks for working with Excel in Python.</p> <hr/> <h2 id="everyday-functionality-importing-excel-files-in-pandas">Everyday Functionality: Importing Excel Files in Pandas</h2> <h3 id="real-world-scenario-metabolomics-data">Real-World Scenario: Metabolomics Data</h3> <p>Imagine you’re analyzing LC/MS metabolomics data from animal samples, with additional metadata. This was my experience at the metabolomics research center, where I worked with a dataset containing:</p> <ol> <li><strong>Biomarker Assay Worksheet</strong>: Measurements for over 100 metabolites.</li> </ol> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/snapshot_biomarker_worksheet.png" sizes="95vw"/> <img src="/assets/img/snapshot_biomarker_worksheet.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <ol> <li><strong>Metadata Worksheet</strong>: Sample information.</li> </ol> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/snapshot_metadata_worksheet.png" sizes="95vw"/> <img src="/assets/img/snapshot_metadata_worksheet.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <hr/> <h2 id="step-by-step-guide">Step-by-Step Guide</h2> <h3 id="1-import-multiple-worksheets">1. Import Multiple Worksheets</h3> <p>Start by loading a specific worksheet while skipping descriptive rows:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span> 

<span class="n">df_biomarker_assay</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_excel</span><span class="p">(</span>
    <span class="sh">'</span><span class="s">example-biomarker-assay.xlsx</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">sheet_name</span><span class="o">=</span><span class="sh">'</span><span class="s">Biomarker assay</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">skiprows</span><span class="o">=</span><span class="mi">11</span>
<span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; df_biomarker_assay.head()
  Sample ID  Creatinine    Glycine     Alanine     Serine Histamine  ...  C16:1OH     C16OH     C18:2     C18:1       C18   C18:1OH
0  LODs(uM)    0.443131   0.859107    0.340909   0.042433  0.013605  ...  0.04906  0.042617  0.058089  0.041081  0.023651  0.056784
1         1   14.600000  51.600000  264.000000  65.100000     &lt; LOD  ...    &lt; LOD     &lt; LOD     &lt; LOD     &lt; LOD     &lt; LOD     &lt; LOD
2         2   14.000000  98.100000  338.000000  87.000000     &lt; LOD  ...    &lt; LOD     &lt; LOD     &lt; LOD     &lt; LOD     &lt; LOD     &lt; LOD
3         3   11.200000  92.000000  329.000000  74.500000     &lt; LOD  ...    &lt; LOD     &lt; LOD     &lt; LOD  0.045089     &lt; LOD     &lt; LOD
4         4   11.600000  77.500000  200.000000  62.400000     &lt; LOD  ...    &lt; LOD     &lt; LOD     &lt; LOD   0.04134   0.02505     &lt; LOD

[5 rows x 144 columns]
</code></pre></div></div> <h3 id="2-select-specific-rows-and-columns">2. Select Specific Rows and Columns</h3> <p>To limit the data to a manageable range:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_biomarker_assay_selected</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_excel</span><span class="p">(</span>
    <span class="sh">'</span><span class="s">example-biomarker-assay.xlsx</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">sheet_name</span><span class="o">=</span><span class="sh">'</span><span class="s">Biomarker assay</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">skiprows</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span>
    <span class="n">usecols</span><span class="o">=</span><span class="sh">'</span><span class="s">A:EN</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">nrows</span><span class="o">=</span><span class="mi">31</span>
<span class="p">)</span>
</code></pre></div></div> <h3 id="3-verify-non-empty-rows-and-columns">3. Verify Non-Empty Rows and Columns</h3> <p>Check for completeness in the imported data:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nonempty_rows</span> <span class="o">=</span> <span class="n">df_biomarker_assay_selected</span><span class="p">.</span><span class="nf">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">all</span><span class="sh">'</span><span class="p">).</span><span class="n">index</span><span class="p">.</span><span class="nf">tolist</span><span class="p">()</span>
<span class="n">count_rows</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">nonempty_rows</span><span class="p">)</span>

<span class="n">nonempty_cols</span> <span class="o">=</span> <span class="n">df_biomarker_assay_selected</span><span class="p">.</span><span class="nf">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">all</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">columns</span><span class="p">.</span><span class="nf">tolist</span><span class="p">()</span>
<span class="n">count_cols</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">nonempty_cols</span><span class="p">)</span>
</code></pre></div></div> <h3 id="4-validate-data-import">4. Validate Data Import</h3> <p>Inspect the first and last rows of your dataset to verify that the import matches the source.</p> <hr/> <h2 id="special-use-cases-with-pandas">Special Use Cases with Pandas</h2> <h3 id="1-formula-generated-data">1. Formula-Generated Data</h3> <p>Excel formulas, like those generating the column in the <strong>Metadata</strong> worksheet, retain their calculated values when imported:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_metadata</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_excel</span><span class="p">(</span><span class="sh">'</span><span class="s">example-biomarker-assay.xlsx</span><span class="sh">'</span><span class="p">,</span> <span class="n">sheet_name</span><span class="o">=</span><span class="sh">'</span><span class="s">Metadata</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <h3 id="2-filtered-data">2. Filtered Data</h3> <p>Filtered tables (e.g., showing only filtered rows in Excel) are fully imported, including the hidden rows.</p> <h3 id="3-binary-workbook-files-xlsb">3. Binary Workbook Files (.xlsb)</h3> <p>For <code class="language-plaintext highlighter-rouge">.xlsb</code> files, use the <code class="language-plaintext highlighter-rouge">pyxlsb</code> library to read the data.</p> <hr/> <h2 id="best-practices-for-importing-excel-files">Best Practices for Importing Excel Files</h2> <p>To streamline your workflow, follow these tips:</p> <ul> <li>Use <code class="language-plaintext highlighter-rouge">skiprows</code> to ignore unnecessary content.</li> <li>Specify <code class="language-plaintext highlighter-rouge">usecols</code> and <code class="language-plaintext highlighter-rouge">nrows</code> for better performance.</li> <li>Confirm data integrity by checking non-empty rows and columns.</li> <li>Choose the correct engine for specialized file formats (e.g., <code class="language-plaintext highlighter-rouge">.xlsb</code>).</li> </ul> <p>By following these steps, you’ll efficiently prepare your data for analysis, no matter the complexity of the Excel files.</p> <hr/> <h2 id="final-thoughts">Final Thoughts</h2> <p>Importing Excel files in Python doesn’t have to be daunting. With a clear process, even the most complex datasets become manageable. Try these steps on your own files, and let me know how it goes!</p> <p>For any questions or advanced use cases, feel free to drop a comment or reach out. Happy coding!</p> <hr/> <h2 id="references">References</h2> <ul> <li><a href="https://support.microsoft.com/en-us/office/file-formats-that-are-supported-in-excel-0943ff2c-6014-4e8d-aaea-b83d51d46247">Excel file format</a></li> <li><a href="https://support.microsoft.com/en-us/office/overview-of-excel-tables-7ab0bb7d-3a9e-4b56-a3c9-6c94334e492c">Overview of Excel table</a></li> <li><a href="https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html">Pandas API doc</a></li> </ul>]]></content><author><name></name></author><category term="statistics"/><category term="python;"/><category term="spreadsheet;"/><category term="data-analysis"/><summary type="html"><![CDATA[Purpose Ever struggled to import Excel data into Python for analysis? This post will guide you step-by-step on how to use Pandas to handle Excel files effortlessly, even for complex datasets.]]></summary></entry><entry><title type="html">Top R Packages for GO Enrichment Analysis: topGO vs globaltest Explained</title><link href="https://davidzhao1015.github.io/blog/2024/go-enrichment/" rel="alternate" type="text/html" title="Top R Packages for GO Enrichment Analysis: topGO vs globaltest Explained"/><published>2024-11-22T00:00:00+00:00</published><updated>2024-11-22T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2024/go-enrichment</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2024/go-enrichment/"><![CDATA[<h2 id="1-introduction"><strong>1. Introduction</strong></h2> <p>Gene Ontology (GO) enrichment analysis is a cornerstone of gene expression studies. It helps researchers identify biological processes, molecular functions, and cellular components that are overrepresented in a set of genes, offering insights into the underlying biology. Several statistical methods can be used for GO enrichment analysis, including Fisher’s exact test, the Kolmogorov-Smirnov test, and the global test.</p> <p>This article aims to simplify the process of choosing an appropriate R package for GO enrichment analysis by introducing two popular Bioconductor packages: <strong>topGO</strong> and <strong>globaltest</strong>. While both packages are widely used, their distinct statistical methods and outputs can make it challenging to choose the right tool for your study. This guide compares these packages, highlights their differences, and provides practical examples to help researchers, especially those with busy lab schedules, efficiently integrate GO analysis into their workflows.</p> <h2 id="2-overview-of-bioconductor-packages"><strong>2. Overview of Bioconductor Packages</strong></h2> <p><strong>topGO</strong></p> <p><strong>topGO</strong> is a versatile R package for GO enrichment analysis, well-suited for identifying specific GO terms that are enriched among differentially expressed genes. It primarily employs statistical methods like Fisher’s exact test and the Kolmogorov-Smirnov test, making it a reliable choice for detecting overrepresentation in gene lists. With its robust functionality and detailed documentation, topGO is a go-to tool for exploring gene-level associations in various biological datasets.</p> <p><strong>globaltest</strong></p> <p><strong>globaltest</strong> takes a different approach by assessing whether specific GO terms are associated with clinical outcomes or other continuous variables. It uses the global test methodology, which evaluates associations at a more holistic level compared to gene-specific tests. This makes it particularly valuable for studies where the research question involves linking GO terms to phenotypic data, such as disease progression or treatment response.</p> <p><strong>Key Differences in Statistical Approaches</strong></p> <p>Both packages are highly ranked in the Bioconductor repository due to their active maintenance and comprehensive documentation. However, their underlying statistical methods set them apart:</p> <p>• <strong>topGO</strong>: Uses Fisher’s exact test or the Kolmogorov-Smirnov test to test the null hypothesis that no specific GO terms are enriched in a set of genes.</p> <p>• <strong>globaltest</strong>: Employs the global test to evaluate the null hypothesis that no association exists between a set of genes and a clinical outcome or phenotype.</p> <p><strong>Use Case Comparison</strong></p> <p>• <strong>topGO</strong> is ideal for researchers seeking to uncover enriched biological processes in differentially expressed genes.</p> <p>• <strong>globaltest</strong> is better suited for studies focused on linking GO terms to clinical or phenotypic outcomes, such as identifying functional pathways associated with disease progression.</p> <p>By understanding these distinctions, researchers can choose the package that best aligns with their study objectives.</p> <h2 id="3-setting-environment"><strong>3. Setting Environment</strong></h2> <p>Setting up includes ensuring the required packages are installed and loaded.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Install globaltest Biocondcutor package</span><span class="w">
</span><span class="n">BiocManager</span><span class="o">::</span><span class="n">install</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s2">"globaltest"</span><span class="p">,</span><span class="w"> </span><span class="s2">"topGO"</span><span class="p">,</span><span class="w"> </span><span class="s2">"golubEsets"</span><span class="p">,</span><span class="w"> </span><span class="s2">"vsn"</span><span class="p">,</span><span class="w"> </span><span class="s2">"hu6800.db"</span><span class="p">,</span><span class="w"> </span><span class="s2">"GO.db"</span><span class="p">,</span><span class="w"> </span><span class="s2">"AnnotationDbi"</span><span class="p">,</span><span class="w"> </span><span class="s2">"annotate"</span><span class="p">,</span><span class="w"> </span><span class="s2">"topGO"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ALL"</span><span class="p">,</span><span class="w"> </span><span class="s2">"Biobase"</span><span class="p">,</span><span class="w"> </span><span class="s2">"limma"</span><span class="p">))</span><span class="w">  

</span><span class="c1"># Load the globaltest package</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">topGO</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">globaltest</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">golubEsets</span><span class="p">)</span><span class="w"> 
</span><span class="n">library</span><span class="p">(</span><span class="n">vsn</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">hu6800.db</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">AnnotationDbi</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">methods</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">annotate</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">limma</span><span class="p">)</span><span class="w"> 
</span><span class="n">library</span><span class="p">(</span><span class="n">dplyr</span><span class="p">)</span><span class="w">
</span></code></pre></div></div> <h2 id="4-data-prepration"><strong>4. Data Prepration</strong></h2> <p>Data preprocessing and normalization.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load the Golub training data set consisting of 7129 genes and 38 samples (27 ALL and 11 AML)</span><span class="w">
</span><span class="n">data</span><span class="p">(</span><span class="n">Golub_Train</span><span class="p">,</span><span class="w"> </span><span class="n">package</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"golubEsets"</span><span class="p">)</span><span class="w">  

</span><span class="c1">## Normalize the data using the VSN package</span><span class="w">
</span><span class="n">Golub_Train_VSN</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">vsn</span><span class="o">::</span><span class="n">vsn2</span><span class="p">(</span><span class="n">exprs</span><span class="p">(</span><span class="n">Golub_Train</span><span class="p">))</span><span class="w"> 
</span></code></pre></div></div> <p>Gene expression data before the normalization process:</p> <p>A matrix: 5 x 10 of type int</p> <table> <thead> <tr> <th></th> <th>1</th> <th>2</th> <th>3</th> <th>4</th> <th>5</th> <th>6</th> <th>7</th> <th>8</th> <th>9</th> <th>10</th> </tr> </thead> <tbody> <tr> <td>AFFX-BioB-5_at</td> <td>-214</td> <td>-139</td> <td>-76</td> <td>-135</td> <td>-106</td> <td>-138</td> <td>-72</td> <td>-413</td> <td>5</td> <td>-88</td> </tr> <tr> <td>AFFX-BioB-M_at</td> <td>-153</td> <td>-73</td> <td>-49</td> <td>-114</td> <td>-125</td> <td>-85</td> <td>-144</td> <td>-260</td> <td>-127</td> <td>-105</td> </tr> <tr> <td>AFFX-BioB-3_at</td> <td>-58</td> <td>-1</td> <td>-307</td> <td>265</td> <td>-76</td> <td>215</td> <td>238</td> <td>7</td> <td>106</td> <td>42</td> </tr> <tr> <td>AFFX-BioC-5_at</td> <td>88</td> <td>283</td> <td>309</td> <td>12</td> <td>168</td> <td>71</td> <td>55</td> <td>-2</td> <td>268</td> <td>219</td> </tr> <tr> <td>AFFX-BioC-3_at</td> <td>-295</td> <td>-264</td> <td>-376</td> <td>-419</td> <td>-230</td> <td>-272</td> <td>-399</td> <td>-541</td> <td>-210</td> <td>-178</td> </tr> </tbody> </table> <p>Gene expression data after the normalization process:</p> <p>A matrix: 5 x 10 of type dbl</p> <table> <thead> <tr> <th></th> <th>1</th> <th>2</th> <th>3</th> <th>4</th> <th>5</th> <th>6</th> <th>7</th> <th>8</th> <th>9</th> <th>10</th> </tr> </thead> <tbody> <tr> <td>AFFX-BioB-5_at</td> <td>5.053873</td> <td>5.396673</td> <td>5.972362</td> <td>5.549766</td> <td>5.337167</td> <td>5.411235</td> <td>5.968888</td> <td>4.616873</td> <td>6.396420</td> <td>5.615805</td> </tr> <tr> <td>AFFX-BioB-M_at</td> <td>5.364311</td> <td>5.838160</td> <td>6.128136</td> <td>5.678733</td> <td>5.212093</td> <td>5.797844</td> <td>5.508008</td> <td>5.178958</td> <td>5.605328</td> <td>5.480476</td> </tr> <tr> <td>AFFX-BioB-3_at</td> <td>5.948439</td> <td>6.391596</td> <td>4.906233</td> <td>8.079299</td> <td>5.550368</td> <td>8.071159</td> <td>7.967052</td> <td>6.646939</td> <td>7.033943</td> <td>6.825375</td> </tr> <tr> <td>AFFX-BioC-5_at</td> <td>6.988237</td> <td>8.224862</td> <td>8.003817</td> <td>6.558152</td> <td>7.593938</td> <td>7.118814</td> <td>6.884934</td> <td>6.591159</td> <td>7.872088</td> <td>8.162249</td> </tr> <tr> <td>AFFX-BioC-3_at</td> <td>4.707586</td> <td>4.747971</td> <td>4.672928</td> <td>4.322134</td> <td>4.638834</td> <td>4.665432</td> <td>4.390771</td> <td>4.257310</td> <td>5.197148</td> <td>4.978863</td> </tr> </tbody> </table> <h2 id="5-go-enrichment-analysis-with-topgo"><strong>5. GO Enrichment Analysis with topGO</strong></h2> <p>GO enrichment with topGO</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create a topGOdata object </span><span class="w">
</span><span class="n">sampleGOdata</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">new</span><span class="p">(</span><span class="s2">"topGOdata"</span><span class="p">,</span><span class="w"> </span><span class="n">description</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Simple session"</span><span class="p">,</span><span class="w"> </span><span class="n">ontology</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"BP"</span><span class="p">,</span><span class="w"> </span><span class="n">allGenes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pvalues</span><span class="p">,</span><span class="w"> </span><span class="n">geneSel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">topDiffGenes</span><span class="p">,</span><span class="w"> </span><span class="n">nodeSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="n">annot</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">annFUN.db</span><span class="p">,</span><span class="w"> </span><span class="n">affyLib</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">affyLib</span><span class="p">)</span><span class="w"> 

</span><span class="c1"># Run GO enrichment analysis with Fisher's exact test </span><span class="w">
</span><span class="n">resultFisher</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">runTest</span><span class="p">(</span><span class="n">sampleGOdata</span><span class="p">,</span><span class="w"> </span><span class="n">algorithm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"classic"</span><span class="p">,</span><span class="w"> </span><span class="n">statistic</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"fisher"</span><span class="p">)</span><span class="w"> 
</span></code></pre></div></div> <p>Display summary of results:</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Display the results </span><span class="w">
</span><span class="n">resultFisher</span><span class="w"> 
</span></code></pre></div></div> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Description</span><span class="o">:</span><span class="w"> </span><span class="n">Simple</span><span class="w"> </span><span class="n">session</span><span class="w"> 
</span><span class="n">Ontology</span><span class="o">:</span><span class="w"> </span><span class="n">BP</span><span class="w"> 
</span><span class="s1">'classic'</span><span class="w"> </span><span class="n">algorithm</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="s1">'fisher'</span><span class="w"> </span><span class="n">test</span><span class="w">
</span><span class="m">5431</span><span class="w"> </span><span class="n">GO</span><span class="w"> </span><span class="n">terms</span><span class="w"> </span><span class="n">scored</span><span class="o">:</span><span class="w"> </span><span class="m">302</span><span class="w"> </span><span class="n">terms</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0.01</span><span class="w">
</span><span class="n">Annotation</span><span class="w"> </span><span class="n">data</span><span class="o">:</span><span class="w">
    </span><span class="n">Annotated</span><span class="w"> </span><span class="n">genes</span><span class="o">:</span><span class="w"> </span><span class="m">6234</span><span class="w"> 
    </span><span class="n">Significant</span><span class="w"> </span><span class="n">genes</span><span class="o">:</span><span class="w"> </span><span class="m">1512</span><span class="w"> 
    </span><span class="n">Min.</span><span class="w"> </span><span class="n">no.</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">genes</span><span class="w"> </span><span class="n">annotated</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">GO</span><span class="o">:</span><span class="w"> </span><span class="m">10</span><span class="w"> 
    </span><span class="n">Nontrivial</span><span class="w"> </span><span class="n">nodes</span><span class="o">:</span><span class="w"> </span><span class="m">5341</span><span class="w"> 
</span></code></pre></div></div> <p>Show the top 10 enriched GO terms:</p> <table> <thead> <tr> <th></th> <th>GO.ID &lt;chr&gt;</th> <th>Term &lt;chr&gt;</th> <th>Annotated &lt;int&gt;</th> <th>Significant &lt;int&gt;</th> <th>Expected &lt;dbl&gt;</th> <th>Rank in classicFisher &lt;int&gt;</th> <th>classicFisher &lt;chr&gt;</th> <th>classicKS &lt;chr&gt;</th> <th>elimKS &lt;chr&gt;</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>GO:0010042</td> <td>response to manganese ion</td> <td>18</td> <td>14</td> <td>4.37</td> <td>10</td> <td>2.6e-06</td> <td>2.1e-06</td> <td>2.1e-06</td> </tr> <tr> <td>2</td> <td>GO:0000002</td> <td>mitochondrial genome maintenance</td> <td>13</td> <td>8</td> <td>3.15</td> <td>199</td> <td>0.00458</td> <td>0.00015</td> <td>0.00015</td> </tr> <tr> <td>3</td> <td>GO:0044539</td> <td>long-chain fatty acid import into cell</td> <td>11</td> <td>8</td> <td>2.67</td> <td>88</td> <td>0.00095</td> <td>0.00017</td> <td>0.00017</td> </tr> <tr> <td>4</td> <td>GO:0070198</td> <td>protein localization to chromosome, telo…</td> <td>20</td> <td>13</td> <td>4.85</td> <td>43</td> <td>0.00013</td> <td>0.00018</td> <td>0.00018</td> </tr> <tr> <td>5</td> <td>GO:0071897</td> <td>DNA biosynthetic process</td> <td>109</td> <td>41</td> <td>26.44</td> <td>101</td> <td>0.00118</td> <td>1.1e-05</td> <td>0.00029</td> </tr> <tr> <td>6</td> <td>GO:0045429</td> <td>positive regulation of nitric oxide bios…</td> <td>32</td> <td>18</td> <td>7.76</td> <td>42</td> <td>0.00010</td> <td>0.00033</td> <td>0.00033</td> </tr> <tr> <td>7</td> <td>GO:0016570</td> <td>histone modification</td> <td>44</td> <td>16</td> <td>10.67</td> <td>694</td> <td>0.04846</td> <td>0.00053</td> <td>0.00053</td> </tr> <tr> <td>8</td> <td>GO:0098869</td> <td>cellular oxidant detoxification</td> <td>70</td> <td>28</td> <td>16.98</td> <td>142</td> <td>0.00243</td> <td>0.00056</td> <td>0.00056</td> </tr> <tr> <td>9</td> <td>GO:0045820</td> <td>negative regulation of glycolytic proces…</td> <td>11</td> <td>9</td> <td>2.67</td> <td>39</td> <td>9.6e-05</td> <td>0.00056</td> <td>0.00056</td> </tr> <tr> <td>10</td> <td>GO:1903241</td> <td>U2-type prespliceosome assembly</td> <td>15</td> <td>9</td> <td>3.64</td> <td>168</td> <td>0.00332</td> <td>0.00057</td> <td>0.00057</td> </tr> </tbody> </table> <p>The GO topology graph for the top 5 enriched GO terms is shown below:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/topGO-enriched-GO.png" sizes="95vw"/> <img src="/assets/img/topGO-enriched-GO.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h2 id="6-analysis-with-globaltest"><strong>6. Analysis with globaltest</strong></h2> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">global_test_result</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">globaltest</span><span class="o">::</span><span class="n">gt</span><span class="p">(</span><span class="n">response</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ALL.AML</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Golub_Train</span><span class="p">)</span><span class="w">

</span><span class="n">res</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">globaltest</span><span class="o">::</span><span class="n">gtGO</span><span class="p">(</span><span class="n">ALL.AML</span><span class="p">,</span><span class="w"> </span><span class="n">Golub_Train</span><span class="p">,</span><span class="n">ontology</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"BP"</span><span class="p">,</span><span class="w"> </span><span class="n">annotation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"hu6800.db"</span><span class="p">,</span><span class="w"> </span><span class="n">multtest</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"BH"</span><span class="p">)</span><span class="w"> 
</span></code></pre></div></div> <table> <thead> <tr> <th></th> <th>GO &lt;chr&gt;</th> <th>alias &lt;chr&gt;</th> <th>BH &lt;dbl&gt;</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>GO:0006979</td> <td>response to oxidative stress</td> <td>5.937219e-09</td> </tr> <tr> <td>2</td> <td>GO:0062197</td> <td>cellular response to chemical stress</td> <td>5.937219e-09</td> </tr> <tr> <td>3</td> <td>GO:0034599</td> <td>cellular response to oxidative stress</td> <td>5.937219e-09</td> </tr> <tr> <td>4</td> <td>GO:0034614</td> <td>cellular response to reactive oxygen species</td> <td>1.479059e-08</td> </tr> <tr> <td>5</td> <td>GO:0009628</td> <td>response to abiotic stimulus</td> <td>2.469754e-08</td> </tr> <tr> <td>6</td> <td>GO:0000302</td> <td>response to reactive oxygen species</td> <td>2.680335e-08</td> </tr> <tr> <td>7</td> <td>GO:0019932</td> <td>second-messenger-mediated signaling</td> <td>1.030937e-07</td> </tr> <tr> <td>8</td> <td>GO:0019722</td> <td>calcium-mediated signaling</td> <td>1.080573e-07</td> </tr> <tr> <td>9</td> <td>GO:0050921</td> <td>positive regulation of chemotaxis</td> <td>1.080573e-07</td> </tr> <tr> <td>10</td> <td>GO:0003013</td> <td>circulatory system process</td> <td>1.342398e-07</td> </tr> </tbody> </table> <h2 id="5-comparing-results"><strong>5. Comparing Results</strong></h2> <p>The results of GO enrichment analysis using <strong>topGO</strong> and <strong>globaltest</strong> provide distinct yet informative insights into the biological processes underlying the data.</p> <p><strong>Key Results and Differences:</strong></p> <p>• <strong>Significant GO Terms</strong>:</p> <p>• topGO identified 302 significant GO terms using the Fisher’s exact test, with a focus on Biological Process (BP) ontology, while globaltest highlighted 10 highly significant GO terms, such as “response to oxidative stress” (GO:0006979) and “cellular response to reactive oxygen species” (GO:0034614).</p> <p>• <strong>Methodological Nuances</strong>:</p> <p>• topGO excels in leveraging the GO hierarchy, particularly with algorithms like “elim” to minimize redundancy. This approach is effective for capturing nuanced biological pathways.</p> <p>• globaltest uses a multivariate approach that evaluates the overall association between gene sets and outcomes, making it particularly sensitive to systemic biological patterns.</p> <p><strong>Type of Questions Addressed</strong>:</p> <p>• topGO is better suited for researchers aiming to understand specific enriched processes while accounting for the GO graph topology.</p> <p>• globaltest is ideal for broader hypotheses, such as assessing the overall contribution of a gene set to a phenotype.</p> <h2 id="6-discussion"><strong>6. Discussion</strong></h2> <p>The results from topGO and globaltest are largely complementary rather than competitive. Each package offers a unique lens through which to interpret the data:</p> <p>• <strong>Complementary Insights</strong>:</p> <p>• topGO provides granular details about localized processes within the GO hierarchy.</p> <p>• globaltest identifies overarching biological associations, highlighting system-wide trends.</p> <p>• <strong>Scenarios for Combining Insights</strong>:</p> <p>• Combining topGO’s hierarchical insights with globaltest’s systemic view can help uncover both specific mechanisms and broader biological themes, particularly for complex datasets.</p> <p>• For example, a researcher could first use topGO to pinpoint key pathways and then employ globaltest to evaluate their aggregate impact.</p> <p>• <strong>Limitations and Considerations</strong>:</p> <p>• topGO assumes independence between GO terms, which may oversimplify relationships in some contexts.</p> <p>• globaltest may lose specificity in its focus on global patterns, potentially overlooking individual pathway nuances.</p> <p>• Computational efficiency may also differ: topGO’s hierarchical algorithms may demand more preprocessing, while globaltest benefits from a simpler multivariate setup.</p> <h2 id="7-conclusion"><strong>7. Conclusion</strong></h2> <p>This comparative analysis demonstrates that both topGO and globaltest offer valuable but distinct approaches to GO enrichment analysis:</p> <p><strong>Practical Takeaways</strong>:</p> <ul> <li> <p>topGO is preferred for detailed pathway analysis, especially for datasets with hierarchical biological information.</p> </li> <li> <p>globaltest excels in scenarios requiring a holistic assessment of gene set relevance to phenotypes.</p> </li> </ul> <p><strong>Encouragement for Beginners</strong>:</p> <p>New researchers are encouraged to explore both packages to deepen their understanding of GO enrichment methods. Experimenting with these tools fosters a comprehensive grasp of the biological and statistical nuances critical for robust bioinformatics analysis.</p> <h2 id="8-references-and-further-reading"><strong>8. References and Further Reading</strong></h2> <ul> <li><a href="https://bioconductor.org/packages/release/bioc/html/topGO.html">topGO: Enrichment Analysis for Gene Ontology</a></li> <li><a href="https://bioconductor.org/packages/release/bioc/html/globaltest.html">globatest: Global Test for Functional Enrichment Analysis</a></li> <li><a href="http://geneontology.org/">Gene Ontology Consortium</a></li> </ul>]]></content><author><name></name></author><category term="statistics"/><category term="bioconductor;"/><category term="R;"/><category term="topGO;"/><category term="globaltest;"/><category term="gene-ontology;"/><category term="enrichment-analysis"/><summary type="html"><![CDATA[1. Introduction]]></summary></entry><entry><title type="html">How to Run R Code in Jupyter Notebook within VS Code: A Step-by-Step Guide</title><link href="https://davidzhao1015.github.io/blog/2024/R-kernel-jupyter/" rel="alternate" type="text/html" title="How to Run R Code in Jupyter Notebook within VS Code: A Step-by-Step Guide"/><published>2024-11-14T00:00:00+00:00</published><updated>2024-11-14T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2024/R-kernel-jupyter</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2024/R-kernel-jupyter/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>Jupyter Notebook is an invaluable tool for data scientists, researchers, and developers, enabling them to create and share computational documents seamlessly. With the added power of an integrated development environment (IDE) like Visual Studio Code (VS Code), you can run Jupyter Notebook locally and access an array of helpful extensions that enhance your workflow.</p> <p>However, despite Jupyter Notebook’s broad support for programming languages like Python, it doesn’t natively support R—something I quickly discovered while trying to use it for a blogging project. Determined to make it work, I embarked on a journey that involved scouring solutions online, seeking advice from the programming community, and leveraging the power of ChatGPT 4.0. Through a mix of trial, error, and persistence, I finally uncovered a method to run R code in Jupyter Notebook within VS Code.</p> <p>In this blog post, I’m excited to share a step-by-step guide that will help others in the same situation. I’ll also walk you through the troubleshooting process that eventually led to my solution, so you can learn from my experience and avoid the roadblocks I encountered.</p> <h2 id="step-by-step-guide-to-install-r-kernel-in-jupyter-notebook">Step-by-Step Guide to Install R Kernel in Jupyter Notebook</h2> <h3 id="1-verify-r-installation">1. Verify R Installation</h3> <p>Ensure R is installed by checking its version:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>R <span class="nt">--version</span>
</code></pre></div></div> <h3 id="2-verify-jupyter-notebook-installation">2. Verify Jupyter Notebook Installation</h3> <p>Make sure Python is installed and accessible in your PATH. Then, check for Jupyter:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python <span class="nt">--version</span>
</code></pre></div></div> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>jupyter <span class="nt">--version</span>
</code></pre></div></div> <p>To confirm Jupyter Notebook is working, run:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>jupyter notebook
</code></pre></div></div> <p>This should open a Jupyter Notebook in your web browser. If there are issues, install Jupyter using:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>jupyter
</code></pre></div></div> <h3 id="3-check-if-jupyter-directory-is-in-path">3. Check if Jupyter Directory is in PATH</h3> <p>Ensure the Jupyter directory is included in your PATH:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">echo</span> <span class="nv">$PATH</span>
</code></pre></div></div> <p>The PATH environment variable tells the system where to find executable files when you run a command.</p> <h3 id="4-install-irkernel-package-in-r">4. Install <code class="language-plaintext highlighter-rouge">IRkernel</code> Package in R</h3> <p>Install the <code class="language-plaintext highlighter-rouge">IRkernel</code> package in R:</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">install.packages</span><span class="p">(</span><span class="s1">'IRkernel'</span><span class="p">)</span><span class="w">
</span></code></pre></div></div> <h3 id="5-register-r-kernel-with-jupyter">5. Register R Kernel with Jupyter</h3> <p>Run the following command in your R terminal (not the interactive R console):</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">IRkernel</span><span class="o">::</span><span class="n">installspec</span><span class="p">(</span><span class="n">user</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div> <p>Setting <code class="language-plaintext highlighter-rouge">user = FALSE</code> makes the kernel available for all users. Use <code class="language-plaintext highlighter-rouge">user = TRUE</code> if you prefer a user-specific installation.</p> <h4 id="common-error-and-solution">Common Error and Solution</h4> <p>If you encounter this error:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Error in IRkernel::installspec(user = FALSE) :
jupyter-client has to be installed but “jupyter kernelspec --version” exited with code 127.
In addition: Warning message:
In system2("jupyter", c("kernelspec", "--version"), FALSE, FALSE) :
error in running command
</code></pre></div></div> <p>Run the command in the R terminal instead of the R console to resolve it.</p> <h3 id="6-create-a-new-jupyter-notebook-in-vs-code">6. Create a New Jupyter Notebook in VS Code</h3> <p>Restart VS Code and create a new Jupyter Notebook. Select the R kernel to start coding in R within Jupyter Notebook.</p> <h2 id="additional-tips">Additional Tips</h2> <ul> <li>Install R Packages in Jupyter: You can install R packages directly in a Jupyter cell by using install.packages(“package_name”).</li> <li>Switch Between Python and R Kernels: If you want to mix Python and R code in a Jupyter Notebook, you can use rpy2, a package that allows for inter-language compatibility. Alternatively, you can use Jupyter Lab with extensions that allow cell-specific kernel selection.</li> </ul> <p>This setup allows you to use Jupyter Notebooks with R code, which can be particularly useful for data analysis, visualization, and sharing work with others who use Python or Jupyter Notebooks.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">How to Perform Power Analysis for High-Throughput Omics Data Using SSPA, A Guide to the Bioconductor Package</title><link href="https://davidzhao1015.github.io/blog/2024/power-analysis/" rel="alternate" type="text/html" title="How to Perform Power Analysis for High-Throughput Omics Data Using SSPA, A Guide to the Bioconductor Package"/><published>2024-11-07T00:00:00+00:00</published><updated>2024-11-07T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2024/power-analysis</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2024/power-analysis/"><![CDATA[<div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/power-analysis-sspa-case-study.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div>]]></content><author><name></name></author><category term="statistics"/><category term="power-analysis;"/><category term="bioconductor;"/><category term="R;"/><category term="SSPA"/><summary type="html"><![CDATA[{::nomarkdown}]]></summary></entry><entry><title type="html">Automating Reporting with RMarkdown</title><link href="https://davidzhao1015.github.io/blog/2024/auto-reporting-rmarkdown/" rel="alternate" type="text/html" title="Automating Reporting with RMarkdown"/><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2024/auto-reporting-rmarkdown</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2024/auto-reporting-rmarkdown/"><![CDATA[<h2 id="background-and-problem-overview">Background and Problem Overview</h2> <hr/> <p>RMarkdown is a powerful tool widely used for creating dynamic, professional reports that blend text, code, and visualizations. It’s efficient and versatile, offering outputs in formats like PDF, HTML, Word, and even interactive files, making it a go-to solution for data reporting. But beyond its basic capabilities, RMarkdown offers a hidden advantage: the potential to automate report generation. By doing this, users can avoid repetitive manual updates, which not only saves time but also reduces the chance of errors, especially when content remains largely consistent with only specific details needing adjustment.</p> <p>Recently, I experienced firsthand how automating RMarkdown reporting can enhance both speed and accuracy in my workflows. This blog will serve as a step-by-step guide, showing how you can leverage RMarkdown’s automation features to streamline your own projects with minimal parameter adjustments.</p> <h3 id="problem-scenario">Problem Scenario</h3> <p>In a recent project, I needed to generate multiple reports for PCA analysis across two comparison groups. For each group, I had to update several pieces of narrative text and adjust file paths for specific figures and tables. This repetitive, manual process quickly became time-consuming and error-prone. With RMarkdown’s programming capabilities, I was able to automate these updates, saving at least 30% of my time. Not only did this streamline the current project, but it also set up a reusable template for future reporting needs.</p> <h2 id="prerequisites">Prerequisites</h2> <hr/> <p>Before diving into automating RMarkdown reports, it’s important to have a foundational understanding of a few key concepts and tools. These prerequisites will help ensure a smooth experience as you follow along with the guide.</p> <ul> <li><strong>Parameters in the YAML Header</strong>: In RMarkdown, the YAML header at the top of your file allows you to set global parameters that can be accessed throughout the document. These parameters let you customize elements such as titles, dates, and specific variables needed for your analysis. Knowing how to define and edit parameters in the YAML header is essential for making your reports dynamic and flexible.</li> <li><strong>Creating Variables from Parameter Values</strong>: Once parameters are set in the YAML header, they need to be referenced within the document. This involves creating variables in R that directly pull from these parameter values. By doing so, you can easily update specific content across the report by simply changing the parameter values, without having to adjust individual sections manually.</li> <li><strong>Embedding Parameters Using knit</strong>: RMarkdown’s knit function allows you to insert parameters within text, code chunks, or inline calculations. This embedding feature is crucial for dynamically adjusting content within the report, ensuring that titles, captions, and sections update seamlessly with each rendering of the file.</li> <li><strong>The rmarkdown::render() Function</strong>: This function is central to programmatically creating reports. It lets you specify an RMarkdown file along with any custom parameters you want to update for each run. By using rmarkdown::render(), you can generate multiple customized reports in one go by changing parameters in a loop.</li> <li><strong>Iterating with <em>for</em> Loops</strong>: Automation often requires generating multiple outputs for different variables or scenarios. A basic understanding of for loops in R is helpful here, as it allows you to iterate over different parameter sets, such as comparison groups in an analysis. This approach makes it easy to replicate report structures with tailored content for each scenario.</li> <li><strong>Running Base Command Lines in R</strong>: Certain aspects of automating RMarkdown reports may involve running command-line operations directly from R. This skill enables you to manage file paths, automate data downloads, or perform batch processing, enhancing the report’s flexibility and reducing manual workload.</li> </ul> <p>Familiarity with these components will help you set up an efficient, automated RMarkdown reporting process that can be reused and adapted to meet future reporting needs.</p> <p>If you’re new to RMarkdown or R, I recommend reviewing the basics in the official guide, <a href="https://bookdown.org/yihui/rmarkdown/"><em>R Markdown: The Definitive Guide</em></a>, to ensure you’re comfortable with these fundamentals before proceeding.</p> <h2 id="data-and-codes">Data and Codes</h2> <hr/> <p>To follow along with this tutorial and reproduce the automated reporting process, you can clone the <a href="https://github.com/davidzhao1015/AutomateRMarkdown.git">repository</a> containing all necessary files to your local machine. The repository includes all essential scripts and files required to generate a fully automated RMarkdown report.</p> <ul> <li>RMarkdown File (<code class="language-plaintext highlighter-rouge">AutomateRMarkdown/code/pca-module.Rmd</code>): <em>**</em>This core file contains the report template, including text, code chunks, and the YAML header with customizable parameters. The .Rmd file is structured to dynamically integrate analysis results, figures, and tables based on parameter values, so modifying the parameter inputs will automatically adjust the contents of the report.</li> <li><strong>R Script File (</strong><code class="language-plaintext highlighter-rouge">AutomateRMarkdown/code/combine-rmarkdown-files.R</code><strong>)</strong>: The .R file complements the RMarkdown report by containing the main script to render the report programmatically. It includes necessary functions, such as rmarkdown::render(), to automate the report generation, manage parameter values, and run any looping structures for batch reporting.</li> <li><strong>Figures and Tables (</strong><code class="language-plaintext highlighter-rouge">AutomateRMarkdown/data/</code><strong>)</strong>: Sample figures and tables are included in the repository to simulate typical analysis outputs, such as plots and summary tables. These files are referenced within the RMarkdown file to illustrate how visuals and data outputs can be dynamically incorporated. You can replace these with your own figures and tables to customize the report further.</li> </ul> <p>By downloading and running these files locally, you’ll be able to experiment with the process firsthand and see how each component interacts in automating RMarkdown reports.</p> <h2 id="step-by-step-guide">Step-by-Step Guide</h2> <hr/> <p>This guide provides a structured approach to automating an RMarkdown report. We’ll go through the setup and use key parameters in .Rmd and .R files to streamline the reporting process.</p> <p>In this example, we have two PCA comparison groups, “WT-NC vs WT-HFD” and “KO-NC vs KO-HFD.” The report structure is adaptable for other groups by adjusting parameters as needed.</p> <p><strong>Step 1: Organizing and Naming Files</strong></p> <p>Start by organizing our data files. Create two folders named <code class="language-plaintext highlighter-rouge">Download_WT-NC_WT-HFD</code> and <code class="language-plaintext highlighter-rouge">Download_KO-NC_KO-HFD</code>. Each folder will hold three essential files for the PCA report:</p> <p>• <code class="language-plaintext highlighter-rouge">pca_scored2d_0_dpi72.png</code> (PCA score plot image)</p> <p>• <code class="language-plaintext highlighter-rouge">metabolite-names.csv</code> (metabolite names table)</p> <p>• <code class="language-plaintext highlighter-rouge">pca_loadings.csv</code> (PCA loadings data)</p> <p>These folders should follow a consistent naming pattern and contain identically named files, which will help in dynamically generating the report.</p> <p><strong>Step 2: Creating the Initial .Rmd File and YAML Header</strong></p> <p>In RStudio, create an RMarkdown file named <code class="language-plaintext highlighter-rouge">pca-module.Rmd</code>. Set up the YAML header with the following fields to define metadata for the report:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.26.55_AM.png" sizes="95vw"/> <img src="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.26.55_AM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <ul> <li>title, author, and date define basic document metadata.</li> <li>output is set to md_document to output in markdown format.</li> <li>params initializes customizable parameters (group_1, group_2, order) to control specific sections in the report.</li> </ul> <p><strong>Step 3: Setting Up Parameters</strong></p> <p>In the YAML header, the params section allows parameters to be adjusted dynamically through rmarkdown::render() outside the RMarkdown document.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.28.05_AM.png" sizes="95vw"/> <img src="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.28.05_AM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Each parameter (eg. group_1, group_2, order) is initialized to represent the first group and can be modified later in the .R script for other groups.</p> <p><strong>Step 4: Defining Global Variables</strong></p> <p>Within the RMarkdown document, define global variables to capture parameter values and paths for figures and tables:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.29.07_AM.png" sizes="95vw"/> <img src="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.29.07_AM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>These variables allow us to set paths and references that will update automatically with each parameter iteration.</p> <p><strong>Step 5: Editing Subtitles with Code</strong></p> <p>To make subtitles change dynamically for each group, use a for loop and if-else statements:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.29.54_AM.png" sizes="95vw"/> <img src="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.29.54_AM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>This will display a specific subtitle for the first group and adjust accordingly for subsequent groups. Inline R code can also be used to insert parameter-based subtitles at different levels in the report.</p> <p><strong>Step 6: Embedding Variables in Figures, Tables, and Narrative Text</strong></p> <p>In the body of the report, combine static text with inline R code to make dynamic sections for figures, tables, and narrative text.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.30.46_AM.png" sizes="95vw"/> <img src="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.30.46_AM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><strong>Step 7: Writing a Loop to Automate Rendering</strong></p> <p>In a new <code class="language-plaintext highlighter-rouge">.R</code> script, create a function to loop through each group, rendering the <code class="language-plaintext highlighter-rouge">.Rmd</code> file for each set of parameters.</p> <ol> <li><strong>Create a Data Frame:</strong> Define groups with corresponding values in a data frame.</li> </ol> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">groups_collection2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="n">group_1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"WT-NC"</span><span class="p">,</span><span class="w"> </span><span class="s2">"KO-NC"</span><span class="p">),</span><span class="w">
								 </span><span class="n">group_2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"WT-HFD"</span><span class="p">,</span><span class="w"> </span><span class="s2">"KO-HFD"</span><span class="p">),</span><span class="w">
								 </span><span class="n">orders</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">))</span><span class="w">
</span></code></pre></div></div> <ol> <li><strong>Loop through Groups</strong>: Use a for loop with rmarkdown::render() to render the .Rmd file for each group.</li> </ol> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">nrow</span><span class="p">(</span><span class="n">groups_collection2</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">              
	</span><span class="n">group_1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">groups_collection2</span><span class="o">$</span><span class="n">group_1</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="w">    
	</span><span class="n">group_2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">groups_collection2</span><span class="o">$</span><span class="n">group_2</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="w">    
	</span><span class="n">order</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">groups_collection2</span><span class="o">$</span><span class="n">orders</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="w">        
	
	</span><span class="n">rmarkdown</span><span class="o">::</span><span class="n">render</span><span class="p">(</span><span class="s2">"pca-module.Rmd"</span><span class="p">,</span><span class="w">                       
		</span><span class="n">output_file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"pca_"</span><span class="p">,</span><span class="w"> </span><span class="n">group_1</span><span class="p">,</span><span class="w"> </span><span class="s2">"_"</span><span class="p">,</span><span class="w"> </span><span class="n">group_2</span><span class="p">,</span><span class="w"> </span><span class="s2">".md"</span><span class="p">),</span><span class="w">
		</span><span class="n">params</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">group_1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">group_1</span><span class="p">,</span><span class="w"> 
		              </span><span class="n">group_2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">group_2</span><span class="p">,</span><span class="w">
					  </span><span class="n">host</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Mice"</span><span class="p">,</span><span class="w">
					  </span><span class="n">order</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">order</span><span class="p">))</span><span class="w">
									</span><span class="p">}</span><span class="w"> 
</span></code></pre></div></div> <p>Executing this loop generates markdown reports for each comparison group, saved with unique filenames.</p> <p><strong>Step 8: Merging Markdown Files in Command Line</strong></p> <p>Finally, combine the individual markdown files into one file with an R command:</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">system</span><span class="p">(</span><span class="s2">"cat pca_WT-NC_WT-HFD.md &gt; combined_pca.md &amp;&amp; echo &gt;&gt; combined_pca.md &amp;&amp; cat pca_KO-NC_KO-HFD.md &gt;&gt; combined_pca.md"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div> <p>This will create a single file, <code class="language-plaintext highlighter-rouge">combined_pca.md</code>, containing the complete report with results for both groups.</p> <p>Following these steps, you can streamline report creation for multiple groups, making RMarkdown a powerful tool for efficient, reproducible analysis.</p> <h2 id="takeaway">Takeaway</h2> <hr/> <p>RMarkdown is a powerful tool for creating high-quality, reproducible reports, and by integrating programming solutions, it becomes even more versatile. By following this guide, you’ve gained insight into setting up dynamic and reusable report templates, which can save time and improve accuracy.</p> <p>Now it’s your turn! Clone the GitHub repo and try running the example code yourself. Once you get familiar with it, experiment by customizing sections to fit your unique data or reporting needs. This hands-on approach will not only deepen your understanding but also help you master dynamic reporting for any project!</p>]]></content><author><name></name></author><category term="reporting"/><category term="rmarkdown;"/><category term="automation;"/><category term="tutorial"/><summary type="html"><![CDATA[Background and Problem Overview]]></summary></entry><entry><title type="html">Introduction to Linear Mixed Models with the limma Package</title><link href="https://davidzhao1015.github.io/blog/2024/linear-mixed-model/" rel="alternate" type="text/html" title="Introduction to Linear Mixed Models with the limma Package"/><published>2024-10-23T00:00:00+00:00</published><updated>2024-10-23T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2024/linear-mixed-model</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2024/linear-mixed-model/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>In the field of bioinformatics and genomics, understanding the variations in gene expression across different experimental conditions is crucial for interpreting biological processes. The limma package is widely recognized for its powerful capabilities in fitting linear models to gene expression data, allowing researchers to evaluate differences due to experimental conditions.</p> <p>However, many experimental designs involve repeated measurements from the same subjects, whether they are animals, human samples, or cells. These repeated measures introduce random effects, which must be accounted for to avoid biased results. Random effects occur when some variability in the data is due to differences between subjects or samples that are not directly related to the experimental conditions being studied.</p> <p>This tutorial provides a step-by-step guide on how to build linear mixed models (LMM) using the limma package to incorporate random effects. You will learn how to adjust for these random variations, ensuring more accurate and reliable conclusions about gene expression.</p> <h2 id="what-is-effect-of-repeated-measures">What is effect of repeated measures?</h2> <p>Repeated measures refer to data collected from the same subjects at multiple time points or under different conditions. These designs result in correlated observations, as repeated measures on the same individual tend to share subject-specific traits. Ignoring this correlation can lead to incorrect conclusions since traditional methods assume independence between observations.</p> <p>The use of repeated measures often reduces variability, as each subject serves as their own control, which increases the sensitivity of the analysis. This can lead to greater statistical power, enabling researchers to detect effects with fewer subjects. To handle the correlation between repeated observations, specialized methods such as Repeated Measures ANOVA, Linear Mixed Models (LMM), or Generalized Estimating Equations (GEE) are typically used.</p> <h2 id="what-can-linear-mixed-effect-model-do">What can linear mixed-effect model do?</h2> <p>A Linear Mixed-Effects Model (LMM) is used to analyze repeated measures data by accounting for both overall effects (like treatments or time) and individual differences between subjects. It helps manage the fact that repeated observations from the same person are related, and it can handle missing data or different time points for each person. This makes it a flexible tool for analyzing complex data.</p> <p>In the context of gene expression analysis, LMMs can be used to model the effects of experimental conditions (e.g., treatment groups) while accounting for individual variability and correlations between repeated measurements. By incorporating random effects, LMMs provide a more accurate representation of the underlying data structure, leading to more reliable results and improved statistical power.</p> <h1 id="prerequisites">Prerequisites</h1> <p>Before proceeding with this tutorial, you should have a basic understanding of linear models, gene expression analysis, and the R programming language. Familiarity with the limma package and its functions is recommended but not required.</p> <p>To follow along with the code examples, you will need to have R and RStudio installed on your computer. You can download R from the Comprehensive R Archive Network (CRAN) and RStudio from the RStudio website. Additionally, you will need to install the limma package, which can be done using the BiocManager package.</p> <p>The R package <code class="language-plaintext highlighter-rouge">limma</code> is used for linear models and differential expression analysis. If you haven’t installed the package yet, you can do so by running the following code:</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Install the biocManager package </span><span class="w">
    </span><span class="c1"># install.packages("BiocManager") </span><span class="w">
    </span><span class="c1"># Install the limma package </span><span class="w">
    </span><span class="c1"># BiocManager::install("limma", force = TRUE)  </span><span class="w">

    </span><span class="n">library</span><span class="p">(</span><span class="n">limma</span><span class="p">)</span><span class="w"> </span><span class="c1"># For linear models and differential expression analysis </span><span class="w">
    </span><span class="n">library</span><span class="p">(</span><span class="n">ggplot2</span><span class="p">)</span><span class="w"> </span><span class="c1"># For data visualization </span><span class="w">
    </span><span class="n">library</span><span class="p">(</span><span class="n">gridExtra</span><span class="p">)</span><span class="w">
</span></code></pre></div></div> <h1 id="code-structure">Code Structure</h1> <p>This tutorial is divided into four main steps:</p> <ol> <li><strong>Simulate Example Data</strong>: We will generate example data with repeated measures to demonstrate the use of linear mixed-effect models with the limma package.</li> <li><strong>Fit Linear Models with limma</strong>: We will fit linear models to the example data using the limma package, considering different model configurations.</li> <li><strong>Evaluate the Block Effect</strong>: We will extract differentially expressed genes and visualize the coefficients and confidence intervals for the fixed effects of treatment on gene expression.</li> <li><strong>Evaluate Model Robustness</strong>: We will evaluate the assumptions of homoscedasticity and linearity by examining the residuals and checking the normality of residuals using Q-Q plots.</li> </ol> <h2 id="step-1---simulate-example-data">Step 1 - Simulate example data</h2> <p>In this step, we will simulate example data to demonstrate the use of linear mixed-effect models with the <code class="language-plaintext highlighter-rouge">limma</code> package.</p> <p>The example data will consist of gene expression data for 10 individuals per group (control and treatment groups), with 2 samples (repeative measures) per individual.</p> <p>We will simulate the following variables for each sample: 1. <code class="language-plaintext highlighter-rouge">people</code>: A numeric variable representing the individual ID 2. <code class="language-plaintext highlighter-rouge">treatment</code>: A factor variable indicating the treatment group (0 = Control, 1 = Treatment) 3. <code class="language-plaintext highlighter-rouge">gender</code>: A factor variable representing</p> <p>We will also simulate gene expression data for 5 genes, from normal distributions with different means and standard deviations for the control and treatment groups.</p> <p>The gene expression data will be combined into a single data frame, with the genes as rows and the samples as columns.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Simulate example data</span><span class="w">
    </span><span class="n">set.seed</span><span class="p">(</span><span class="m">123</span><span class="p">)</span><span class="w">

    </span><span class="c1"># Define variables</span><span class="w">
    </span><span class="n">people</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">),</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="c1"># 10 people, 2 samples per person </span><span class="w">
    </span><span class="n">treatment</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">factor</span><span class="p">(</span><span class="nf">rep</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">))</span><span class="w">  </span><span class="c1"># 0 = Control, 1 = Treatment</span><span class="w">
    </span><span class="n">gender</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">factor</span><span class="p">(</span><span class="n">sample</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s2">"Male"</span><span class="p">,</span><span class="w"> </span><span class="s2">"Female"</span><span class="p">),</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">))</span><span class="w">  </span><span class="c1"># Gender</span><span class="w">
    </span><span class="n">genes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"Gene"</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">)</span><span class="w">

    </span><span class="c1"># Simulate gene expression matrix for treatment group</span><span class="w">
    </span><span class="n">gene_expression_treatment</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="n">rnorm</span><span class="p">(</span><span class="m">50</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">),</span><span class="w"> </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">dimnames</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">genes</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">))</span><span class="w"> 
    </span><span class="n">print</span><span class="p">(</span><span class="n">gene_expression_treatment</span><span class="p">)</span><span class="w">

    </span><span class="c1">##               1         2        3         4         5         6         7         8         9        10</span><span class="w">
    </span><span class="c1">## Gene1 12.448164 13.573826 7.864353  6.626613 10.852928 11.377281  8.610586  7.753783 10.506637 13.032941</span><span class="w">
    </span><span class="c1">## Gene2 10.719628 10.995701 9.564050 11.675574  9.409857 11.107835  9.584165  9.194230  9.942906  6.902494</span><span class="w">
    </span><span class="c1">## Gene3 10.801543  6.066766 7.947991 10.306746 11.790251  9.876177  7.469207  9.066689  9.914259 11.169227</span><span class="w">
    </span><span class="c1">## Gene4 10.221365 11.402712 8.542218  7.723726 11.756267  9.388075 14.337912 11.559930 12.737205 10.247708</span><span class="w">
    </span><span class="c1">## Gene5  8.888318  9.054417 8.749921 12.507630 11.643162  9.239058 12.415924  9.833262  9.548458 10.431883</span><span class="w">

    </span><span class="c1"># Simulate gene expression matrix for control group </span><span class="w">
    </span><span class="n">gene_expression_control</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="n">rnorm</span><span class="p">(</span><span class="m">50</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">),</span><span class="w"> </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">dimnames</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">genes</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">))</span><span class="w"> 
    </span><span class="n">print</span><span class="p">(</span><span class="n">gene_expression_control</span><span class="p">)</span><span class="w">

    </span><span class="c1">##              1        2         3        4        5        6        7        8        9       10</span><span class="w">
    </span><span class="c1">## Gene1 5.759279 5.607057 4.0179377 7.051143 5.011528 5.663564 6.987008 3.799481 3.579187 4.909945</span><span class="w">
    </span><span class="c1">## Gene2 3.995353 5.896420 0.3816622 4.430454 5.770561 7.193678 6.096794 9.374666 5.513767 3.430191</span><span class="w">
    </span><span class="c1">## Gene3 4.333585 5.106008 7.0114770 2.558565 4.258680 5.870363 5.477463 8.065221 4.506616 1.664116</span><span class="w">
    </span><span class="c1">## Gene4 2.962849 6.844535 3.5815985 5.362607 6.288753 4.348137 3.744188 4.528599 4.304915 4.239547</span><span class="w">
    </span><span class="c1">## Gene5 2.856418 9.100169 3.6239828 4.722217 4.559027 7.297615 7.721305 2.947158 3.096763 6.837993</span><span class="w">

    </span><span class="c1"># Combine the gene expression data </span><span class="w">
    </span><span class="n">gene_expression</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">gene_expression_treatment</span><span class="p">,</span><span class="w"> </span><span class="n">gene_expression_control</span><span class="p">)</span><span class="w">

    </span><span class="c1"># Create a data frame with the gene expression data </span><span class="w">
    </span><span class="n">expression_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="n">gene_expression</span><span class="p">,</span><span class="w"> </span><span class="n">row.names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">genes</span><span class="p">)</span><span class="w">
    </span><span class="n">colnames</span><span class="p">(</span><span class="n">expression_data</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"sample"</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">20</span><span class="p">)</span><span class="w"> 

    </span><span class="c1"># Print the expression data</span><span class="w">
    </span><span class="n">print</span><span class="p">(</span><span class="n">expression_data</span><span class="p">)</span><span class="w"> 

    </span><span class="c1">##         sample1   sample2  sample3   sample4   sample5   sample6   sample7   sample8   sample9  sample10 sample11 sample12  sample13 sample14 sample15 sample16 sample17</span><span class="w">
    </span><span class="c1">## Gene1 12.448164 13.573826 7.864353  6.626613 10.852928 11.377281  8.610586  7.753783 10.506637 13.032941 5.759279 5.607057 4.0179377 7.051143 5.011528 5.663564 6.987008</span><span class="w">
    </span><span class="c1">## Gene2 10.719628 10.995701 9.564050 11.675574  9.409857 11.107835  9.584165  9.194230  9.942906  6.902494 3.995353 5.896420 0.3816622 4.430454 5.770561 7.193678 6.096794</span><span class="w">
    </span><span class="c1">## Gene3 10.801543  6.066766 7.947991 10.306746 11.790251  9.876177  7.469207  9.066689  9.914259 11.169227 4.333585 5.106008 7.0114770 2.558565 4.258680 5.870363 5.477463</span><span class="w">
    </span><span class="c1">## Gene4 10.221365 11.402712 8.542218  7.723726 11.756267  9.388075 14.337912 11.559930 12.737205 10.247708 2.962849 6.844535 3.5815985 5.362607 6.288753 4.348137 3.744188</span><span class="w">
    </span><span class="c1">## Gene5  8.888318  9.054417 8.749921 12.507630 11.643162  9.239058 12.415924  9.833262  9.548458 10.431883 2.856418 9.100169 3.6239828 4.722217 4.559027 7.297615 7.721305</span><span class="w">
    </span><span class="c1">##       sample18 sample19 sample20</span><span class="w">
    </span><span class="c1">## Gene1 3.799481 3.579187 4.909945</span><span class="w">
    </span><span class="c1">## Gene2 9.374666 5.513767 3.430191</span><span class="w">
    </span><span class="c1">## Gene3 8.065221 4.506616 1.664116</span><span class="w">
    </span><span class="c1">## Gene4 4.528599 4.304915 4.239547</span><span class="w">
    </span><span class="c1">## Gene5 2.947158 3.096763 6.837993</span><span class="w">
</span></code></pre></div></div> <h2 id="step-2---fit-linear-models-with-limma">Step 2 - Fit linear models with limma</h2> <p>In this step, we will fit linear models to the example data using the <code class="language-plaintext highlighter-rouge">limma</code> package. We will consider three different models:</p> <ol> <li>Model 1: Treatment as the only predictor variable</li> <li>Model 2: Treatment and gender as covariates</li> <li>Model 3: Treatment and gender as covariates with repeated measures</li> </ol> <p>In <code class="language-plaintext highlighter-rouge">limma</code>, block effects can be used to account for non-independent samples, such as technical replicates or paired samples. You can use the <code class="language-plaintext highlighter-rouge">duplicateCorrelation()</code> function to model the correlation between samples within the same block.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1">#------Model 1: Treatment as the only predictor variable------# </span><span class="w">
    </span><span class="c1"># Create model matrix (with treatment as the only predictor variable)  </span><span class="w">
    </span><span class="n">design_1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">model.matrix</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">treatment</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expression_data</span><span class="p">)</span><span class="w"> 
    </span><span class="c1"># Fit the linear model</span><span class="w">
    </span><span class="n">fit_1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lmFit</span><span class="p">(</span><span class="n">expression_data</span><span class="p">,</span><span class="w"> </span><span class="n">design_1</span><span class="p">)</span><span class="w">  
    </span><span class="c1"># Apply empirical Bayes moderation</span><span class="w">
    </span><span class="n">fit_1_ebayes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">eBayes</span><span class="p">(</span><span class="n">fit_1</span><span class="p">)</span><span class="w">


    </span><span class="c1">#------Model 2: Treatment and Gender as covariates------# </span><span class="w">
    </span><span class="c1"># Create design matrix (treatment and gender as covariates)</span><span class="w">
    </span><span class="n">design_2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">model.matrix</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">treatment</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">gender</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expression_data</span><span class="p">)</span><span class="w">
    </span><span class="c1"># Fit the linear model for each gene</span><span class="w">
    </span><span class="n">fit_2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lmFit</span><span class="p">(</span><span class="n">expression_data</span><span class="p">,</span><span class="w"> </span><span class="n">design_2</span><span class="p">)</span><span class="w">
    </span><span class="c1"># Apply empirical Bayes moderation</span><span class="w">
    </span><span class="n">fit_2_ebayes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">eBayes</span><span class="p">(</span><span class="n">fit_2</span><span class="p">)</span><span class="w">


    </span><span class="c1">#------Model 3: Treatment and Gender as covariates with repeated measures------# </span><span class="w">
    </span><span class="c1"># Model the correlation between samples within the same block (repeated measures) </span><span class="w">
    </span><span class="n">corfit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">limma</span><span class="o">::</span><span class="n">duplicateCorrelation</span><span class="p">(</span><span class="n">gene_expression</span><span class="p">,</span><span class="w"> </span><span class="n">design_2</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">people</span><span class="p">)</span><span class="w"> 
    </span><span class="c1"># Incorprate the block effect in the model </span><span class="w">
    </span><span class="n">fit_3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lmFit</span><span class="p">(</span><span class="n">gene_expression</span><span class="p">,</span><span class="w"> </span><span class="n">design_2</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">people</span><span class="p">,</span><span class="w"> </span><span class="n">correlation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">corfit</span><span class="o">$</span><span class="n">consensus</span><span class="p">)</span><span class="w">
    </span><span class="c1"># Apply empirical Bayes moderation</span><span class="w">
    </span><span class="n">fit_3_ebayes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">eBayes</span><span class="p">(</span><span class="n">fit_3</span><span class="p">)</span><span class="w"> 
</span></code></pre></div></div> <p>The <code class="language-plaintext highlighter-rouge">corfit$consensus</code> object contains the correlation structure of the repeated measures, which is used in the <code class="language-plaintext highlighter-rouge">lmFit</code> function to account for the correlation between samples from the same individual. It is an estimate of the average intra-block correlation. If the value is close to zero, the block effect is weak or negligible. A higher value (closer to 1) indicates a stronger correlation within blocks, meaning the block effect is significant.</p> <p>In this case, the block effect is not significant, as the correlation is close to zero (approximately, 0.01).</p> <h2 id="step-3---evaluate-the-block-effect">Step 3 - Evaluate the Block Effect</h2> <p><strong>Extract top differentially expressed genes</strong></p> <p>In this step, we will extract the top differentially expressed genes from the fitted models. We will use the <code class="language-plaintext highlighter-rouge">topTable</code> function to extract the results, including the log fold change, moderated t-statistic, raw p-value, adjusted p-value (FDR), and log-odds that the gene is differentially expressed.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Extract top differentially expressed genes</span><span class="w">
    </span><span class="n">topTable</span><span class="p">(</span><span class="n">fit_1_ebayes</span><span class="p">,</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">Inf</span><span class="p">,</span><span class="w"> </span><span class="n">adjust.method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"BH"</span><span class="p">,</span><span class="w"> </span><span class="n">sort.by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"P"</span><span class="p">)</span><span class="w"> 

    </span><span class="c1">## Removing intercept from test coefficients</span><span class="w">

    </span><span class="c1">##           logFC  AveExpr         t      P.Value    adj.P.Val         B</span><span class="w">
    </span><span class="c1">## Gene4 -6.171139 7.706142 -7.430413 5.986052e-11 2.993026e-10 20.276398</span><span class="w">
    </span><span class="c1">## Gene1 -5.026098 7.751662 -6.051717 3.234941e-08 7.859775e-08 11.366624</span><span class="w">
    </span><span class="c1">## Gene5 -4.954939 7.753734 -5.966037 4.715865e-08 7.859775e-08 10.873058</span><span class="w">
    </span><span class="c1">## Gene2 -4.701290 7.558999 -5.660628 1.776199e-07 2.220249e-07  9.170996</span><span class="w">
    </span><span class="c1">## Gene3 -4.555676 7.163048 -5.485301 3.752867e-07 3.752867e-07  8.234286</span><span class="w">

    </span><span class="c1"># Show results</span><span class="w">
    </span><span class="n">topTable</span><span class="p">(</span><span class="n">fit_2_ebayes</span><span class="p">)</span><span class="w">

    </span><span class="c1">## Removing intercept from test coefficients</span><span class="w">

    </span><span class="c1">##       treatment1  genderMale  AveExpr        F      P.Value    adj.P.Val</span><span class="w">
    </span><span class="c1">## Gene4  -6.174442 -0.03303168 7.706142 27.05854 1.772654e-12 8.863272e-12</span><span class="w">
    </span><span class="c1">## Gene1  -4.913836  1.12261968 7.751662 18.82582 6.668838e-09 1.667210e-08</span><span class="w">
    </span><span class="c1">## Gene5  -5.047809 -0.92870157 7.753734 18.04422 1.457123e-08 2.428538e-08</span><span class="w">
    </span><span class="c1">## Gene2  -4.660927  0.40362347 7.558999 15.81690 1.351472e-07 1.689340e-07</span><span class="w">
    </span><span class="c1">## Gene3  -4.570297 -0.14621287 7.163048 14.76065 3.886259e-07 3.886259e-07</span><span class="w">

    </span><span class="c1"># Show results</span><span class="w">
    </span><span class="n">topTable</span><span class="p">(</span><span class="n">fit_3_ebayes</span><span class="p">)</span><span class="w"> 

    </span><span class="c1">## Removing intercept from test coefficients</span><span class="w">

    </span><span class="c1">##       treatment1  genderMale  AveExpr        F      P.Value    adj.P.Val</span><span class="w">
    </span><span class="c1">## Gene4  -6.173634 -0.02495011 7.706142 26.77375 2.356711e-12 1.178356e-11</span><span class="w">
    </span><span class="c1">## Gene1  -4.914731  1.11367369 7.751662 18.62289 8.169239e-09 2.042310e-08</span><span class="w">
    </span><span class="c1">## Gene5  -5.047331 -0.92392051 7.753734 17.85445 1.761614e-08 2.936023e-08</span><span class="w">
    </span><span class="c1">## Gene2  -4.660333  0.40956206 7.558999 15.65513 1.588780e-07 1.985975e-07</span><span class="w">
    </span><span class="c1">## Gene3  -4.570291 -0.14614599 7.163048 14.60561 4.538018e-07 4.538018e-07</span><span class="w">
</span></code></pre></div></div> <p>Parameters Interpretation: - logFC: Log fold change of the gene expression between conditions. - AveExpr: Average expression of the gene across all samples. - t: Moderated t-statistic. - P.Value: Raw p-value. - adj.P.Val: Adjusted p-value (FDR). - B: Log-odds that the gene is differentially expressed.</p> <p>If including the block effect changes the results substantially (e.g., differentially expressed genes, p-values), then the block effect is important in your model. Otherwise, if there is minimal change, the block effect may not significantly impact the model.</p> <p>In this case, the block effect does not significantly affect the results, as the top differentially expressed genes are similar across the models. In contrast, the covariate, gender has a significant impact on the results, as the top differentially expressed genes differ between Model 1 and Model 2.</p> <p><strong>Visualize the coefficients and CI</strong></p> <p>In this step, we will visualize the coefficients and confidence intervals for the fixed effects of treatment on gene expression. We will compare the results from Model 1, Model 2, and Model 3.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Define a function to extract the coefficients and confidence intervals </span><span class="w">
    </span><span class="n">extract_coef_ci</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="n">coef_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="w">
        </span><span class="n">Gene</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rownames</span><span class="p">(</span><span class="n">fit</span><span class="o">$</span><span class="n">coefficients</span><span class="p">),</span><span class="w">
        </span><span class="n">Estimate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[,</span><span class="w"> </span><span class="s2">"treatment1"</span><span class="p">],</span><span class="w">
        </span><span class="n">CI_Lower</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[,</span><span class="w"> </span><span class="s2">"treatment1"</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1.96</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">stdev.unscaled</span><span class="p">[,</span><span class="w"> </span><span class="s2">"treatment1"</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">sigma</span><span class="p">,</span><span class="w">
        </span><span class="n">CI_Upper</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[,</span><span class="w"> </span><span class="s2">"treatment1"</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1.96</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">stdev.unscaled</span><span class="p">[,</span><span class="w"> </span><span class="s2">"treatment1"</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">sigma</span><span class="w">
      </span><span class="p">)</span><span class="w">
      </span><span class="nf">return</span><span class="p">(</span><span class="n">coef_df</span><span class="p">)</span><span class="w">
    </span><span class="p">}</span><span class="w">

    </span><span class="c1"># Extract coefficients and confidence intervals for Model 1 - 3 </span><span class="w">
    </span><span class="n">coef_df_1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">extract_coef_ci</span><span class="p">(</span><span class="n">fit_1_ebayes</span><span class="p">)</span><span class="w">
    </span><span class="n">coef_df_2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">extract_coef_ci</span><span class="p">(</span><span class="n">fit_2_ebayes</span><span class="p">)</span><span class="w">
    </span><span class="n">coef_df_3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">extract_coef_ci</span><span class="p">(</span><span class="n">fit_3_ebayes</span><span class="p">)</span><span class="w">

    </span><span class="c1"># Prepare the data for plotting </span><span class="w">
    </span><span class="n">coef_df_1</span><span class="o">$</span><span class="n">model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s2">"Model_1"</span><span class="w">
    </span><span class="n">coef_df_2</span><span class="o">$</span><span class="n">model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s2">"Model_2"</span><span class="w"> 
    </span><span class="n">coef_df_3</span><span class="o">$</span><span class="n">model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s2">"Model_3"</span><span class="w"> 

    </span><span class="n">coef_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rbind</span><span class="p">(</span><span class="n">coef_df_1</span><span class="p">,</span><span class="w"> </span><span class="n">coef_df_2</span><span class="p">,</span><span class="w"> </span><span class="n">coef_df_3</span><span class="p">)</span><span class="w"> 
    </span><span class="n">print</span><span class="p">(</span><span class="n">coef_df</span><span class="p">)</span><span class="w">  

    </span><span class="c1">##         Gene  Estimate  CI_Lower  CI_Upper   model</span><span class="w">
    </span><span class="c1">## Gene1  Gene1 -5.026098 -6.710451 -3.341746 Model_1</span><span class="w">
    </span><span class="c1">## Gene2  Gene2 -4.701290 -6.404071 -2.998508 Model_1</span><span class="w">
    </span><span class="c1">## Gene3  Gene3 -4.555676 -6.179768 -2.931585 Model_1</span><span class="w">
    </span><span class="c1">## Gene4  Gene4 -6.171139 -7.610268 -4.732010 Model_1</span><span class="w">
    </span><span class="c1">## Gene5  Gene5 -4.954939 -6.629405 -3.280472 Model_1</span><span class="w">
    </span><span class="c1">## Gene11 Gene1 -4.913836 -6.572943 -3.254729 Model_2</span><span class="w">
    </span><span class="c1">## Gene21 Gene2 -4.660927 -6.411613 -2.910241 Model_2</span><span class="w">
    </span><span class="c1">## Gene31 Gene3 -4.570297 -6.248554 -2.892041 Model_2</span><span class="w">
    </span><span class="c1">## Gene41 Gene4 -6.174442 -7.662748 -4.686136 Model_2</span><span class="w">
    </span><span class="c1">## Gene51 Gene5 -5.047809 -6.722954 -3.372663 Model_2</span><span class="w">
    </span><span class="c1">## Gene12 Gene1 -4.914731 -6.578634 -3.250828 Model_3</span><span class="w">
    </span><span class="c1">## Gene22 Gene2 -4.660333 -6.417573 -2.903094 Model_3</span><span class="w">
    </span><span class="c1">## Gene32 Gene3 -4.570291 -6.258486 -2.882096 Model_3</span><span class="w">
    </span><span class="c1">## Gene42 Gene4 -6.173634 -7.668705 -4.678563 Model_3</span><span class="w">
    </span><span class="c1">## Gene52 Gene5 -5.047331 -6.737661 -3.357000 Model_3</span><span class="w">
</span></code></pre></div></div> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Plot the fixed effects with confidence intervals, comparing Model 1 - 3 </span><span class="w">
    </span><span class="n">pd</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">position_dodge</span><span class="p">(</span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.2</span><span class="p">)</span><span class="w"> </span><span class="c1"># Position dodge for better visualization </span><span class="w">

    </span><span class="n">ggplot</span><span class="p">(</span><span class="n">coef_df</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Gene</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Estimate</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
      </span><span class="n">geom_point</span><span class="p">(</span><span class="n">position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pd</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
      </span><span class="n">geom_errorbar</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">ymin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CI_Lower</span><span class="p">,</span><span class="w"> </span><span class="n">ymax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CI_Upper</span><span class="p">),</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.2</span><span class="p">,</span><span class="w"> </span><span class="n">position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pd</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="c1"># Error bars for confidence intervals </span><span class="w">
      </span><span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Fixed Effects of Treatment on Gene Expression"</span><span class="p">,</span><span class="w">
           </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Gene"</span><span class="p">,</span><span class="w">
           </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Estimate (Treatment Effect)"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
      </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
      </span><span class="n">theme</span><span class="p">(</span><span class="n">legend.position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"top"</span><span class="p">)</span><span class="w"> 
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/linear-mixed-model_files/figure-markdown_strict/unnamed-chunk-3-1.png" sizes="95vw"/> <img src="/assets/img/linear-mixed-model_files/figure-markdown_strict/unnamed-chunk-3-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>The plot shows the fixed effects of treatment on gene expression, with confidence intervals for Model 1 - 3. The coefficients represent the estimated treatment effect on gene expression, and the confidence intervals indicate the uncertainty around the estimates.</p> <p>The gene expression of Genes 1 - 5 are significantly downregulated in the treatment group compared to the control group, as the confidence interval does not include zero. The confidence intervals provide a range of plausible values for the treatment effect, taking into account the uncertainty in the estimates.</p> <h2 id="step-4---evaluate-model-robustness">Step 4 - Evaluate model robustness</h2> <p>This step evaluates the assumptions of homoscedasticity and linearity by examining the residuals. If the residuals are randomly distributed around zero and show no clear patterns, the assumptions are met. If there are patterns or trends in the residuals, further investigation may be needed to address model assumptions.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Plot the residuals</span><span class="w">

    </span><span class="c1"># Create a functiont to plot fitted values vs residuals </span><span class="w">
    </span><span class="n">plot_residuals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="n">residuals_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="w">
        </span><span class="n">Residuals</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">as.vector</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data</span><span class="p">)),</span><span class="w"> 
        </span><span class="n">Fitted</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">as.vector</span><span class="p">(</span><span class="n">fitted</span><span class="p">(</span><span class="n">fit</span><span class="p">))</span><span class="w">
      </span><span class="p">)</span><span class="w"> 
      
      </span><span class="n">ggplot</span><span class="p">(</span><span class="n">residuals_df</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Fitted</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Residuals</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
        </span><span class="n">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
        </span><span class="n">geom_hline</span><span class="p">(</span><span class="n">yintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"dashed"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
        </span><span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Residuals vs Fitted Values"</span><span class="p">,</span><span class="w">
             </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Fitted Values"</span><span class="p">,</span><span class="w">
             </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Residuals"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
        </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w">
    </span><span class="p">}</span><span class="w">

    </span><span class="c1"># Combine the residual plots for Model 1 - 3</span><span class="w">
    </span><span class="n">grid.arrange</span><span class="p">(</span><span class="n">plot_residuals</span><span class="p">(</span><span class="n">fit_1</span><span class="p">,</span><span class="w"> </span><span class="n">expression_data</span><span class="p">),</span><span class="w"> 
                 </span><span class="n">plot_residuals</span><span class="p">(</span><span class="n">fit_2</span><span class="p">,</span><span class="w"> </span><span class="n">expression_data</span><span class="p">),</span><span class="w"> 
                 </span><span class="n">plot_residuals</span><span class="p">(</span><span class="n">fit_3</span><span class="p">,</span><span class="w"> </span><span class="n">gene_expression</span><span class="p">),</span><span class="w"> 
                 </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w"> 
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/linear-mixed-model_files/figure-markdown_strict/unnamed-chunk-4-1.png" sizes="95vw"/> <img src="/assets/img/linear-mixed-model_files/figure-markdown_strict/unnamed-chunk-4-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>In this case, the residual plots show no clear patterns or trends, indicating that the assumptions of homoscedasticity and linearity are met for Model 1 - 3.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Check the normality of residuals using Q-Q plots </span><span class="w">
    </span><span class="n">par</span><span class="p">(</span><span class="n">mfrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">))</span><span class="w"> 
    </span><span class="n">qqnorm</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit_1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expression_data</span><span class="p">))</span><span class="w"> 
    </span><span class="n">qqline</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit_1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expression_data</span><span class="p">))</span><span class="w"> 

    </span><span class="n">qqnorm</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit_2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expression_data</span><span class="p">))</span><span class="w"> 
    </span><span class="n">qqline</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit_2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expression_data</span><span class="p">))</span><span class="w">

    </span><span class="n">qqnorm</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit_3</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gene_expression</span><span class="p">))</span><span class="w"> 
    </span><span class="n">qqline</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit_3</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gene_expression</span><span class="p">))</span><span class="w"> 
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/linear-mixed-model_files/figure-markdown_strict/unnamed-chunk-5-1.png" sizes="95vw"/> <img src="/assets/img/linear-mixed-model_files/figure-markdown_strict/unnamed-chunk-5-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>The residuals are randomly distributed around zero, with no systematic deviations from the assumptions.</p> <h1 id="conclusion">Conclusion</h1> <p>In this tutorial, we demonstrated how to fit linear mixed-effect models with the <code class="language-plaintext highlighter-rouge">limma</code> package in R. We simulated example data with repeated measures and applied linear models with different covariates and block effects. We evaluated the block effect, extracted differentially expressed genes, visualized the coefficients, and assessed model robustness.</p> <p>Linear mixed-effect models are useful for analyzing data with repeated measures or nested structures, where samples are not independent. By incorporating random effects and block effects, we can account for the correlation between samples and improve the accuracy of the statistical analysis.</p> <p>This tutorial is for demonstration purpose, although the block efffect is not significant. You can apply similar steps to analyze your own data with linear mixed-effect models using the <code class="language-plaintext highlighter-rouge">limma</code> package in R.</p> <h1 id="sessoin-info">Sessoin Info</h1> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="n">sessionInfo</span><span class="p">()</span><span class="w">

    </span><span class="c1">## R version 4.3.3 (2024-02-29)</span><span class="w">
    </span><span class="c1">## Platform: aarch64-apple-darwin20 (64-bit)</span><span class="w">
    </span><span class="c1">## Running under: macOS 15.0</span><span class="w">
    </span><span class="c1">## </span><span class="w">
    </span><span class="c1">## Matrix products: default</span><span class="w">
    </span><span class="c1">## BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib </span><span class="w">
    </span><span class="c1">## LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0</span><span class="w">
    </span><span class="c1">## </span><span class="w">
    </span><span class="c1">## locale:</span><span class="w">
    </span><span class="c1">## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8</span><span class="w">
    </span><span class="c1">## </span><span class="w">
    </span><span class="c1">## time zone: America/Edmonton</span><span class="w">
    </span><span class="c1">## tzcode source: internal</span><span class="w">
    </span><span class="c1">## </span><span class="w">
    </span><span class="c1">## attached base packages:</span><span class="w">
    </span><span class="c1">## [1] stats     graphics  grDevices utils     datasets  methods   base     </span><span class="w">
    </span><span class="c1">## </span><span class="w">
    </span><span class="c1">## other attached packages:</span><span class="w">
    </span><span class="c1">## [1] rmarkdown_2.26 gridExtra_2.3  limma_3.58.1   shiny_1.9.1    ggplot2_3.5.0  bookdown_0.41 </span><span class="w">
    </span><span class="c1">## </span><span class="w">
    </span><span class="c1">## loaded via a namespace (and not attached):</span><span class="w">
    </span><span class="c1">##  [1] sass_0.4.9          utf8_1.2.4          generics_0.1.3      digest_0.6.35       magrittr_2.0.3      evaluate_0.23       grid_4.3.3          fastmap_1.2.0      </span><span class="w">
    </span><span class="c1">##  [9] jsonlite_1.8.8      promises_1.2.1      BiocManager_1.30.25 fansi_1.0.6         scales_1.3.0        jquerylib_0.1.4     cli_3.6.2           rlang_1.1.3        </span><span class="w">
    </span><span class="c1">## [17] munsell_0.5.0       withr_3.0.0         cachem_1.1.0        yaml_2.3.8          tools_4.3.3         memoise_2.0.1       dplyr_1.1.4         colorspace_2.1-1   </span><span class="w">
    </span><span class="c1">## [25] httpuv_1.6.15       vctrs_0.6.5         R6_2.5.1            mime_0.12           lifecycle_1.0.4     pkgconfig_2.0.3     pillar_1.9.0        bslib_0.6.2        </span><span class="w">
    </span><span class="c1">## [33] later_1.3.2         gtable_0.3.4        glue_1.7.0          Rcpp_1.0.12         statmod_1.5.0       xfun_0.48           tibble_3.2.1        tidyselect_1.2.1   </span><span class="w">
    </span><span class="c1">## [41] highr_0.10          rstudioapi_0.16.0   knitr_1.45          farver_2.1.1        xtable_1.8-4        htmltools_0.5.8     labeling_0.4.3      compiler_4.3.3</span><span class="w">
</span></code></pre></div></div>]]></content><author><name></name></author><category term="statistics"/><category term="data-analysis,"/><category term="limma,"/><category term="linear-mixed-models,"/><category term="gene-expression"/><summary type="html"><![CDATA[Introduction]]></summary></entry></feed>