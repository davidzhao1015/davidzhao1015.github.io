<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://davidzhao1015.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://davidzhao1015.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-21T19:38:29+00:00</updated><id>https://davidzhao1015.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Modeling Diagnostic Delays in Rare Disease: A Survival Analysis Case Study in Python</title><link href="https://davidzhao1015.github.io/blog/2025/delay-diganosis-survival-analysis/" rel="alternate" type="text/html" title="Modeling Diagnostic Delays in Rare Disease: A Survival Analysis Case Study in Python"/><published>2025-03-03T00:00:00+00:00</published><updated>2025-03-03T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2025/delay-diganosis-survival-analysis</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2025/delay-diganosis-survival-analysis/"><![CDATA[<h1 id="introduction-why-survival-analysis">Introduction: Why Survival Analysis?</h1> <p>Rare diseases often come with a hidden burden—the <strong>delay in diagnosis</strong>. For patients with <strong>acid sphingomyelinase deficiency (ASMD)</strong>, a genetic disorder with highly variable onset and progression, the diagnostic journey can be long and uncertain. Those with <strong>chronic neurovisceral ASMD (NPD A/B)</strong> and <strong>chronic visceral ASMD (NPD B)</strong> may face <strong>years</strong> before receiving a definitive diagnosis, impacting their treatment options and long-term health outcomes.</p> <p>But how long do these delays typically last? Can we <strong>quantify</strong> the diagnostic journey and predict the likelihood of diagnosis at different time points?</p> <p>This is where <strong>survival analysis</strong> comes in. By modeling <strong>time-to-diagnosis</strong>, we can estimate <strong>median diagnostic timelines</strong>, compare different patient subgroups, and even predict when a patient is most likely to receive a diagnosis based on their clinical history. In this article, I’ll walk through the <strong>fundamentals of survival analysis</strong> and share how I applied it to ASMD patient data using Python.</p> <p>You can explore the full <a href="https://github.com/davidzhao1015/survival-analysis-case-example/blob/main/survival-analysis-ASMD-example.ipynb">notebook</a> and <a href="https://github.com/davidzhao1015/survival-analysis-case-example/blob/main/age-at-diagnosis-asmd.xlsx">dataset</a> to try the analysis yourself 🚀</p> <h2 id="my-learning-journey-in-survival-analysis">My Learning Journey in Survival Analysis</h2> <h3 id="why-i-started-exploring-survival-analysis">Why I started exploring survival analysis</h3> <p>I became interested in survival analysis because it answers a critical question: <strong>How likely is an event (such as diagnosis) to occur at a given time point, considering different covariates?</strong></p> <p>This type of analysis is widely used in: • <strong>Disease progression modeling</strong> – Understanding how long it takes for a condition to worsen. • <strong>Precision medicine</strong> – Predicting patient outcomes based on medical history. • <strong>Clinical trials</strong> – Estimating time-to-recovery, disease recurrence, or survival rates.</p> <p>Unlike conventional regression models, <strong>survival analysis can handle censored data</strong>—cases where the event of interest hasn’t occurred yet by the time of data collection. This makes it a powerful tool in both medical research and epidemiology.</p> <h3 id="key-takeaways-from-my-learning-process">Key takeaways from my learning process</h3> <p>As I explored survival analysis, I focused on three major areas:</p> <ol> <li><strong>Understanding the statistical foundations</strong> <ul> <li>The concept of <strong>censored data</strong> and why it’s important.</li> <li>Common survival models: <strong>Kaplan-Meier curves, parametric regression models, and Cox proportional hazards models</strong>.</li> <li><strong>Model selection</strong> using AIC to determine the best fit.</li> </ul> </li> <li><strong>Implementing survival analysis in Python</strong> <ul> <li>Learning by reproducing examples from <strong>tutorials and documentation</strong>.</li> <li>Using the <strong>lifelines</strong> library for survival modeling and visualization.</li> <li>Writing clean, reusable code for different types of survival models.</li> </ul> </li> <li><strong>Applying knowledge to a real-world case study</strong> <ul> <li>Choosing the right statistical models: <strong>non-parametric, semi-parametric, or parametric</strong>.</li> <li>Interpreting model coefficients <strong>in the context of a medical study</strong>.</li> <li>Creating <strong>effective and insightful plots</strong> to communicate results.</li> </ul> </li> </ol> <h3 id="how-this-method-applies-beyond-asmd">How this method applies beyond ASMD</h3> <p>While this case study focuses on <strong>time-to-diagnosis in ASMD</strong>, the approach can be generalized to many other scenarios:</p> <ul> <li>The <strong>analysis workflow</strong> can be applied to different time-to-event studies.</li> <li>The <strong>parametric models</strong> used in survival analysis can be adjusted for other medical research questions.</li> <li>The <strong>Python code</strong> can be repurposed for different datasets with minimal modifications.</li> </ul> <h3 id="what-this-post-covers">What this post covers</h3> <p>In this blog post, I’ll share:</p> <p>✅ A <strong>beginner-friendly introduction</strong> to survival analysis.</p> <p>✅ <strong>Helpful resources</strong> for learning survival analysis and Python implementation.</p> <p>✅ A <strong>step-by-step case study</strong> using ASMD diagnosis data.</p> <p>🚀 For the full code and interactive analysis, check out my <a href="https://github.com/davidzhao1015/survival-analysis-case-example/blob/main/survival-analysis-ASMD-example.ipynb">Jupyter Notebook</a></p> <p>Let’s dive in!</p> <h1 id="fundamentals-of-survival-analysis">Fundamentals of Survival Analysis</h1> <h2 id="what-is-survival-analysis">What is survival analysis?</h2> <p>Survival analysis is a statistical approach used to model <strong>time-to-event data</strong>—where the outcome of interest is the time until an event occurs. This event could be <strong>time to disease relapse</strong>, <strong>time until a diagnosis</strong>, or even <strong>time to treatment failure</strong>. Despite the name, survival analysis isn’t just about survival—it’s about understanding when an event is likely to happen.</p> <p>One of the key advantages of survival analysis is its ability to handle <strong>censored data</strong>—cases where:</p> <ul> <li><strong>Left censoring</strong> occurs when the event happened before the study began, but the exact time is unknown.</li> <li><strong>Right censoring</strong> happens when the event has not yet occurred by the end of the study period.</li> </ul> <p>Traditional regression models struggle with these challenges, but survival models are specifically designed to <strong>account for incomplete data</strong>, making them essential in epidemiology, clinical research, and beyond.</p> <h2 id="key-concepts-explained-simply">Key concepts explained simply</h2> <p><strong>Censoring</strong>: Not every subject in a study experiences the event of interest. Censoring allows us to <strong>include incomplete observations</strong>, making survival analysis more robust than conventional regression methods.</p> <p><strong>Kaplan-Meier Curve</strong>: A <strong>Kaplan-Meier curve</strong> provides a visual representation of survival probabilities over time. It plots:</p> <ul> <li><strong>Time (X-axis)</strong> vs. <strong>Probability of event-free survival (Y-axis)</strong>.</li> <li>It helps estimate how likely the event (e.g., diagnosis) will occur by a given time.</li> </ul> <p><strong>Log-Rank Test</strong>: A statistical test used to <strong>compare survival distributions</strong> between two or more independent groups. For example, it helps determine whether patients with different ASMD subtypes experience significantly different diagnostic delays.</p> <p><strong>Cox Proportional Hazards Model</strong>: A regression model that evaluates the <strong>effect of multiple variables</strong> on survival time. It helps answer questions like:</p> <ul> <li>Do certain clinical factors increase or decrease the likelihood of earlier diagnosis?</li> <li>How do different ASMD subtypes compare in terms of diagnostic delay?</li> </ul> <h2 id="resources-i-found-helpful">Resources I found helpful</h2> <p>If you’re new to survival analysis, these resources helped me grasp the fundamentals and apply them in Python:</p> <p>📺 <strong>Video Tutorial Series:</strong> <a href="https://www.youtube.com/watch?v=Wo9RNcHM_bs">Survival Analysis by DATAtab</a></p> <p>📖 <strong>Python Documentation:</strong> <a href="https://lifelines.readthedocs.io/">Lifelines Survival Analysis Library</a></p> <h1 id="asmd-case-study-analyzing-time-to-diagnosis">ASMD Case Study: Analyzing Time-to-Diagnosis</h1> <h2 id="understanding-the-dataset">Understanding the dataset</h2> <p>For this analysis, the age-at-diagnosis data derived from a <a href="https://www.sciencedirect.com/science/article/pii/S1096719216300580">scientific publication</a> by Cassiman et al. (2016) on ASMD patient outcomes.</p> <p>Each row in the dataset represents an <strong>individual patient</strong>, with the following key variables:</p> <ul> <li><strong>Time since birth (years):</strong> Age at which an event (diagnosis) occurs.</li> <li><strong>Diagnosis (event):</strong> Binary indicator of whether the patient was diagnosed (<strong>1 = diagnosed, 0 = censored</strong>).</li> <li><strong>AB subtype:</strong> Indicates disease type (<strong>0 = Type B, 1 = Type AB</strong>).</li> <li><strong>CH subtype:</strong> Indicates age group (<strong>0 = Child, 1 = Adult</strong>).</li> </ul> <p>Since some patients remained undiagnosed at the time of data collection, <strong>censored data</strong> is present—making survival analysis an ideal approach for estimating diagnostic timelines.</p> <p>👉 Next, we apply survival analysis techniques to uncover diagnostic trends and patterns.</p> <h2 id="why-survival-analysis-fits-this-problem">Why survival analysis fits this problem</h2> <p>One of the key challenges in studying <strong>diagnostic delays in ASMD</strong> is that different patient subgroups likely experience <strong>varying timelines</strong> before receiving a diagnosis. Some individuals may be diagnosed early, while others remain undiagnosed for an extended period. This variability makes it difficult to analyze the data using conventional statistical methods.</p> <p>Additionally, not all patients in the dataset have received a diagnosis at the time of study. These <strong>“still undiagnosed”</strong> cases are what we call <strong>censored data</strong>—we know that their diagnosis hasn’t happened yet, but we don’t know exactly when it will occur. Traditional regression models struggle to handle this type of incomplete data, which is where <strong>survival analysis excels</strong>.</p> <ul> <li><strong>Captures time-to-event data:</strong> Instead of treating diagnosis as a simple yes/no outcome, survival analysis allows us to model <strong>when</strong> the diagnosis occurs.</li> <li><strong>Handles censored data effectively:</strong> Patients who haven’t been diagnosed yet aren’t excluded from the analysis—they are incorporated appropriately using survival functions.</li> <li><strong>Compares different patient subgroups:</strong> By applying Kaplan-Meier curves and Cox regression models, we can compare <strong>diagnostic delays</strong> between ASMD subtypes.</li> </ul> <p>By leveraging survival analysis, we can <strong>estimate the probability of diagnosis over time</strong>, understand which patients face the longest delays, and potentially identify clinical factors that contribute to earlier or later diagnosis.</p> <h2 id="applying-survival-analysis-to-asmd-data">Applying Survival Analysis to ASMD Data</h2> <h3 id="step-by-step-survial-analysis-in-python">Step-by-Step Survial Analysis in Python</h3> <p><strong>🗃️ Data Loading and Exploration</strong></p> <ul> <li>Loaded age-at-diagnosis data from Excel using pandas.</li> <li>Each row represented a patient, with columns for age at diagnosis, event occurrence (diagnosed or not), and ASMD subtype indicators (AB, CH).</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">diagnosis_age_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_excel</span><span class="p">(</span><span class="sh">"</span><span class="s">age-at-diagnosis-asmd.xlsx</span><span class="sh">"</span><span class="p">)</span>
<span class="n">diagnosis_age_df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div> <table> <thead> <tr> <th>Time since birth (year)</th> <th>Diagnosis</th> <th>AB</th> <th>CH</th> </tr> </thead> <tbody> <tr> <td>0.10</td> <td>1</td> <td>1</td> <td>0</td> </tr> <tr> <td>0.28</td> <td>1</td> <td>1</td> <td>0</td> </tr> <tr> <td>0.36</td> <td>1</td> <td>1</td> <td>0</td> </tr> <tr> <td>0.45</td> <td>1</td> <td>1</td> <td>0</td> </tr> <tr> <td>0.45</td> <td>1</td> <td>1</td> <td>0</td> </tr> </tbody> </table> <p>📊 <strong>Kaplan-Meier Survival Curves</strong></p> <ul> <li>Used lifelines’ KaplanMeierFitter to visualize survival (i.e., undiagnosed) probability over time.</li> <li>Stratified patients by subtype: <ul> <li>Type B Adult: AB = 0, CH = 0</li> <li>Type B Child: AB = 0, CH = 1</li> <li>Type AB: AB = 1</li> </ul> </li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">lifelines</span> <span class="kn">import</span> <span class="n">KaplanMeierFitter</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">kmf</span> <span class="o">=</span> <span class="nc">KaplanMeierFitter</span><span class="p">()</span>

<span class="n">T</span> <span class="o">=</span> <span class="n">diagnosis_age_df</span><span class="p">[</span><span class="sh">"</span><span class="s">Time since birth (year)</span><span class="sh">"</span><span class="p">]</span>
<span class="n">E</span> <span class="o">=</span> <span class="n">diagnosis_age_df</span><span class="p">[</span><span class="sh">"</span><span class="s">Diagnosis</span><span class="sh">"</span><span class="p">]</span>

<span class="n">type_b_adult</span> <span class="o">=</span> <span class="p">(</span><span class="n">diagnosis_age_df</span><span class="p">[</span><span class="sh">"</span><span class="s">AB</span><span class="sh">"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">diagnosis_age_df</span><span class="p">[</span><span class="sh">"</span><span class="s">CH</span><span class="sh">"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">type_b_child</span> <span class="o">=</span> <span class="p">(</span><span class="n">diagnosis_age_df</span><span class="p">[</span><span class="sh">"</span><span class="s">AB</span><span class="sh">"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">diagnosis_age_df</span><span class="p">[</span><span class="sh">"</span><span class="s">CH</span><span class="sh">"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">type_ab</span> <span class="o">=</span> <span class="p">(</span><span class="n">diagnosis_age_df</span><span class="p">[</span><span class="sh">"</span><span class="s">AB</span><span class="sh">"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">()</span>

<span class="n">kmf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">type_b_adult</span><span class="p">],</span> <span class="n">E</span><span class="p">[</span><span class="n">type_b_adult</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Type B Adult</span><span class="sh">"</span><span class="p">).</span><span class="nf">plot_survival_function</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">kmf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">type_b_child</span><span class="p">],</span> <span class="n">E</span><span class="p">[</span><span class="n">type_b_child</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Type B Child</span><span class="sh">"</span><span class="p">).</span><span class="nf">plot_survival_function</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">kmf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">type_ab</span><span class="p">],</span> <span class="n">E</span><span class="p">[</span><span class="n">type_ab</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Type AB</span><span class="sh">"</span><span class="p">).</span><span class="nf">plot_survival_function</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Kaplan-Meier Curve of Age at Diagnosis by Subtypes</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Time since birth (year)</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Survival Probability</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/survival_KM_curve.png" sizes="95vw"/> <img src="/assets/img/survival_KM_curve.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Figure 1. The Kaplan-Meier plot for the three subtypes (Type B Adult, Type B Child, Type AB)</p> <p>Key observations:</p> <ul> <li>Type AB and Type B Child are diagnosed early: <ul> <li>Steep drop in survival curves before age 5</li> <li>Most diagnoses occur in early childhood</li> </ul> </li> <li>Type B Adult experiences delayed diagnosis: <ul> <li>Gradual decline in survival curve over several decades</li> <li>Many are diagnosed in middle age or later</li> </ul> </li> <li>Subtypes show clear separation: <ul> <li>Distinct survival curves across groups</li> <li>Statistically significant differences confirmed by log-rank test</li> </ul> </li> </ul> <p>📈 <strong>Statistical Comparison</strong></p> <p>Conducted a log-rank test to compare survival curves between subtypes and assess whether diagnostic delays differed significantly.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">lifelines</span> <span class="kn">import</span> <span class="n">WeibullFitter</span><span class="p">,</span> <span class="n">ExponentialFitter</span><span class="p">,</span> <span class="n">LogNormalFitter</span>

<span class="n">models</span> <span class="o">=</span> <span class="p">[</span>
    <span class="nc">WeibullFitter</span><span class="p">().</span><span class="nf">fit</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">E</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Weibull</span><span class="sh">"</span><span class="p">),</span>
    <span class="nc">ExponentialFitter</span><span class="p">().</span><span class="nf">fit</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">E</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Exponential</span><span class="sh">"</span><span class="p">),</span>
    <span class="nc">LogNormalFitter</span><span class="p">().</span><span class="nf">fit</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">E</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Log-Normal</span><span class="sh">"</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">()</span>

<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">plot_survival_function</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">aic</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">AIC_</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mf">0.8</span> <span class="o">-</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">models</span><span class="p">.</span><span class="nf">index</span><span class="p">(</span><span class="n">model</span><span class="p">),</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">_label</span><span class="si">}</span><span class="s"> AIC: </span><span class="si">{</span><span class="n">aic</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Model Comparison by AIC</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Time since birth (year)</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Survival Probability</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/survival_AIC.png" sizes="95vw"/> <img src="/assets/img/survival_AIC.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Figure 2. The survival functions overlaid with AIC values.</p> <p>🧮 <strong>Parametric Model Fitting</strong></p> <ul> <li>Fit various models including Weibull, Log-Normal, Exponential, Log-Logistic, and Generalized Gamma.</li> <li>Compared model fit using AIC (Akaike Information Criterion).</li> <li>Selected Log-Normal AFT as the best-performing model.</li> </ul> <p>🔍 <strong>Prediction by Subtype</strong></p> <ul> <li>Applied the best model to predict survival (undiagnosed) probability curves for each subtype across a 0–100 year timespan.</li> <li>Visualized predictions with subtype-specific curves—helpful for clinicians and researchers interpreting diagnosis timelines.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">lifelines</span> <span class="kn">import</span> <span class="n">LogNormalAFTFitter</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">lognorm_aft</span> <span class="o">=</span> <span class="nc">LogNormalAFTFitter</span><span class="p">()</span>
<span class="n">lognorm_aft</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">diagnosis_age_df</span><span class="p">,</span> <span class="n">duration_col</span><span class="o">=</span><span class="sh">"</span><span class="s">Time since birth (year)</span><span class="sh">"</span><span class="p">,</span> <span class="n">event_col</span><span class="o">=</span><span class="sh">"</span><span class="s">Diagnosis</span><span class="sh">"</span><span class="p">)</span>

<span class="n">new_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">"</span><span class="s">AB</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="sh">"</span><span class="s">CH</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]})</span>
<span class="n">times</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="n">survival_probs</span> <span class="o">=</span> <span class="n">lognorm_aft</span><span class="p">.</span><span class="nf">predict_survival_function</span><span class="p">(</span><span class="n">new_data</span><span class="p">,</span> <span class="n">times</span><span class="o">=</span><span class="n">times</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">survival_probs</span><span class="p">.</span><span class="nf">plot</span><span class="p">()</span>

<span class="n">ax</span><span class="p">.</span><span class="nf">legend</span><span class="p">([</span><span class="sh">"</span><span class="s">Type B Adult</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Type B Child</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Type AB</span><span class="sh">"</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Predicted Survival Curve – Log-Normal AFT</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Time since birth (year)</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Survival Probability</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/survival_prediction.png" sizes="95vw"/> <img src="/assets/img/survival_prediction.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Figure 3. The predicted survival function showing how diagnosis probability changes by subtype.</p> <h2 id="findings--implications">Findings &amp; Implications</h2> <p>This analysis showed clear differences in time-to-diagnosis across ASMD subtypes. Kaplan-Meier curves revealed that Type AB and childhood-onset Type B patients were diagnosed earlier, while adult-onset Type B cases experienced the longest delays. The Log-Normal AFT model provided the best fit for modeling these differences and enabled prediction of diagnosis probabilities by subtype.</p> <p>While this example focuses on ASMD, the same survival modeling techniques can be adapted to other rare diseases to quantify diagnostic delays, compare patient subgroups, or support screening research. The methods demonstrated here—handling censored data, fitting multiple survival models, and interpreting time-to-event probabilities—are broadly useful in medical data analysis.</p> <h1 id="4-key-learning--takeaways">4. Key learning &amp; takeaways</h1> <p>Here are some key lessons I gained while working through this survival analysis project:</p> <p>What I Learned About Survival Analysis</p> <ul> <li>There are three major categories of survival models: <ul> <li>Non-parametric (e.g., Kaplan-Meier): flexible, assumption-free, and good for descriptive analysis</li> <li>Parametric (e.g., Weibull, Log-Normal): useful for prediction and interpretation when assumptions are met</li> <li>Semi-parametric (e.g., Cox regression): interpretable and flexible for covariates, without requiring full distributional assumptions</li> </ul> </li> <li>AIC (Akaike Information Criterion) is a valuable tool for selecting the best-fit model among several options.</li> <li>When visualizing survival curves with lifelines, it’s helpful to: <ul> <li>Include 95% confidence intervals to convey uncertainty</li> <li>Display at-risk tables to show how many events (diagnoses or censored cases) are observed over time</li> </ul> </li> </ul> <p>Practical Challenges and How I Overcame Them</p> <ul> <li>Survival analysis differs conceptually from typical regression. Grasping its unique assumptions and knowing how to interpret coefficients was essential to making sense of the results.</li> <li>Implementing survival models in Python involved trial and error. I relied on: <ul> <li>lifelines documentation</li> <li>Reproducing basic examples</li> <li>Experimentation and patience when adapting methods to real-world data, which is often messier than toy examples</li> </ul> </li> </ul> <p>Tips for Beginners</p> <ul> <li>Start with the fundamentals: understand basic statistical concepts and what survival analysis is trying to solve.</li> <li>Gain working knowledge of key survival algorithms (Kaplan-Meier, Cox, Log-Normal, etc.).</li> <li>Be patient—coding survival models takes attention to detail and a willingness to try, tweak, and retry. Real-world datasets rarely behave like textbook examples, so iteration is part of the process.</li> </ul>]]></content><author><name></name></author><category term="statistics"/><category term="survival-analysis;"/><category term="rare-disease;"/><category term="ASMD;"/><category term="python"/><summary type="html"><![CDATA[Introduction: Why Survival Analysis?]]></summary></entry><entry><title type="html">Beyond Heatmaps: Mapping Two Variables with Plotly in Public Health</title><link href="https://davidzhao1015.github.io/blog/2025/plotly-maps-public-health/" rel="alternate" type="text/html" title="Beyond Heatmaps: Mapping Two Variables with Plotly in Public Health"/><published>2025-01-27T00:00:00+00:00</published><updated>2025-01-27T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2025/plotly-maps-public-health</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2025/plotly-maps-public-health/"><![CDATA[<h2 id="background">Background</h2> <p>In public health and epidemiology, data visualization isn’t just about aesthetics—it’s about clarity, impact, and storytelling. Choropleth maps, which color-code geographic areas based on variable intensity, are a go-to tool for illustrating spatial trends in disease burden, health behaviors, or population risk factors.</p> <p>But what if you want to compare <strong>two variables simultaneously</strong> on the same geographic map?</p> <p>This is a common challenge in health data storytelling. For instance, imagine you’re studying the <strong>distribution of a dietary habit</strong> and the <strong>associated disease outcomes</strong>—how do you present this relationship clearly and intuitively?</p> <p><strong>💡 Innovation Highlight</strong> Overlay a <strong>bubble map</strong> on top of a choropleth map. The base layer (choropleth) provides a regional context for one variable, while the overlaid bubbles show the intensity of another, allowing for quick visual comparisons.</p> <p>This post shows how to combine two variables on a single map using a dual-layer approach — choropleth for spatial intensity + bubble size for a second variable. It’s a simple but powerful storytelling technique.</p> <h3 id="-real-world-example">📌 Real-World Example</h3> <p>In 2020, a <a href="https://www.medrxiv.org/content/10.1101/2020.07.06.20147025v1">preprint</a> suggested that <strong>fermented vegetable consumption</strong> might be inversely associated with <strong>COVID-19 mortality</strong> in Europe—even after adjusting for confounding factors. I wanted to explore that hypothesis using public data and an interactive map.</p> <hr/> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/snapshort_final_map.png" sizes="95vw"/> <img src="/assets/img/snapshort_final_map.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>This interactive map overlays fermented food intake (bubbles) on COVID-19 death rates (color). Scroll down to learn how it’s built.</p> <hr/> <h2 id="-quick-start">📦 Quick Start</h2> <ol> <li>Install dependencies</li> <li>Download the dataset (<a href="https://github.com/davidzhao1015/plotly-bubble-choropleth/tree/main/input_csv">link</a>)</li> <li>Run the notebook (<a href="https://hub.2i2c.mybinder.org/user/davidzhao1015-p-bble-choropleth-cx8i7dbv/doc/tree/interactive-map-covid-fermented-food_v3.ipynb">link</a>)</li> <li>Explore the interactive map</li> </ol> <hr/> <h2 id="what-youll-need-to-recreate-this-map"><strong>What You’ll Need to Recreate This Map</strong></h2> <p>To recreate the interactive map and plots in this post, you’ll need a few Python packages commonly used in data science:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Core data handling
</span><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="c1"># Interactive map visualization
</span><span class="kn">import</span> <span class="n">plotly.express</span> <span class="k">as</span> <span class="n">px</span> <span class="c1"># Creating choropleth and scatter_geo maps
</span><span class="kn">import</span> <span class="n">plotly.graph_objects</span> <span class="k">as</span> <span class="n">go</span> <span class="c1"># Overlaying plot layers and annotation
</span>
<span class="c1"># For geospatial data 
</span><span class="kn">import</span> <span class="n">requests</span> <span class="c1"># Fetching GeoJSON data from remote URL 
</span><span class="kn">import</span> <span class="n">json</span> <span class="c1"># Parsing JSON data
</span><span class="kn">import</span> <span class="n">pycountry</span> <span class="c1"># Mapping country names to ISO alpha-3 codes
</span>
<span class="c1"># For exporting maps
</span><span class="kn">import</span> <span class="n">plotly.io</span> <span class="k">as</span> <span class="n">pio</span> <span class="c1"># Exporting Plotly figures as HTML
</span><span class="kn">import</span> <span class="n">kaleido</span>  <span class="c1"># Saving Plotly maps as static images (optional)
</span></code></pre></div></div> <p>💡 <strong>Tip:</strong> This tutorial uses Python packages like pandas, plotly, and pycountry. You can install all dependencies by running:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt
</code></pre></div></div> <p>Or check out the full notebook on <a href="https://github.com/yourusername/repo-name">GitHub</a> to explore the code and interactive map.</p> <h3 id="why-plotlyexpress"><strong>Why plotly.express?</strong></h3> <p>For this project, I used plotly.express to create <strong>interactive choropleth and bubble maps</strong>. Unlike traditional plotting libraries like matplotlib, plotly.express lets you explore maps by hovering, zooming, and clicking — all right inside your browser or Jupyter Notebook.</p> <p>It’s a powerful yet beginner-friendly way to bring geographic data to life.</p> <p>The official tutorials for choropleth are <a href="https://plotly.com/python/choropleth-maps/">here</a>, and for bubble map is <a href="https://plotly.com/python/bubble-maps/">here</a>.</p> <hr/> <h2 id="preparing-the-epidemiological-data"><strong>Preparing the Epidemiological Data</strong></h2> <p>Before visualizing our map, we first need to get the data into the right shape. In this case, we’re combining datasets on:</p> <ul> <li>COVID-19 mortality rates (per million people)</li> <li>Fermented food consumption (e.g. sauerkraut, pickled vegetables)</li> </ul> <p>Let’s walk through the key steps.</p> <p><strong>📂 1. Load Data from CSV</strong></p> <p>We read the data using pandas — a Python package that makes working with tables easy:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># Load COVID-19 mortality rate dataset
</span><span class="n">COVID_death_pop_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">COVID_mortality_rate.csv</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Load fermented vegetables dataset
</span><span class="n">avg_consumption_country</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">fermented_food_consumption.csv</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p><strong>🔄 2. Merge Datasets</strong></p> <p>We then renamed some columns for clarity and merged additional information, like ISO codes and population:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Merge fermented vegetable data with COVID-19 mortality rate data
</span><span class="n">eu_avg_consumption_COVID_death_pop_df</span> <span class="o">=</span> <span class="n">eu_avg_consumption_country</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">COVID_death_pop_df</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="sh">'</span><span class="s">Country</span><span class="sh">'</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Inspect first rows in the merged dataset
</span><span class="n">eu_avg_consumption_COVID_death_pop_df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>   
</code></pre></div></div> <p>The frist rows in the merged dataset:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">Country</span>	<span class="n">Average</span> <span class="n">Consumption</span>	<span class="n">Year</span>	<span class="n">Population</span>	<span class="n">Deaths</span>	<span class="n">Death</span> <span class="n">Rate</span>
<span class="mi">0</span>	<span class="n">France</span>	<span class="mf">1.135681</span>	<span class="mi">2020</span>	<span class="mf">67473651.0</span>	<span class="mf">9284524.0</span>	<span class="mf">0.137602</span>
<span class="mi">1</span>	<span class="n">France</span>	<span class="mf">1.135681</span>	<span class="mi">2021</span>	<span class="mf">67728568.0</span>	<span class="mf">38470807.0</span>	<span class="mf">0.568014</span>
<span class="mi">2</span>	<span class="n">France</span>	<span class="mf">1.135681</span>	<span class="mi">2022</span>	<span class="mf">67957053.0</span>	<span class="mf">54424558.0</span>	<span class="mf">0.800867</span>
<span class="mi">3</span>	<span class="n">France</span>	<span class="mf">1.135681</span>	<span class="mi">2023</span>	<span class="mf">68172977.0</span>	<span class="mf">11230468.0</span>	<span class="mf">0.164735</span>
<span class="mi">4</span>	<span class="n">Czechia</span>	<span class="mf">5.578666</span>	<span class="mi">2020</span>	<span class="mf">10693939.0</span>	<span class="mf">600899.0</span>	<span class="mf">0.056191</span>

</code></pre></div></div> <p><strong>🌍 3. Add Country Codes for Mapping</strong></p> <p>Using pycountry, we convert country names to ISO 3-letter codes so they can be matched to the map:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pycountry</span>

<span class="c1"># List of EU countries
</span><span class="n">eu_countries</span> <span class="o">=</span> <span class="n">eu_avg_consumption_COVID_death_pop_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Country</span><span class="sh">'</span><span class="p">].</span><span class="nf">unique</span><span class="p">().</span><span class="nf">tolist</span><span class="p">()</span>   

<span class="c1"># Dictionary of country names and their corresponding alpha_3 codes
</span><span class="n">country_alpha3</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">country</span> <span class="ow">in</span> <span class="n">eu_countries</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">country_data</span> <span class="o">=</span> <span class="n">pycountry</span><span class="p">.</span><span class="n">countries</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">country</span><span class="p">)</span>
        <span class="c1"># print(country_data.alpha_3)
</span>        <span class="n">country_alpha3</span><span class="p">[</span><span class="n">country</span><span class="p">]</span> <span class="o">=</span> <span class="n">country_data</span><span class="p">.</span><span class="n">alpha_3</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">country</span><span class="si">}</span><span class="s"> not found</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <hr/> <h2 id="how-do-we-get-map-data-in-python"><strong>How Do We Get Map Data in Python?</strong></h2> <p>To create interactive maps, we need two things:</p> <ol> <li>A base map that knows the shape of each country (like a digital atlas 📐)</li> <li>A way to match our data (e.g. COVID deaths, food consumption) to the correct country</li> </ol> <p>In this project, we used two helpful Python tools to achieve that:</p> <p><strong>🧩 1. requests + json: Loading the World Map</strong></p> <p>We downloaded a GeoJSON file — which is a special file format that stores map shapes — using Python’s requests module:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">requests</span>
<span class="kn">import</span> <span class="n">json</span>

<span class="n">url</span> <span class="o">=</span> <span class="sh">'</span><span class="s">https://raw.githubusercontent.com/johan/world.geo.json/master/countries.geo.json</span><span class="sh">'</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">geojson_data</span> <span class="o">=</span> <span class="n">response</span><span class="p">.</span><span class="nf">json</span><span class="p">()</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Filter the geojson for EU 
</span><span class="n">eu_geojson</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">type</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">FeatureCollection</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">features</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span>
        <span class="n">feature</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">geojson_data</span><span class="p">[</span><span class="sh">"</span><span class="s">features</span><span class="sh">"</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">feature</span><span class="p">[</span><span class="sh">"</span><span class="s">properties</span><span class="sh">"</span><span class="p">][</span><span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">]</span> <span class="ow">in</span> <span class="n">targeted_countries</span>
    <span class="p">]</span>
<span class="p">}</span>
</code></pre></div></div> <p><strong>🏷️ 2. pycountry: Matching Country Names to ISO Codes</strong></p> <p>Our datasets (like food consumption) use country names such as “Germany” or “Vietnam”. But map files often use short codes like “DEU” or “VNM”.</p> <p>We used the pycountry module to automatically convert country names into standardized ISO codes:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pycountry</span>

<span class="c1"># List of EU countries
</span><span class="n">eu_countries</span> <span class="o">=</span> <span class="n">eu_avg_consumption_COVID_death_pop_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Country</span><span class="sh">'</span><span class="p">].</span><span class="nf">unique</span><span class="p">().</span><span class="nf">tolist</span><span class="p">()</span>   

<span class="c1"># Dictionary of country names and their corresponding alpha_3 codes
</span><span class="n">country_alpha3</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">country</span> <span class="ow">in</span> <span class="n">eu_countries</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">country_data</span> <span class="o">=</span> <span class="n">pycountry</span><span class="p">.</span><span class="n">countries</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">country</span><span class="p">)</span>
        <span class="c1"># print(country_data.alpha_3)
</span>        <span class="n">country_alpha3</span><span class="p">[</span><span class="n">country</span><span class="p">]</span> <span class="o">=</span> <span class="n">country_data</span><span class="p">.</span><span class="n">alpha_3</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">country</span><span class="si">}</span><span class="s"> not found</span><span class="sh">"</span><span class="p">)</span>
        
 <span class="nf">print</span><span class="p">(</span><span class="n">country_alpha3</span><span class="p">)</span>
</code></pre></div></div> <p>Together, these two steps make it possible to visualize complex health and nutrition data on an interactive world map!</p> <hr/> <h2 id="choropleth-map--background-color-by-average-fermented-vegetables-consumption"><strong>Choropleth Map – Background Color by Average Fermented Vegetables Consumption</strong></h2> <p>This map shows average fermented vegetable consumption by country, shaded by intensity:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create a Choropleth map (for country colors) based on fermented vegetable consumption
</span><span class="n">food_map</span> <span class="o">=</span> <span class="n">px</span><span class="p">.</span><span class="nf">choropleth</span><span class="p">(</span>
    <span class="n">data_map_2020</span><span class="p">,</span>
    <span class="n">locations</span><span class="o">=</span><span class="sh">"</span><span class="s">iso_alpha</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">Average Consumption</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">hover_name</span><span class="o">=</span><span class="sh">"</span><span class="s">Country</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">scope</span><span class="o">=</span><span class="sh">"</span><span class="s">europe</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">projection</span><span class="o">=</span><span class="sh">"</span><span class="s">natural earth</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">color_continuous_scale</span><span class="o">=</span><span class="sh">'</span><span class="s">Plasma</span><span class="sh">'</span>
<span class="p">)</span>
</code></pre></div></div> <p>🖼️ ⬇️ Example Output</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/snapshot_choropleth_map_fermented_food.png" sizes="95vw"/> <img src="/assets/img/snapshot_choropleth_map_fermented_food.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><strong>Bubble Overlay – COVID-19 mortality rates by countriescountries</strong></p> <p>We then add circle markers to indicate COVID-19 mortality rates per country. Bigger bubbles = more intake.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">plotly.graph_objects</span> <span class="k">as</span> <span class="n">go</span>

<span class="n">bubble_map</span> <span class="o">=</span> <span class="n">px</span><span class="p">.</span><span class="nf">scatter_geo</span><span class="p">(</span><span class="n">data_map_2020</span><span class="p">,</span>
                            <span class="n">locations</span><span class="o">=</span><span class="sh">"</span><span class="s">iso_alpha</span><span class="sh">"</span><span class="p">,</span>
                            <span class="n">hover_name</span><span class="o">=</span><span class="sh">"</span><span class="s">Country</span><span class="sh">"</span><span class="p">,</span>
                            <span class="n">size</span><span class="o">=</span><span class="sh">"</span><span class="s">Death Rate</span><span class="sh">"</span><span class="p">,</span>
                            <span class="n">scope</span><span class="o">=</span><span class="sh">"</span><span class="s">europe</span><span class="sh">"</span><span class="p">,</span>
                            <span class="n">projection</span><span class="o">=</span><span class="sh">"</span><span class="s">natural earth</span><span class="sh">"</span><span class="p">,</span>
                            <span class="n">opacity</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="c1"># Set opacity level for better visibility
</span>                            <span class="n">size_max</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
                            <span class="n">color_continuous_scale</span><span class="o">=</span><span class="n">px</span><span class="p">.</span><span class="n">colors</span><span class="p">.</span><span class="n">sequential</span><span class="p">.</span><span class="n">Plasma</span><span class="p">)</span>
</code></pre></div></div> <p>🖼️ ⬇️ Example Output:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/snapshot_bubble_map_COVID.png" sizes="95vw"/> <img src="/assets/img/snapshot_bubble_map_COVID.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><strong>Combine Both Layers</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Combine both layers
</span><span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="p">.</span><span class="nc">Figure</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">food_map</span><span class="p">.</span><span class="n">data</span> <span class="o">+</span> <span class="n">bubble_map</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
</code></pre></div></div> <h3 id="-why-these-steps-matter"><strong>🎯 Why These Steps Matter</strong></h3> <p>This combination allows us to visualize two variables on the same map:</p> <ul> <li>💀 Red shading = how bad COVID-19 outcomes were</li> <li>🥬 Bubble size = how much fermented food people eat</li> </ul> <p>It opens up exploratory insights like:</p> <blockquote> <p>“Do countries with more fermented vegetable consumption have lower COVID-19 death rates?”</p> </blockquote> <p>This dual-layer approach makes it intuitive to compare variables geographically.</p> <h3 id="fine-tuning-the-map-for-clarity--style"><strong>Fine-Tuning the Map for Clarity &amp; Style</strong></h3> <p>Once we’ve layered the choropleth and bubbles, we fine-tune the map to make it easier to understand and more visually polished.</p> <p>Here are some key adjustments made in the notebook:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Improve layout
</span><span class="n">fig</span><span class="p">.</span><span class="nf">update_geos</span><span class="p">(</span>
    <span class="n">scope</span><span class="o">=</span><span class="sh">"</span><span class="s">europe</span><span class="sh">"</span><span class="p">,</span> <span class="c1"># Only show European countries
</span>    <span class="n">showcoastlines</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
    <span class="n">showland</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
    <span class="n">landcolor</span><span class="o">=</span><span class="sh">"</span><span class="s">lightgray</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">projection_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">update_layout</span><span class="p">(</span>
    <span class="n">coloraxis_colorbar_title</span><span class="o">=</span><span class="sh">"</span><span class="s">Fermented Vegetable Consumption</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">coloraxis_colorscale</span><span class="o">=</span><span class="sh">"</span><span class="s">RdYlBu</span><span class="sh">"</span> <span class="p">,</span> <span class="c1"># Change color scale
</span>    <span class="n">width</span><span class="o">=</span><span class="mi">1200</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">coloraxis_colorbar</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span>
        <span class="n">orientation</span><span class="o">=</span><span class="sh">"</span><span class="s">h</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Set colorbar horizontal
</span>        <span class="n">title</span><span class="o">=</span><span class="sh">"</span><span class="s">Fermented Vegetable Consumption</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">title_side</span><span class="o">=</span><span class="sh">"</span><span class="s">top</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">title_font_size</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">thickness</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>  <span class="c1"># Adjust colorbar width
</span>        <span class="nb">len</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>  <span class="c1"># Adjust colorbar height (relative size)
</span>        <span class="n">x</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>  <span class="c1"># Move colorbar horizontally
</span>        <span class="n">y</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>  <span class="c1"># Move colorbar vertically
</span>    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">update_layout</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span>
        <span class="n">text</span><span class="o">=</span><span class="sh">"</span><span class="s">Fermented Vegetable Consumption and COVID-19 Death Rate in Europe (2020)</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">x</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>  <span class="c1"># Center the title
</span>        <span class="n">y</span><span class="o">=</span><span class="mf">0.98</span><span class="p">,</span>  <span class="c1"># Position it above the colorbar
</span>        <span class="n">xanchor</span><span class="o">=</span><span class="sh">"</span><span class="s">center</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Ensure proper centering
</span>        <span class="n">yanchor</span><span class="o">=</span><span class="sh">"</span><span class="s">top</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Anchor at the top
</span>        <span class="n">font</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span>
            <span class="n">size</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span>  <span class="c1"># Increase font size for better readability
</span>            <span class="n">family</span><span class="o">=</span><span class="sh">"</span><span class="s">Arial, sans-serif</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Use a professional font
</span>            <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">black</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Set color (adjust if needed)
</span>            <span class="n">weight</span><span class="o">=</span><span class="sh">"</span><span class="s">bold</span><span class="sh">"</span>  <span class="c1"># Bolden the title (alternative: use "&lt;b&gt;Title&lt;/b&gt;" in text)
</span>        <span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">update_layout</span><span class="p">(</span>
    <span class="n">coloraxis_colorbar</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span>
        <span class="n">orientation</span><span class="o">=</span><span class="sh">"</span><span class="s">h</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Horizontal colorbar
</span>        <span class="n">x</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">y</span><span class="o">=-</span><span class="mf">0.15</span><span class="p">,</span>  <span class="c1"># Move below the map
</span>        <span class="nb">len</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">thickness</span><span class="o">=</span><span class="mi">10</span>
    <span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div> <p>These tweaks:</p> <ul> <li>Geographic layout</li> <li>Colorbar customization</li> <li>Title configuration</li> <li>Additional colorbar adjustment</li> </ul> <p><strong>Annotate country names to the map</strong></p> <p>To make the map more professional-looking and easier to interpret, we apply layout settings:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># Create the DataFrame
</span><span class="n">country_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span>
    <span class="sh">"</span><span class="s">Country</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="sh">"</span><span class="s">Austria</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Belgium</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Bulgaria</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Bosnia and Herzegovina</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Germany</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Estonia</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Finland</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">France</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">United Kingdom</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Greece</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Croatia</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Hungary</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Latvia</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Montenegro</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Netherlands</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Poland</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Portugal</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Romania</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Slovenia</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Sweden</span><span class="sh">"</span><span class="p">],</span>
    <span class="sh">"</span><span class="s">ISO3</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="sh">"</span><span class="s">AUT</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">BEL</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">BGR</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">BIH</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">DEU</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">EST</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">FIN</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">FRA</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">GBR</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">GRC</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">HRV</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">HUN</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">LVA</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">MNE</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">NLD</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">POL</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">PRT</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">ROU</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">SVN</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">SWE</span><span class="sh">"</span><span class="p">],</span>
    <span class="sh">"</span><span class="s">Lat</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mf">47.5162</span><span class="p">,</span> <span class="mf">50.5039</span><span class="p">,</span> <span class="mf">42.7339</span><span class="p">,</span> <span class="mf">43.9159</span><span class="p">,</span> <span class="mf">51.1657</span><span class="p">,</span> <span class="mf">58.5953</span><span class="p">,</span> <span class="mf">61.9241</span><span class="p">,</span> <span class="mf">46.6034</span><span class="p">,</span> <span class="mf">55.3781</span><span class="p">,</span> <span class="mf">39.0742</span><span class="p">,</span> <span class="mf">45.1</span><span class="p">,</span> <span class="mf">47.1625</span><span class="p">,</span> <span class="mf">56.8796</span><span class="p">,</span> <span class="mf">42.7087</span><span class="p">,</span> <span class="mf">52.1326</span><span class="p">,</span> <span class="mf">51.9194</span><span class="p">,</span> <span class="mf">39.3999</span><span class="p">,</span> <span class="mf">45.9432</span><span class="p">,</span> <span class="mf">46.1512</span><span class="p">,</span> <span class="mf">60.1282</span><span class="p">],</span>
    <span class="sh">"</span><span class="s">Lon</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="mf">14.5501</span><span class="p">,</span> <span class="mf">4.4699</span><span class="p">,</span> <span class="mf">25.4858</span><span class="p">,</span> <span class="mf">17.6791</span><span class="p">,</span> <span class="mf">10.4515</span><span class="p">,</span> <span class="mf">25.0136</span><span class="p">,</span> <span class="mf">25.7482</span><span class="p">,</span> <span class="mf">1.8883</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.4360</span><span class="p">,</span> <span class="mf">21.8243</span><span class="p">,</span> <span class="mf">15.2</span><span class="p">,</span> <span class="mf">19.5033</span><span class="p">,</span> <span class="mf">24.6032</span><span class="p">,</span> <span class="mf">19.3744</span><span class="p">,</span> <span class="mf">5.2913</span><span class="p">,</span> <span class="mf">19.1451</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.2245</span><span class="p">,</span> <span class="mf">24.9668</span><span class="p">,</span> <span class="mf">14.9955</span><span class="p">,</span> <span class="mf">18.6435</span><span class="p">]</span>
<span class="p">})</span>

<span class="kn">import</span> <span class="n">plotly.graph_objects</span> <span class="k">as</span> <span class="n">go</span>

<span class="c1"># Create the country label layer (scattergeo)
</span><span class="n">country_labels</span> <span class="o">=</span> <span class="n">go</span><span class="p">.</span><span class="nc">Scattergeo</span><span class="p">(</span>
    <span class="n">locationmode</span><span class="o">=</span><span class="sh">"</span><span class="s">ISO-3</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">lon</span><span class="o">=</span><span class="n">country_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Lon</span><span class="sh">"</span><span class="p">],</span>
    <span class="n">lat</span><span class="o">=</span><span class="n">country_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Lat</span><span class="sh">"</span><span class="p">],</span>
    <span class="n">text</span><span class="o">=</span><span class="n">country_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Country</span><span class="sh">"</span><span class="p">],</span>  <span class="c1"># Display country names
</span>    <span class="n">mode</span><span class="o">=</span><span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Only text (no markers)
</span>    <span class="n">textfont</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">black</span><span class="sh">"</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="sh">"</span><span class="s">Arial</span><span class="sh">"</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="sh">"</span><span class="s">bold</span><span class="sh">"</span><span class="p">),</span>  <span class="c1"># Adjust font
</span>    <span class="n">textposition</span><span class="o">=</span><span class="sh">"</span><span class="s">top center</span><span class="sh">"</span><span class="p">,</span>  
    <span class="n">showlegend</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span>

<span class="c1"># Add to your existing Plotly figure
</span><span class="n">fig</span><span class="p">.</span><span class="nf">add_trace</span><span class="p">(</span><span class="n">country_labels</span><span class="p">)</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/snapshot_added_country_names.png" sizes="95vw"/> <img src="/assets/img/snapshot_added_country_names.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Explore the full interactive version on <a href="https://davidzhao1015.github.io/plotly-bubble-choropleth/">GitHub</a>.</p> <p><strong>Exporting the Map (Optional)</strong></p> <p>Want to save your plot as an image or HTML? Use:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pio</span><span class="p">.</span><span class="nf">write_image</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="sh">'</span><span class="s">fermented_vegetable_consumption_COVID_death_rate_europe_2020.png</span><span class="sh">'</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="sh">'</span><span class="s">png</span><span class="sh">'</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">1200</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>                  <span class="c1"># Save as PNG
</span>
<span class="n">pio</span><span class="p">.</span><span class="nf">write_html</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="nb">file</span><span class="o">=</span><span class="sh">'</span><span class="s">index.html</span><span class="sh">'</span><span class="p">,</span> <span class="n">auto_open</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>       <span class="c1"># Save as interactive webpage
</span></code></pre></div></div> <p>This step is great for sharing visuals in presentations or embedding interactive plots on your own blog or website.</p> <p>Together, these finishing touches elevate your map from “functional” to “insightful and polished.” They also make the visualization more friendly to readers who are new to data exploration or unfamiliar with the dataset.</p> <hr/> <h3 id="-what-does-the-map-tell-us"><strong>📖 What Does the Map Tell Us?</strong></h3> <p>As we zoom into this interactive map, a few patterns emerge:</p> <ul> <li>Countries like France and Germany — with relatively high intake of fermented vegetables — show noticeably lower COVID-19 mortality in this 2020 dataset.</li> <li>On the other hand, countries with lower fermented food consumption, such as the UK or Belgium, show higher death rates.</li> <li>While this map doesn’t prove causality, it does support the hypothesis from [the original study] that dietary habits might influence immune resilience — a fascinating intersection of public health and nutrition.</li> </ul> <p>Of course, many other factors (like healthcare infrastructure or testing policies) may also be at play. But that’s the beauty of this kind of map — it opens up questions and encourages deeper exploration.</p>]]></content><author><name></name></author><category term="data-visualization;"/><category term="epidemiology;"/><category term="plolty;"/><category term="choropleth-map;"/><category term="fermented-food;"/><category term="COVID-19"/><summary type="html"><![CDATA[Background In public health and epidemiology, data visualization isn’t just about aesthetics—it’s about clarity, impact, and storytelling. Choropleth maps, which color-code geographic areas based on variable intensity, are a go-to tool for illustrating spatial trends in disease burden, health behaviors, or population risk factors.]]></summary></entry><entry><title type="html">How to Import Excel Files in Python</title><link href="https://davidzhao1015.github.io/blog/2024/import-spreadsheet-python/" rel="alternate" type="text/html" title="How to Import Excel Files in Python"/><published>2024-12-24T00:00:00+00:00</published><updated>2024-12-24T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2024/import-spreadsheet-python</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2024/import-spreadsheet-python/"><![CDATA[<h2 id="purpose">Purpose</h2> <p>Ever struggled to import Excel data into Python for analysis? This post will guide you step-by-step on how to use <strong>Pandas</strong> to handle Excel files effortlessly, even for complex datasets.</p> <hr/> <h2 id="excel-data-essentials">Excel Data Essentials</h2> <p>Excel is a go-to tool for managing and analyzing data. Let’s refresh some key terms to ensure smooth communication:</p> <ul> <li><strong>Workbook</strong>: The entire Excel file.</li> <li><strong>Worksheet</strong>: Individual sheets (or tabs) within the workbook.</li> <li><strong>Header</strong>: Labels at the top defining columns (e.g., A, B, C).</li> <li><strong>Cells</strong>: Data units located at row-column intersections, like A1.</li> </ul> <p>If these terms feel familiar, great! If not, think of them as the building blocks for working with Excel in Python.</p> <hr/> <h2 id="everyday-functionality-importing-excel-files-in-pandas">Everyday Functionality: Importing Excel Files in Pandas</h2> <h3 id="real-world-scenario-metabolomics-data">Real-World Scenario: Metabolomics Data</h3> <p>Imagine you’re analyzing LC/MS metabolomics data from animal samples, with additional metadata. This was my experience at the metabolomics research center, where I worked with a dataset containing:</p> <ol> <li><strong>Biomarker Assay Worksheet</strong>: Measurements for over 100 metabolites.</li> </ol> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/snapshot_biomarker_worksheet.png" sizes="95vw"/> <img src="/assets/img/snapshot_biomarker_worksheet.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <ol> <li><strong>Metadata Worksheet</strong>: Sample information.</li> </ol> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/snapshot_metadata_worksheet.png" sizes="95vw"/> <img src="/assets/img/snapshot_metadata_worksheet.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <hr/> <h2 id="step-by-step-guide">Step-by-Step Guide</h2> <h3 id="1-import-multiple-worksheets">1. Import Multiple Worksheets</h3> <p>Start by loading a specific worksheet while skipping descriptive rows:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span> 

<span class="n">df_biomarker_assay</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_excel</span><span class="p">(</span>
    <span class="sh">'</span><span class="s">example-biomarker-assay.xlsx</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">sheet_name</span><span class="o">=</span><span class="sh">'</span><span class="s">Biomarker assay</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">skiprows</span><span class="o">=</span><span class="mi">11</span>
<span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; df_biomarker_assay.head()
  Sample ID  Creatinine    Glycine     Alanine     Serine Histamine  ...  C16:1OH     C16OH     C18:2     C18:1       C18   C18:1OH
0  LODs(uM)    0.443131   0.859107    0.340909   0.042433  0.013605  ...  0.04906  0.042617  0.058089  0.041081  0.023651  0.056784
1         1   14.600000  51.600000  264.000000  65.100000     &lt; LOD  ...    &lt; LOD     &lt; LOD     &lt; LOD     &lt; LOD     &lt; LOD     &lt; LOD
2         2   14.000000  98.100000  338.000000  87.000000     &lt; LOD  ...    &lt; LOD     &lt; LOD     &lt; LOD     &lt; LOD     &lt; LOD     &lt; LOD
3         3   11.200000  92.000000  329.000000  74.500000     &lt; LOD  ...    &lt; LOD     &lt; LOD     &lt; LOD  0.045089     &lt; LOD     &lt; LOD
4         4   11.600000  77.500000  200.000000  62.400000     &lt; LOD  ...    &lt; LOD     &lt; LOD     &lt; LOD   0.04134   0.02505     &lt; LOD

[5 rows x 144 columns]
</code></pre></div></div> <h3 id="2-select-specific-rows-and-columns">2. Select Specific Rows and Columns</h3> <p>To limit the data to a manageable range:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_biomarker_assay_selected</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_excel</span><span class="p">(</span>
    <span class="sh">'</span><span class="s">example-biomarker-assay.xlsx</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">sheet_name</span><span class="o">=</span><span class="sh">'</span><span class="s">Biomarker assay</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">skiprows</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span>
    <span class="n">usecols</span><span class="o">=</span><span class="sh">'</span><span class="s">A:EN</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">nrows</span><span class="o">=</span><span class="mi">31</span>
<span class="p">)</span>
</code></pre></div></div> <h3 id="3-verify-non-empty-rows-and-columns">3. Verify Non-Empty Rows and Columns</h3> <p>Check for completeness in the imported data:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nonempty_rows</span> <span class="o">=</span> <span class="n">df_biomarker_assay_selected</span><span class="p">.</span><span class="nf">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">all</span><span class="sh">'</span><span class="p">).</span><span class="n">index</span><span class="p">.</span><span class="nf">tolist</span><span class="p">()</span>
<span class="n">count_rows</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">nonempty_rows</span><span class="p">)</span>

<span class="n">nonempty_cols</span> <span class="o">=</span> <span class="n">df_biomarker_assay_selected</span><span class="p">.</span><span class="nf">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">all</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">columns</span><span class="p">.</span><span class="nf">tolist</span><span class="p">()</span>
<span class="n">count_cols</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">nonempty_cols</span><span class="p">)</span>
</code></pre></div></div> <h3 id="4-validate-data-import">4. Validate Data Import</h3> <p>Inspect the first and last rows of your dataset to verify that the import matches the source.</p> <hr/> <h2 id="special-use-cases-with-pandas">Special Use Cases with Pandas</h2> <h3 id="1-formula-generated-data">1. Formula-Generated Data</h3> <p>Excel formulas, like those generating the column in the <strong>Metadata</strong> worksheet, retain their calculated values when imported:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_metadata</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_excel</span><span class="p">(</span><span class="sh">'</span><span class="s">example-biomarker-assay.xlsx</span><span class="sh">'</span><span class="p">,</span> <span class="n">sheet_name</span><span class="o">=</span><span class="sh">'</span><span class="s">Metadata</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <h3 id="2-filtered-data">2. Filtered Data</h3> <p>Filtered tables (e.g., showing only filtered rows in Excel) are fully imported, including the hidden rows.</p> <h3 id="3-binary-workbook-files-xlsb">3. Binary Workbook Files (.xlsb)</h3> <p>For <code class="language-plaintext highlighter-rouge">.xlsb</code> files, use the <code class="language-plaintext highlighter-rouge">pyxlsb</code> library to read the data.</p> <hr/> <h2 id="best-practices-for-importing-excel-files">Best Practices for Importing Excel Files</h2> <p>To streamline your workflow, follow these tips:</p> <ul> <li>Use <code class="language-plaintext highlighter-rouge">skiprows</code> to ignore unnecessary content.</li> <li>Specify <code class="language-plaintext highlighter-rouge">usecols</code> and <code class="language-plaintext highlighter-rouge">nrows</code> for better performance.</li> <li>Confirm data integrity by checking non-empty rows and columns.</li> <li>Choose the correct engine for specialized file formats (e.g., <code class="language-plaintext highlighter-rouge">.xlsb</code>).</li> </ul> <p>By following these steps, you’ll efficiently prepare your data for analysis, no matter the complexity of the Excel files.</p> <hr/> <h2 id="final-thoughts">Final Thoughts</h2> <p>Importing Excel files in Python doesn’t have to be daunting. With a clear process, even the most complex datasets become manageable. Try these steps on your own files, and let me know how it goes!</p> <p>For any questions or advanced use cases, feel free to drop a comment or reach out. Happy coding!</p> <hr/> <h2 id="references">References</h2> <ul> <li><a href="https://support.microsoft.com/en-us/office/file-formats-that-are-supported-in-excel-0943ff2c-6014-4e8d-aaea-b83d51d46247">Excel file format</a></li> <li><a href="https://support.microsoft.com/en-us/office/overview-of-excel-tables-7ab0bb7d-3a9e-4b56-a3c9-6c94334e492c">Overview of Excel table</a></li> <li><a href="https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html">Pandas API doc</a></li> </ul>]]></content><author><name></name></author><category term="statistics"/><category term="python;"/><category term="spreadsheet;"/><category term="data-analysis"/><summary type="html"><![CDATA[Purpose Ever struggled to import Excel data into Python for analysis? This post will guide you step-by-step on how to use Pandas to handle Excel files effortlessly, even for complex datasets.]]></summary></entry><entry><title type="html">Top R Packages for GO Enrichment Analysis: topGO vs globaltest Explained</title><link href="https://davidzhao1015.github.io/blog/2024/go-enrichment/" rel="alternate" type="text/html" title="Top R Packages for GO Enrichment Analysis: topGO vs globaltest Explained"/><published>2024-11-22T00:00:00+00:00</published><updated>2024-11-22T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2024/go-enrichment</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2024/go-enrichment/"><![CDATA[<h2 id="1-introduction"><strong>1. Introduction</strong></h2> <p>Gene Ontology (GO) enrichment analysis is a cornerstone of gene expression studies. It helps researchers identify biological processes, molecular functions, and cellular components that are overrepresented in a set of genes, offering insights into the underlying biology. Several statistical methods can be used for GO enrichment analysis, including Fisher’s exact test, the Kolmogorov-Smirnov test, and the global test.</p> <p>This article aims to simplify the process of choosing an appropriate R package for GO enrichment analysis by introducing two popular Bioconductor packages: <strong>topGO</strong> and <strong>globaltest</strong>. While both packages are widely used, their distinct statistical methods and outputs can make it challenging to choose the right tool for your study. This guide compares these packages, highlights their differences, and provides practical examples to help researchers, especially those with busy lab schedules, efficiently integrate GO analysis into their workflows.</p> <h2 id="2-overview-of-bioconductor-packages"><strong>2. Overview of Bioconductor Packages</strong></h2> <p><strong>topGO</strong></p> <p><strong>topGO</strong> is a versatile R package for GO enrichment analysis, well-suited for identifying specific GO terms that are enriched among differentially expressed genes. It primarily employs statistical methods like Fisher’s exact test and the Kolmogorov-Smirnov test, making it a reliable choice for detecting overrepresentation in gene lists. With its robust functionality and detailed documentation, topGO is a go-to tool for exploring gene-level associations in various biological datasets.</p> <p><strong>globaltest</strong></p> <p><strong>globaltest</strong> takes a different approach by assessing whether specific GO terms are associated with clinical outcomes or other continuous variables. It uses the global test methodology, which evaluates associations at a more holistic level compared to gene-specific tests. This makes it particularly valuable for studies where the research question involves linking GO terms to phenotypic data, such as disease progression or treatment response.</p> <p><strong>Key Differences in Statistical Approaches</strong></p> <p>Both packages are highly ranked in the Bioconductor repository due to their active maintenance and comprehensive documentation. However, their underlying statistical methods set them apart:</p> <p>• <strong>topGO</strong>: Uses Fisher’s exact test or the Kolmogorov-Smirnov test to test the null hypothesis that no specific GO terms are enriched in a set of genes.</p> <p>• <strong>globaltest</strong>: Employs the global test to evaluate the null hypothesis that no association exists between a set of genes and a clinical outcome or phenotype.</p> <p><strong>Use Case Comparison</strong></p> <p>• <strong>topGO</strong> is ideal for researchers seeking to uncover enriched biological processes in differentially expressed genes.</p> <p>• <strong>globaltest</strong> is better suited for studies focused on linking GO terms to clinical or phenotypic outcomes, such as identifying functional pathways associated with disease progression.</p> <p>By understanding these distinctions, researchers can choose the package that best aligns with their study objectives.</p> <h2 id="3-setting-environment"><strong>3. Setting Environment</strong></h2> <p>Setting up includes ensuring the required packages are installed and loaded.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Install globaltest Biocondcutor package</span><span class="w">
</span><span class="n">BiocManager</span><span class="o">::</span><span class="n">install</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s2">"globaltest"</span><span class="p">,</span><span class="w"> </span><span class="s2">"topGO"</span><span class="p">,</span><span class="w"> </span><span class="s2">"golubEsets"</span><span class="p">,</span><span class="w"> </span><span class="s2">"vsn"</span><span class="p">,</span><span class="w"> </span><span class="s2">"hu6800.db"</span><span class="p">,</span><span class="w"> </span><span class="s2">"GO.db"</span><span class="p">,</span><span class="w"> </span><span class="s2">"AnnotationDbi"</span><span class="p">,</span><span class="w"> </span><span class="s2">"annotate"</span><span class="p">,</span><span class="w"> </span><span class="s2">"topGO"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ALL"</span><span class="p">,</span><span class="w"> </span><span class="s2">"Biobase"</span><span class="p">,</span><span class="w"> </span><span class="s2">"limma"</span><span class="p">))</span><span class="w">  

</span><span class="c1"># Load the globaltest package</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">topGO</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">globaltest</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">golubEsets</span><span class="p">)</span><span class="w"> 
</span><span class="n">library</span><span class="p">(</span><span class="n">vsn</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">hu6800.db</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">AnnotationDbi</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">methods</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">annotate</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">limma</span><span class="p">)</span><span class="w"> 
</span><span class="n">library</span><span class="p">(</span><span class="n">dplyr</span><span class="p">)</span><span class="w">
</span></code></pre></div></div> <h2 id="4-data-prepration"><strong>4. Data Prepration</strong></h2> <p>Data preprocessing and normalization.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load the Golub training data set consisting of 7129 genes and 38 samples (27 ALL and 11 AML)</span><span class="w">
</span><span class="n">data</span><span class="p">(</span><span class="n">Golub_Train</span><span class="p">,</span><span class="w"> </span><span class="n">package</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"golubEsets"</span><span class="p">)</span><span class="w">  

</span><span class="c1">## Normalize the data using the VSN package</span><span class="w">
</span><span class="n">Golub_Train_VSN</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">vsn</span><span class="o">::</span><span class="n">vsn2</span><span class="p">(</span><span class="n">exprs</span><span class="p">(</span><span class="n">Golub_Train</span><span class="p">))</span><span class="w"> 
</span></code></pre></div></div> <p>Gene expression data before the normalization process:</p> <p>A matrix: 5 x 10 of type int</p> <table> <thead> <tr> <th></th> <th>1</th> <th>2</th> <th>3</th> <th>4</th> <th>5</th> <th>6</th> <th>7</th> <th>8</th> <th>9</th> <th>10</th> </tr> </thead> <tbody> <tr> <td>AFFX-BioB-5_at</td> <td>-214</td> <td>-139</td> <td>-76</td> <td>-135</td> <td>-106</td> <td>-138</td> <td>-72</td> <td>-413</td> <td>5</td> <td>-88</td> </tr> <tr> <td>AFFX-BioB-M_at</td> <td>-153</td> <td>-73</td> <td>-49</td> <td>-114</td> <td>-125</td> <td>-85</td> <td>-144</td> <td>-260</td> <td>-127</td> <td>-105</td> </tr> <tr> <td>AFFX-BioB-3_at</td> <td>-58</td> <td>-1</td> <td>-307</td> <td>265</td> <td>-76</td> <td>215</td> <td>238</td> <td>7</td> <td>106</td> <td>42</td> </tr> <tr> <td>AFFX-BioC-5_at</td> <td>88</td> <td>283</td> <td>309</td> <td>12</td> <td>168</td> <td>71</td> <td>55</td> <td>-2</td> <td>268</td> <td>219</td> </tr> <tr> <td>AFFX-BioC-3_at</td> <td>-295</td> <td>-264</td> <td>-376</td> <td>-419</td> <td>-230</td> <td>-272</td> <td>-399</td> <td>-541</td> <td>-210</td> <td>-178</td> </tr> </tbody> </table> <p>Gene expression data after the normalization process:</p> <p>A matrix: 5 x 10 of type dbl</p> <table> <thead> <tr> <th></th> <th>1</th> <th>2</th> <th>3</th> <th>4</th> <th>5</th> <th>6</th> <th>7</th> <th>8</th> <th>9</th> <th>10</th> </tr> </thead> <tbody> <tr> <td>AFFX-BioB-5_at</td> <td>5.053873</td> <td>5.396673</td> <td>5.972362</td> <td>5.549766</td> <td>5.337167</td> <td>5.411235</td> <td>5.968888</td> <td>4.616873</td> <td>6.396420</td> <td>5.615805</td> </tr> <tr> <td>AFFX-BioB-M_at</td> <td>5.364311</td> <td>5.838160</td> <td>6.128136</td> <td>5.678733</td> <td>5.212093</td> <td>5.797844</td> <td>5.508008</td> <td>5.178958</td> <td>5.605328</td> <td>5.480476</td> </tr> <tr> <td>AFFX-BioB-3_at</td> <td>5.948439</td> <td>6.391596</td> <td>4.906233</td> <td>8.079299</td> <td>5.550368</td> <td>8.071159</td> <td>7.967052</td> <td>6.646939</td> <td>7.033943</td> <td>6.825375</td> </tr> <tr> <td>AFFX-BioC-5_at</td> <td>6.988237</td> <td>8.224862</td> <td>8.003817</td> <td>6.558152</td> <td>7.593938</td> <td>7.118814</td> <td>6.884934</td> <td>6.591159</td> <td>7.872088</td> <td>8.162249</td> </tr> <tr> <td>AFFX-BioC-3_at</td> <td>4.707586</td> <td>4.747971</td> <td>4.672928</td> <td>4.322134</td> <td>4.638834</td> <td>4.665432</td> <td>4.390771</td> <td>4.257310</td> <td>5.197148</td> <td>4.978863</td> </tr> </tbody> </table> <h2 id="5-go-enrichment-analysis-with-topgo"><strong>5. GO Enrichment Analysis with topGO</strong></h2> <p>GO enrichment with topGO</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create a topGOdata object </span><span class="w">
</span><span class="n">sampleGOdata</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">new</span><span class="p">(</span><span class="s2">"topGOdata"</span><span class="p">,</span><span class="w"> </span><span class="n">description</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Simple session"</span><span class="p">,</span><span class="w"> </span><span class="n">ontology</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"BP"</span><span class="p">,</span><span class="w"> </span><span class="n">allGenes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pvalues</span><span class="p">,</span><span class="w"> </span><span class="n">geneSel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">topDiffGenes</span><span class="p">,</span><span class="w"> </span><span class="n">nodeSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="n">annot</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">annFUN.db</span><span class="p">,</span><span class="w"> </span><span class="n">affyLib</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">affyLib</span><span class="p">)</span><span class="w"> 

</span><span class="c1"># Run GO enrichment analysis with Fisher's exact test </span><span class="w">
</span><span class="n">resultFisher</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">runTest</span><span class="p">(</span><span class="n">sampleGOdata</span><span class="p">,</span><span class="w"> </span><span class="n">algorithm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"classic"</span><span class="p">,</span><span class="w"> </span><span class="n">statistic</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"fisher"</span><span class="p">)</span><span class="w"> 
</span></code></pre></div></div> <p>Display summary of results:</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Display the results </span><span class="w">
</span><span class="n">resultFisher</span><span class="w"> 
</span></code></pre></div></div> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Description</span><span class="o">:</span><span class="w"> </span><span class="n">Simple</span><span class="w"> </span><span class="n">session</span><span class="w"> 
</span><span class="n">Ontology</span><span class="o">:</span><span class="w"> </span><span class="n">BP</span><span class="w"> 
</span><span class="s1">'classic'</span><span class="w"> </span><span class="n">algorithm</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="s1">'fisher'</span><span class="w"> </span><span class="n">test</span><span class="w">
</span><span class="m">5431</span><span class="w"> </span><span class="n">GO</span><span class="w"> </span><span class="n">terms</span><span class="w"> </span><span class="n">scored</span><span class="o">:</span><span class="w"> </span><span class="m">302</span><span class="w"> </span><span class="n">terms</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0.01</span><span class="w">
</span><span class="n">Annotation</span><span class="w"> </span><span class="n">data</span><span class="o">:</span><span class="w">
    </span><span class="n">Annotated</span><span class="w"> </span><span class="n">genes</span><span class="o">:</span><span class="w"> </span><span class="m">6234</span><span class="w"> 
    </span><span class="n">Significant</span><span class="w"> </span><span class="n">genes</span><span class="o">:</span><span class="w"> </span><span class="m">1512</span><span class="w"> 
    </span><span class="n">Min.</span><span class="w"> </span><span class="n">no.</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">genes</span><span class="w"> </span><span class="n">annotated</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">GO</span><span class="o">:</span><span class="w"> </span><span class="m">10</span><span class="w"> 
    </span><span class="n">Nontrivial</span><span class="w"> </span><span class="n">nodes</span><span class="o">:</span><span class="w"> </span><span class="m">5341</span><span class="w"> 
</span></code></pre></div></div> <p>Show the top 10 enriched GO terms:</p> <table> <thead> <tr> <th></th> <th>GO.ID &lt;chr&gt;</th> <th>Term &lt;chr&gt;</th> <th>Annotated &lt;int&gt;</th> <th>Significant &lt;int&gt;</th> <th>Expected &lt;dbl&gt;</th> <th>Rank in classicFisher &lt;int&gt;</th> <th>classicFisher &lt;chr&gt;</th> <th>classicKS &lt;chr&gt;</th> <th>elimKS &lt;chr&gt;</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>GO:0010042</td> <td>response to manganese ion</td> <td>18</td> <td>14</td> <td>4.37</td> <td>10</td> <td>2.6e-06</td> <td>2.1e-06</td> <td>2.1e-06</td> </tr> <tr> <td>2</td> <td>GO:0000002</td> <td>mitochondrial genome maintenance</td> <td>13</td> <td>8</td> <td>3.15</td> <td>199</td> <td>0.00458</td> <td>0.00015</td> <td>0.00015</td> </tr> <tr> <td>3</td> <td>GO:0044539</td> <td>long-chain fatty acid import into cell</td> <td>11</td> <td>8</td> <td>2.67</td> <td>88</td> <td>0.00095</td> <td>0.00017</td> <td>0.00017</td> </tr> <tr> <td>4</td> <td>GO:0070198</td> <td>protein localization to chromosome, telo…</td> <td>20</td> <td>13</td> <td>4.85</td> <td>43</td> <td>0.00013</td> <td>0.00018</td> <td>0.00018</td> </tr> <tr> <td>5</td> <td>GO:0071897</td> <td>DNA biosynthetic process</td> <td>109</td> <td>41</td> <td>26.44</td> <td>101</td> <td>0.00118</td> <td>1.1e-05</td> <td>0.00029</td> </tr> <tr> <td>6</td> <td>GO:0045429</td> <td>positive regulation of nitric oxide bios…</td> <td>32</td> <td>18</td> <td>7.76</td> <td>42</td> <td>0.00010</td> <td>0.00033</td> <td>0.00033</td> </tr> <tr> <td>7</td> <td>GO:0016570</td> <td>histone modification</td> <td>44</td> <td>16</td> <td>10.67</td> <td>694</td> <td>0.04846</td> <td>0.00053</td> <td>0.00053</td> </tr> <tr> <td>8</td> <td>GO:0098869</td> <td>cellular oxidant detoxification</td> <td>70</td> <td>28</td> <td>16.98</td> <td>142</td> <td>0.00243</td> <td>0.00056</td> <td>0.00056</td> </tr> <tr> <td>9</td> <td>GO:0045820</td> <td>negative regulation of glycolytic proces…</td> <td>11</td> <td>9</td> <td>2.67</td> <td>39</td> <td>9.6e-05</td> <td>0.00056</td> <td>0.00056</td> </tr> <tr> <td>10</td> <td>GO:1903241</td> <td>U2-type prespliceosome assembly</td> <td>15</td> <td>9</td> <td>3.64</td> <td>168</td> <td>0.00332</td> <td>0.00057</td> <td>0.00057</td> </tr> </tbody> </table> <p>The GO topology graph for the top 5 enriched GO terms is shown below:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/topGO-enriched-GO.png" sizes="95vw"/> <img src="/assets/img/topGO-enriched-GO.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h2 id="6-analysis-with-globaltest"><strong>6. Analysis with globaltest</strong></h2> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">global_test_result</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">globaltest</span><span class="o">::</span><span class="n">gt</span><span class="p">(</span><span class="n">response</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ALL.AML</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Golub_Train</span><span class="p">)</span><span class="w">

</span><span class="n">res</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">globaltest</span><span class="o">::</span><span class="n">gtGO</span><span class="p">(</span><span class="n">ALL.AML</span><span class="p">,</span><span class="w"> </span><span class="n">Golub_Train</span><span class="p">,</span><span class="n">ontology</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"BP"</span><span class="p">,</span><span class="w"> </span><span class="n">annotation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"hu6800.db"</span><span class="p">,</span><span class="w"> </span><span class="n">multtest</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"BH"</span><span class="p">)</span><span class="w"> 
</span></code></pre></div></div> <table> <thead> <tr> <th></th> <th>GO &lt;chr&gt;</th> <th>alias &lt;chr&gt;</th> <th>BH &lt;dbl&gt;</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>GO:0006979</td> <td>response to oxidative stress</td> <td>5.937219e-09</td> </tr> <tr> <td>2</td> <td>GO:0062197</td> <td>cellular response to chemical stress</td> <td>5.937219e-09</td> </tr> <tr> <td>3</td> <td>GO:0034599</td> <td>cellular response to oxidative stress</td> <td>5.937219e-09</td> </tr> <tr> <td>4</td> <td>GO:0034614</td> <td>cellular response to reactive oxygen species</td> <td>1.479059e-08</td> </tr> <tr> <td>5</td> <td>GO:0009628</td> <td>response to abiotic stimulus</td> <td>2.469754e-08</td> </tr> <tr> <td>6</td> <td>GO:0000302</td> <td>response to reactive oxygen species</td> <td>2.680335e-08</td> </tr> <tr> <td>7</td> <td>GO:0019932</td> <td>second-messenger-mediated signaling</td> <td>1.030937e-07</td> </tr> <tr> <td>8</td> <td>GO:0019722</td> <td>calcium-mediated signaling</td> <td>1.080573e-07</td> </tr> <tr> <td>9</td> <td>GO:0050921</td> <td>positive regulation of chemotaxis</td> <td>1.080573e-07</td> </tr> <tr> <td>10</td> <td>GO:0003013</td> <td>circulatory system process</td> <td>1.342398e-07</td> </tr> </tbody> </table> <h2 id="5-comparing-results"><strong>5. Comparing Results</strong></h2> <p>The results of GO enrichment analysis using <strong>topGO</strong> and <strong>globaltest</strong> provide distinct yet informative insights into the biological processes underlying the data.</p> <p><strong>Key Results and Differences:</strong></p> <p>• <strong>Significant GO Terms</strong>:</p> <p>• topGO identified 302 significant GO terms using the Fisher’s exact test, with a focus on Biological Process (BP) ontology, while globaltest highlighted 10 highly significant GO terms, such as “response to oxidative stress” (GO:0006979) and “cellular response to reactive oxygen species” (GO:0034614).</p> <p>• <strong>Methodological Nuances</strong>:</p> <p>• topGO excels in leveraging the GO hierarchy, particularly with algorithms like “elim” to minimize redundancy. This approach is effective for capturing nuanced biological pathways.</p> <p>• globaltest uses a multivariate approach that evaluates the overall association between gene sets and outcomes, making it particularly sensitive to systemic biological patterns.</p> <p><strong>Type of Questions Addressed</strong>:</p> <p>• topGO is better suited for researchers aiming to understand specific enriched processes while accounting for the GO graph topology.</p> <p>• globaltest is ideal for broader hypotheses, such as assessing the overall contribution of a gene set to a phenotype.</p> <h2 id="6-discussion"><strong>6. Discussion</strong></h2> <p>The results from topGO and globaltest are largely complementary rather than competitive. Each package offers a unique lens through which to interpret the data:</p> <p>• <strong>Complementary Insights</strong>:</p> <p>• topGO provides granular details about localized processes within the GO hierarchy.</p> <p>• globaltest identifies overarching biological associations, highlighting system-wide trends.</p> <p>• <strong>Scenarios for Combining Insights</strong>:</p> <p>• Combining topGO’s hierarchical insights with globaltest’s systemic view can help uncover both specific mechanisms and broader biological themes, particularly for complex datasets.</p> <p>• For example, a researcher could first use topGO to pinpoint key pathways and then employ globaltest to evaluate their aggregate impact.</p> <p>• <strong>Limitations and Considerations</strong>:</p> <p>• topGO assumes independence between GO terms, which may oversimplify relationships in some contexts.</p> <p>• globaltest may lose specificity in its focus on global patterns, potentially overlooking individual pathway nuances.</p> <p>• Computational efficiency may also differ: topGO’s hierarchical algorithms may demand more preprocessing, while globaltest benefits from a simpler multivariate setup.</p> <h2 id="7-conclusion"><strong>7. Conclusion</strong></h2> <p>This comparative analysis demonstrates that both topGO and globaltest offer valuable but distinct approaches to GO enrichment analysis:</p> <p><strong>Practical Takeaways</strong>:</p> <ul> <li> <p>topGO is preferred for detailed pathway analysis, especially for datasets with hierarchical biological information.</p> </li> <li> <p>globaltest excels in scenarios requiring a holistic assessment of gene set relevance to phenotypes.</p> </li> </ul> <p><strong>Encouragement for Beginners</strong>:</p> <p>New researchers are encouraged to explore both packages to deepen their understanding of GO enrichment methods. Experimenting with these tools fosters a comprehensive grasp of the biological and statistical nuances critical for robust bioinformatics analysis.</p> <h2 id="8-references-and-further-reading"><strong>8. References and Further Reading</strong></h2> <ul> <li><a href="https://bioconductor.org/packages/release/bioc/html/topGO.html">topGO: Enrichment Analysis for Gene Ontology</a></li> <li><a href="https://bioconductor.org/packages/release/bioc/html/globaltest.html">globatest: Global Test for Functional Enrichment Analysis</a></li> <li><a href="http://geneontology.org/">Gene Ontology Consortium</a></li> </ul>]]></content><author><name></name></author><category term="statistics"/><category term="bioconductor;"/><category term="R;"/><category term="topGO;"/><category term="globaltest;"/><category term="gene-ontology;"/><category term="enrichment-analysis"/><summary type="html"><![CDATA[1. Introduction]]></summary></entry><entry><title type="html">How to Run R Code in Jupyter Notebook within VS Code: A Step-by-Step Guide</title><link href="https://davidzhao1015.github.io/blog/2024/R-kernel-jupyter/" rel="alternate" type="text/html" title="How to Run R Code in Jupyter Notebook within VS Code: A Step-by-Step Guide"/><published>2024-11-14T00:00:00+00:00</published><updated>2024-11-14T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2024/R-kernel-jupyter</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2024/R-kernel-jupyter/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>Jupyter Notebook is an invaluable tool for data scientists, researchers, and developers, enabling them to create and share computational documents seamlessly. With the added power of an integrated development environment (IDE) like Visual Studio Code (VS Code), you can run Jupyter Notebook locally and access an array of helpful extensions that enhance your workflow.</p> <p>However, despite Jupyter Notebook’s broad support for programming languages like Python, it doesn’t natively support R—something I quickly discovered while trying to use it for a blogging project. Determined to make it work, I embarked on a journey that involved scouring solutions online, seeking advice from the programming community, and leveraging the power of ChatGPT 4.0. Through a mix of trial, error, and persistence, I finally uncovered a method to run R code in Jupyter Notebook within VS Code.</p> <p>In this blog post, I’m excited to share a step-by-step guide that will help others in the same situation. I’ll also walk you through the troubleshooting process that eventually led to my solution, so you can learn from my experience and avoid the roadblocks I encountered.</p> <h2 id="step-by-step-guide-to-install-r-kernel-in-jupyter-notebook">Step-by-Step Guide to Install R Kernel in Jupyter Notebook</h2> <h3 id="1-verify-r-installation">1. Verify R Installation</h3> <p>Ensure R is installed by checking its version:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>R <span class="nt">--version</span>
</code></pre></div></div> <h3 id="2-verify-jupyter-notebook-installation">2. Verify Jupyter Notebook Installation</h3> <p>Make sure Python is installed and accessible in your PATH. Then, check for Jupyter:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python <span class="nt">--version</span>
</code></pre></div></div> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>jupyter <span class="nt">--version</span>
</code></pre></div></div> <p>To confirm Jupyter Notebook is working, run:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>jupyter notebook
</code></pre></div></div> <p>This should open a Jupyter Notebook in your web browser. If there are issues, install Jupyter using:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>jupyter
</code></pre></div></div> <h3 id="3-check-if-jupyter-directory-is-in-path">3. Check if Jupyter Directory is in PATH</h3> <p>Ensure the Jupyter directory is included in your PATH:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">echo</span> <span class="nv">$PATH</span>
</code></pre></div></div> <p>The PATH environment variable tells the system where to find executable files when you run a command.</p> <h3 id="4-install-irkernel-package-in-r">4. Install <code class="language-plaintext highlighter-rouge">IRkernel</code> Package in R</h3> <p>Install the <code class="language-plaintext highlighter-rouge">IRkernel</code> package in R:</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">install.packages</span><span class="p">(</span><span class="s1">'IRkernel'</span><span class="p">)</span><span class="w">
</span></code></pre></div></div> <h3 id="5-register-r-kernel-with-jupyter">5. Register R Kernel with Jupyter</h3> <p>Run the following command in your R terminal (not the interactive R console):</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">IRkernel</span><span class="o">::</span><span class="n">installspec</span><span class="p">(</span><span class="n">user</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div> <p>Setting <code class="language-plaintext highlighter-rouge">user = FALSE</code> makes the kernel available for all users. Use <code class="language-plaintext highlighter-rouge">user = TRUE</code> if you prefer a user-specific installation.</p> <h4 id="common-error-and-solution">Common Error and Solution</h4> <p>If you encounter this error:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Error in IRkernel::installspec(user = FALSE) :
jupyter-client has to be installed but “jupyter kernelspec --version” exited with code 127.
In addition: Warning message:
In system2("jupyter", c("kernelspec", "--version"), FALSE, FALSE) :
error in running command
</code></pre></div></div> <p>Run the command in the R terminal instead of the R console to resolve it.</p> <h3 id="6-create-a-new-jupyter-notebook-in-vs-code">6. Create a New Jupyter Notebook in VS Code</h3> <p>Restart VS Code and create a new Jupyter Notebook. Select the R kernel to start coding in R within Jupyter Notebook.</p> <h2 id="additional-tips">Additional Tips</h2> <ul> <li>Install R Packages in Jupyter: You can install R packages directly in a Jupyter cell by using install.packages(“package_name”).</li> <li>Switch Between Python and R Kernels: If you want to mix Python and R code in a Jupyter Notebook, you can use rpy2, a package that allows for inter-language compatibility. Alternatively, you can use Jupyter Lab with extensions that allow cell-specific kernel selection.</li> </ul> <p>This setup allows you to use Jupyter Notebooks with R code, which can be particularly useful for data analysis, visualization, and sharing work with others who use Python or Jupyter Notebooks.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">How to Perform Power Analysis for High-Throughput Omics Data Using SSPA, A Guide to the Bioconductor Package</title><link href="https://davidzhao1015.github.io/blog/2024/power-analysis/" rel="alternate" type="text/html" title="How to Perform Power Analysis for High-Throughput Omics Data Using SSPA, A Guide to the Bioconductor Package"/><published>2024-11-07T00:00:00+00:00</published><updated>2024-11-07T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2024/power-analysis</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2024/power-analysis/"><![CDATA[<div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/power-analysis-sspa-case-study.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div>]]></content><author><name></name></author><category term="statistics"/><category term="power-analysis;"/><category term="bioconductor;"/><category term="R;"/><category term="SSPA"/><summary type="html"><![CDATA[{::nomarkdown}]]></summary></entry><entry><title type="html">Automating Reporting with RMarkdown</title><link href="https://davidzhao1015.github.io/blog/2024/auto-reporting-rmarkdown/" rel="alternate" type="text/html" title="Automating Reporting with RMarkdown"/><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2024/auto-reporting-rmarkdown</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2024/auto-reporting-rmarkdown/"><![CDATA[<h2 id="background-and-problem-overview">Background and Problem Overview</h2> <hr/> <p>RMarkdown is a powerful tool widely used for creating dynamic, professional reports that blend text, code, and visualizations. It’s efficient and versatile, offering outputs in formats like PDF, HTML, Word, and even interactive files, making it a go-to solution for data reporting. But beyond its basic capabilities, RMarkdown offers a hidden advantage: the potential to automate report generation. By doing this, users can avoid repetitive manual updates, which not only saves time but also reduces the chance of errors, especially when content remains largely consistent with only specific details needing adjustment.</p> <p>Recently, I experienced firsthand how automating RMarkdown reporting can enhance both speed and accuracy in my workflows. This blog will serve as a step-by-step guide, showing how you can leverage RMarkdown’s automation features to streamline your own projects with minimal parameter adjustments.</p> <h3 id="problem-scenario">Problem Scenario</h3> <p>In a recent project, I needed to generate multiple reports for PCA analysis across two comparison groups. For each group, I had to update several pieces of narrative text and adjust file paths for specific figures and tables. This repetitive, manual process quickly became time-consuming and error-prone. With RMarkdown’s programming capabilities, I was able to automate these updates, saving at least 30% of my time. Not only did this streamline the current project, but it also set up a reusable template for future reporting needs.</p> <h2 id="prerequisites">Prerequisites</h2> <hr/> <p>Before diving into automating RMarkdown reports, it’s important to have a foundational understanding of a few key concepts and tools. These prerequisites will help ensure a smooth experience as you follow along with the guide.</p> <ul> <li><strong>Parameters in the YAML Header</strong>: In RMarkdown, the YAML header at the top of your file allows you to set global parameters that can be accessed throughout the document. These parameters let you customize elements such as titles, dates, and specific variables needed for your analysis. Knowing how to define and edit parameters in the YAML header is essential for making your reports dynamic and flexible.</li> <li><strong>Creating Variables from Parameter Values</strong>: Once parameters are set in the YAML header, they need to be referenced within the document. This involves creating variables in R that directly pull from these parameter values. By doing so, you can easily update specific content across the report by simply changing the parameter values, without having to adjust individual sections manually.</li> <li><strong>Embedding Parameters Using knit</strong>: RMarkdown’s knit function allows you to insert parameters within text, code chunks, or inline calculations. This embedding feature is crucial for dynamically adjusting content within the report, ensuring that titles, captions, and sections update seamlessly with each rendering of the file.</li> <li><strong>The rmarkdown::render() Function</strong>: This function is central to programmatically creating reports. It lets you specify an RMarkdown file along with any custom parameters you want to update for each run. By using rmarkdown::render(), you can generate multiple customized reports in one go by changing parameters in a loop.</li> <li><strong>Iterating with <em>for</em> Loops</strong>: Automation often requires generating multiple outputs for different variables or scenarios. A basic understanding of for loops in R is helpful here, as it allows you to iterate over different parameter sets, such as comparison groups in an analysis. This approach makes it easy to replicate report structures with tailored content for each scenario.</li> <li><strong>Running Base Command Lines in R</strong>: Certain aspects of automating RMarkdown reports may involve running command-line operations directly from R. This skill enables you to manage file paths, automate data downloads, or perform batch processing, enhancing the report’s flexibility and reducing manual workload.</li> </ul> <p>Familiarity with these components will help you set up an efficient, automated RMarkdown reporting process that can be reused and adapted to meet future reporting needs.</p> <p>If you’re new to RMarkdown or R, I recommend reviewing the basics in the official guide, <a href="https://bookdown.org/yihui/rmarkdown/"><em>R Markdown: The Definitive Guide</em></a>, to ensure you’re comfortable with these fundamentals before proceeding.</p> <h2 id="data-and-codes">Data and Codes</h2> <hr/> <p>To follow along with this tutorial and reproduce the automated reporting process, you can clone the <a href="https://github.com/davidzhao1015/AutomateRMarkdown.git">repository</a> containing all necessary files to your local machine. The repository includes all essential scripts and files required to generate a fully automated RMarkdown report.</p> <ul> <li>RMarkdown File (<code class="language-plaintext highlighter-rouge">AutomateRMarkdown/code/pca-module.Rmd</code>): <em>**</em>This core file contains the report template, including text, code chunks, and the YAML header with customizable parameters. The .Rmd file is structured to dynamically integrate analysis results, figures, and tables based on parameter values, so modifying the parameter inputs will automatically adjust the contents of the report.</li> <li><strong>R Script File (</strong><code class="language-plaintext highlighter-rouge">AutomateRMarkdown/code/combine-rmarkdown-files.R</code><strong>)</strong>: The .R file complements the RMarkdown report by containing the main script to render the report programmatically. It includes necessary functions, such as rmarkdown::render(), to automate the report generation, manage parameter values, and run any looping structures for batch reporting.</li> <li><strong>Figures and Tables (</strong><code class="language-plaintext highlighter-rouge">AutomateRMarkdown/data/</code><strong>)</strong>: Sample figures and tables are included in the repository to simulate typical analysis outputs, such as plots and summary tables. These files are referenced within the RMarkdown file to illustrate how visuals and data outputs can be dynamically incorporated. You can replace these with your own figures and tables to customize the report further.</li> </ul> <p>By downloading and running these files locally, you’ll be able to experiment with the process firsthand and see how each component interacts in automating RMarkdown reports.</p> <h2 id="step-by-step-guide">Step-by-Step Guide</h2> <hr/> <p>This guide provides a structured approach to automating an RMarkdown report. We’ll go through the setup and use key parameters in .Rmd and .R files to streamline the reporting process.</p> <p>In this example, we have two PCA comparison groups, “WT-NC vs WT-HFD” and “KO-NC vs KO-HFD.” The report structure is adaptable for other groups by adjusting parameters as needed.</p> <p><strong>Step 1: Organizing and Naming Files</strong></p> <p>Start by organizing our data files. Create two folders named <code class="language-plaintext highlighter-rouge">Download_WT-NC_WT-HFD</code> and <code class="language-plaintext highlighter-rouge">Download_KO-NC_KO-HFD</code>. Each folder will hold three essential files for the PCA report:</p> <p>• <code class="language-plaintext highlighter-rouge">pca_scored2d_0_dpi72.png</code> (PCA score plot image)</p> <p>• <code class="language-plaintext highlighter-rouge">metabolite-names.csv</code> (metabolite names table)</p> <p>• <code class="language-plaintext highlighter-rouge">pca_loadings.csv</code> (PCA loadings data)</p> <p>These folders should follow a consistent naming pattern and contain identically named files, which will help in dynamically generating the report.</p> <p><strong>Step 2: Creating the Initial .Rmd File and YAML Header</strong></p> <p>In RStudio, create an RMarkdown file named <code class="language-plaintext highlighter-rouge">pca-module.Rmd</code>. Set up the YAML header with the following fields to define metadata for the report:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.26.55_AM.png" sizes="95vw"/> <img src="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.26.55_AM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <ul> <li>title, author, and date define basic document metadata.</li> <li>output is set to md_document to output in markdown format.</li> <li>params initializes customizable parameters (group_1, group_2, order) to control specific sections in the report.</li> </ul> <p><strong>Step 3: Setting Up Parameters</strong></p> <p>In the YAML header, the params section allows parameters to be adjusted dynamically through rmarkdown::render() outside the RMarkdown document.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.28.05_AM.png" sizes="95vw"/> <img src="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.28.05_AM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Each parameter (eg. group_1, group_2, order) is initialized to represent the first group and can be modified later in the .R script for other groups.</p> <p><strong>Step 4: Defining Global Variables</strong></p> <p>Within the RMarkdown document, define global variables to capture parameter values and paths for figures and tables:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.29.07_AM.png" sizes="95vw"/> <img src="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.29.07_AM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>These variables allow us to set paths and references that will update automatically with each parameter iteration.</p> <p><strong>Step 5: Editing Subtitles with Code</strong></p> <p>To make subtitles change dynamically for each group, use a for loop and if-else statements:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.29.54_AM.png" sizes="95vw"/> <img src="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.29.54_AM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>This will display a specific subtitle for the first group and adjust accordingly for subsequent groups. Inline R code can also be used to insert parameter-based subtitles at different levels in the report.</p> <p><strong>Step 6: Embedding Variables in Figures, Tables, and Narrative Text</strong></p> <p>In the body of the report, combine static text with inline R code to make dynamic sections for figures, tables, and narrative text.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.30.46_AM.png" sizes="95vw"/> <img src="/assets/img/Blog_Automating_Reporting_with_RMarkdown/Screenshot_2024-11-01_at_11.30.46_AM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><strong>Step 7: Writing a Loop to Automate Rendering</strong></p> <p>In a new <code class="language-plaintext highlighter-rouge">.R</code> script, create a function to loop through each group, rendering the <code class="language-plaintext highlighter-rouge">.Rmd</code> file for each set of parameters.</p> <ol> <li><strong>Create a Data Frame:</strong> Define groups with corresponding values in a data frame.</li> </ol> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">groups_collection2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="n">group_1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"WT-NC"</span><span class="p">,</span><span class="w"> </span><span class="s2">"KO-NC"</span><span class="p">),</span><span class="w">
								 </span><span class="n">group_2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"WT-HFD"</span><span class="p">,</span><span class="w"> </span><span class="s2">"KO-HFD"</span><span class="p">),</span><span class="w">
								 </span><span class="n">orders</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">))</span><span class="w">
</span></code></pre></div></div> <ol> <li><strong>Loop through Groups</strong>: Use a for loop with rmarkdown::render() to render the .Rmd file for each group.</li> </ol> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">nrow</span><span class="p">(</span><span class="n">groups_collection2</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">              
	</span><span class="n">group_1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">groups_collection2</span><span class="o">$</span><span class="n">group_1</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="w">    
	</span><span class="n">group_2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">groups_collection2</span><span class="o">$</span><span class="n">group_2</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="w">    
	</span><span class="n">order</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">groups_collection2</span><span class="o">$</span><span class="n">orders</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="w">        
	
	</span><span class="n">rmarkdown</span><span class="o">::</span><span class="n">render</span><span class="p">(</span><span class="s2">"pca-module.Rmd"</span><span class="p">,</span><span class="w">                       
		</span><span class="n">output_file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"pca_"</span><span class="p">,</span><span class="w"> </span><span class="n">group_1</span><span class="p">,</span><span class="w"> </span><span class="s2">"_"</span><span class="p">,</span><span class="w"> </span><span class="n">group_2</span><span class="p">,</span><span class="w"> </span><span class="s2">".md"</span><span class="p">),</span><span class="w">
		</span><span class="n">params</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">group_1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">group_1</span><span class="p">,</span><span class="w"> 
		              </span><span class="n">group_2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">group_2</span><span class="p">,</span><span class="w">
					  </span><span class="n">host</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Mice"</span><span class="p">,</span><span class="w">
					  </span><span class="n">order</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">order</span><span class="p">))</span><span class="w">
									</span><span class="p">}</span><span class="w"> 
</span></code></pre></div></div> <p>Executing this loop generates markdown reports for each comparison group, saved with unique filenames.</p> <p><strong>Step 8: Merging Markdown Files in Command Line</strong></p> <p>Finally, combine the individual markdown files into one file with an R command:</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">system</span><span class="p">(</span><span class="s2">"cat pca_WT-NC_WT-HFD.md &gt; combined_pca.md &amp;&amp; echo &gt;&gt; combined_pca.md &amp;&amp; cat pca_KO-NC_KO-HFD.md &gt;&gt; combined_pca.md"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div> <p>This will create a single file, <code class="language-plaintext highlighter-rouge">combined_pca.md</code>, containing the complete report with results for both groups.</p> <p>Following these steps, you can streamline report creation for multiple groups, making RMarkdown a powerful tool for efficient, reproducible analysis.</p> <h2 id="takeaway">Takeaway</h2> <hr/> <p>RMarkdown is a powerful tool for creating high-quality, reproducible reports, and by integrating programming solutions, it becomes even more versatile. By following this guide, you’ve gained insight into setting up dynamic and reusable report templates, which can save time and improve accuracy.</p> <p>Now it’s your turn! Clone the GitHub repo and try running the example code yourself. Once you get familiar with it, experiment by customizing sections to fit your unique data or reporting needs. This hands-on approach will not only deepen your understanding but also help you master dynamic reporting for any project!</p>]]></content><author><name></name></author><category term="reporting"/><category term="rmarkdown;"/><category term="automation;"/><category term="tutorial"/><summary type="html"><![CDATA[Background and Problem Overview]]></summary></entry><entry><title type="html">Introduction to Linear Mixed Models with the limma Package</title><link href="https://davidzhao1015.github.io/blog/2024/linear-mixed-model/" rel="alternate" type="text/html" title="Introduction to Linear Mixed Models with the limma Package"/><published>2024-10-23T00:00:00+00:00</published><updated>2024-10-23T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2024/linear-mixed-model</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2024/linear-mixed-model/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>In the field of bioinformatics and genomics, understanding the variations in gene expression across different experimental conditions is crucial for interpreting biological processes. The limma package is widely recognized for its powerful capabilities in fitting linear models to gene expression data, allowing researchers to evaluate differences due to experimental conditions.</p> <p>However, many experimental designs involve repeated measurements from the same subjects, whether they are animals, human samples, or cells. These repeated measures introduce random effects, which must be accounted for to avoid biased results. Random effects occur when some variability in the data is due to differences between subjects or samples that are not directly related to the experimental conditions being studied.</p> <p>This tutorial provides a step-by-step guide on how to build linear mixed models (LMM) using the limma package to incorporate random effects. You will learn how to adjust for these random variations, ensuring more accurate and reliable conclusions about gene expression.</p> <h2 id="what-is-effect-of-repeated-measures">What is effect of repeated measures?</h2> <p>Repeated measures refer to data collected from the same subjects at multiple time points or under different conditions. These designs result in correlated observations, as repeated measures on the same individual tend to share subject-specific traits. Ignoring this correlation can lead to incorrect conclusions since traditional methods assume independence between observations.</p> <p>The use of repeated measures often reduces variability, as each subject serves as their own control, which increases the sensitivity of the analysis. This can lead to greater statistical power, enabling researchers to detect effects with fewer subjects. To handle the correlation between repeated observations, specialized methods such as Repeated Measures ANOVA, Linear Mixed Models (LMM), or Generalized Estimating Equations (GEE) are typically used.</p> <h2 id="what-can-linear-mixed-effect-model-do">What can linear mixed-effect model do?</h2> <p>A Linear Mixed-Effects Model (LMM) is used to analyze repeated measures data by accounting for both overall effects (like treatments or time) and individual differences between subjects. It helps manage the fact that repeated observations from the same person are related, and it can handle missing data or different time points for each person. This makes it a flexible tool for analyzing complex data.</p> <p>In the context of gene expression analysis, LMMs can be used to model the effects of experimental conditions (e.g., treatment groups) while accounting for individual variability and correlations between repeated measurements. By incorporating random effects, LMMs provide a more accurate representation of the underlying data structure, leading to more reliable results and improved statistical power.</p> <h1 id="prerequisites">Prerequisites</h1> <p>Before proceeding with this tutorial, you should have a basic understanding of linear models, gene expression analysis, and the R programming language. Familiarity with the limma package and its functions is recommended but not required.</p> <p>To follow along with the code examples, you will need to have R and RStudio installed on your computer. You can download R from the Comprehensive R Archive Network (CRAN) and RStudio from the RStudio website. Additionally, you will need to install the limma package, which can be done using the BiocManager package.</p> <p>The R package <code class="language-plaintext highlighter-rouge">limma</code> is used for linear models and differential expression analysis. If you haven’t installed the package yet, you can do so by running the following code:</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Install the biocManager package </span><span class="w">
    </span><span class="c1"># install.packages("BiocManager") </span><span class="w">
    </span><span class="c1"># Install the limma package </span><span class="w">
    </span><span class="c1"># BiocManager::install("limma", force = TRUE)  </span><span class="w">

    </span><span class="n">library</span><span class="p">(</span><span class="n">limma</span><span class="p">)</span><span class="w"> </span><span class="c1"># For linear models and differential expression analysis </span><span class="w">
    </span><span class="n">library</span><span class="p">(</span><span class="n">ggplot2</span><span class="p">)</span><span class="w"> </span><span class="c1"># For data visualization </span><span class="w">
    </span><span class="n">library</span><span class="p">(</span><span class="n">gridExtra</span><span class="p">)</span><span class="w">
</span></code></pre></div></div> <h1 id="code-structure">Code Structure</h1> <p>This tutorial is divided into four main steps:</p> <ol> <li><strong>Simulate Example Data</strong>: We will generate example data with repeated measures to demonstrate the use of linear mixed-effect models with the limma package.</li> <li><strong>Fit Linear Models with limma</strong>: We will fit linear models to the example data using the limma package, considering different model configurations.</li> <li><strong>Evaluate the Block Effect</strong>: We will extract differentially expressed genes and visualize the coefficients and confidence intervals for the fixed effects of treatment on gene expression.</li> <li><strong>Evaluate Model Robustness</strong>: We will evaluate the assumptions of homoscedasticity and linearity by examining the residuals and checking the normality of residuals using Q-Q plots.</li> </ol> <h2 id="step-1---simulate-example-data">Step 1 - Simulate example data</h2> <p>In this step, we will simulate example data to demonstrate the use of linear mixed-effect models with the <code class="language-plaintext highlighter-rouge">limma</code> package.</p> <p>The example data will consist of gene expression data for 10 individuals per group (control and treatment groups), with 2 samples (repeative measures) per individual.</p> <p>We will simulate the following variables for each sample: 1. <code class="language-plaintext highlighter-rouge">people</code>: A numeric variable representing the individual ID 2. <code class="language-plaintext highlighter-rouge">treatment</code>: A factor variable indicating the treatment group (0 = Control, 1 = Treatment) 3. <code class="language-plaintext highlighter-rouge">gender</code>: A factor variable representing</p> <p>We will also simulate gene expression data for 5 genes, from normal distributions with different means and standard deviations for the control and treatment groups.</p> <p>The gene expression data will be combined into a single data frame, with the genes as rows and the samples as columns.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Simulate example data</span><span class="w">
    </span><span class="n">set.seed</span><span class="p">(</span><span class="m">123</span><span class="p">)</span><span class="w">

    </span><span class="c1"># Define variables</span><span class="w">
    </span><span class="n">people</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">),</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="c1"># 10 people, 2 samples per person </span><span class="w">
    </span><span class="n">treatment</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">factor</span><span class="p">(</span><span class="nf">rep</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">))</span><span class="w">  </span><span class="c1"># 0 = Control, 1 = Treatment</span><span class="w">
    </span><span class="n">gender</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">factor</span><span class="p">(</span><span class="n">sample</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s2">"Male"</span><span class="p">,</span><span class="w"> </span><span class="s2">"Female"</span><span class="p">),</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">))</span><span class="w">  </span><span class="c1"># Gender</span><span class="w">
    </span><span class="n">genes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"Gene"</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">)</span><span class="w">

    </span><span class="c1"># Simulate gene expression matrix for treatment group</span><span class="w">
    </span><span class="n">gene_expression_treatment</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="n">rnorm</span><span class="p">(</span><span class="m">50</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">),</span><span class="w"> </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">dimnames</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">genes</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">))</span><span class="w"> 
    </span><span class="n">print</span><span class="p">(</span><span class="n">gene_expression_treatment</span><span class="p">)</span><span class="w">

    </span><span class="c1">##               1         2        3         4         5         6         7         8         9        10</span><span class="w">
    </span><span class="c1">## Gene1 12.448164 13.573826 7.864353  6.626613 10.852928 11.377281  8.610586  7.753783 10.506637 13.032941</span><span class="w">
    </span><span class="c1">## Gene2 10.719628 10.995701 9.564050 11.675574  9.409857 11.107835  9.584165  9.194230  9.942906  6.902494</span><span class="w">
    </span><span class="c1">## Gene3 10.801543  6.066766 7.947991 10.306746 11.790251  9.876177  7.469207  9.066689  9.914259 11.169227</span><span class="w">
    </span><span class="c1">## Gene4 10.221365 11.402712 8.542218  7.723726 11.756267  9.388075 14.337912 11.559930 12.737205 10.247708</span><span class="w">
    </span><span class="c1">## Gene5  8.888318  9.054417 8.749921 12.507630 11.643162  9.239058 12.415924  9.833262  9.548458 10.431883</span><span class="w">

    </span><span class="c1"># Simulate gene expression matrix for control group </span><span class="w">
    </span><span class="n">gene_expression_control</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="n">rnorm</span><span class="p">(</span><span class="m">50</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">),</span><span class="w"> </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">dimnames</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">genes</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">))</span><span class="w"> 
    </span><span class="n">print</span><span class="p">(</span><span class="n">gene_expression_control</span><span class="p">)</span><span class="w">

    </span><span class="c1">##              1        2         3        4        5        6        7        8        9       10</span><span class="w">
    </span><span class="c1">## Gene1 5.759279 5.607057 4.0179377 7.051143 5.011528 5.663564 6.987008 3.799481 3.579187 4.909945</span><span class="w">
    </span><span class="c1">## Gene2 3.995353 5.896420 0.3816622 4.430454 5.770561 7.193678 6.096794 9.374666 5.513767 3.430191</span><span class="w">
    </span><span class="c1">## Gene3 4.333585 5.106008 7.0114770 2.558565 4.258680 5.870363 5.477463 8.065221 4.506616 1.664116</span><span class="w">
    </span><span class="c1">## Gene4 2.962849 6.844535 3.5815985 5.362607 6.288753 4.348137 3.744188 4.528599 4.304915 4.239547</span><span class="w">
    </span><span class="c1">## Gene5 2.856418 9.100169 3.6239828 4.722217 4.559027 7.297615 7.721305 2.947158 3.096763 6.837993</span><span class="w">

    </span><span class="c1"># Combine the gene expression data </span><span class="w">
    </span><span class="n">gene_expression</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">gene_expression_treatment</span><span class="p">,</span><span class="w"> </span><span class="n">gene_expression_control</span><span class="p">)</span><span class="w">

    </span><span class="c1"># Create a data frame with the gene expression data </span><span class="w">
    </span><span class="n">expression_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="n">gene_expression</span><span class="p">,</span><span class="w"> </span><span class="n">row.names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">genes</span><span class="p">)</span><span class="w">
    </span><span class="n">colnames</span><span class="p">(</span><span class="n">expression_data</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"sample"</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">20</span><span class="p">)</span><span class="w"> 

    </span><span class="c1"># Print the expression data</span><span class="w">
    </span><span class="n">print</span><span class="p">(</span><span class="n">expression_data</span><span class="p">)</span><span class="w"> 

    </span><span class="c1">##         sample1   sample2  sample3   sample4   sample5   sample6   sample7   sample8   sample9  sample10 sample11 sample12  sample13 sample14 sample15 sample16 sample17</span><span class="w">
    </span><span class="c1">## Gene1 12.448164 13.573826 7.864353  6.626613 10.852928 11.377281  8.610586  7.753783 10.506637 13.032941 5.759279 5.607057 4.0179377 7.051143 5.011528 5.663564 6.987008</span><span class="w">
    </span><span class="c1">## Gene2 10.719628 10.995701 9.564050 11.675574  9.409857 11.107835  9.584165  9.194230  9.942906  6.902494 3.995353 5.896420 0.3816622 4.430454 5.770561 7.193678 6.096794</span><span class="w">
    </span><span class="c1">## Gene3 10.801543  6.066766 7.947991 10.306746 11.790251  9.876177  7.469207  9.066689  9.914259 11.169227 4.333585 5.106008 7.0114770 2.558565 4.258680 5.870363 5.477463</span><span class="w">
    </span><span class="c1">## Gene4 10.221365 11.402712 8.542218  7.723726 11.756267  9.388075 14.337912 11.559930 12.737205 10.247708 2.962849 6.844535 3.5815985 5.362607 6.288753 4.348137 3.744188</span><span class="w">
    </span><span class="c1">## Gene5  8.888318  9.054417 8.749921 12.507630 11.643162  9.239058 12.415924  9.833262  9.548458 10.431883 2.856418 9.100169 3.6239828 4.722217 4.559027 7.297615 7.721305</span><span class="w">
    </span><span class="c1">##       sample18 sample19 sample20</span><span class="w">
    </span><span class="c1">## Gene1 3.799481 3.579187 4.909945</span><span class="w">
    </span><span class="c1">## Gene2 9.374666 5.513767 3.430191</span><span class="w">
    </span><span class="c1">## Gene3 8.065221 4.506616 1.664116</span><span class="w">
    </span><span class="c1">## Gene4 4.528599 4.304915 4.239547</span><span class="w">
    </span><span class="c1">## Gene5 2.947158 3.096763 6.837993</span><span class="w">
</span></code></pre></div></div> <h2 id="step-2---fit-linear-models-with-limma">Step 2 - Fit linear models with limma</h2> <p>In this step, we will fit linear models to the example data using the <code class="language-plaintext highlighter-rouge">limma</code> package. We will consider three different models:</p> <ol> <li>Model 1: Treatment as the only predictor variable</li> <li>Model 2: Treatment and gender as covariates</li> <li>Model 3: Treatment and gender as covariates with repeated measures</li> </ol> <p>In <code class="language-plaintext highlighter-rouge">limma</code>, block effects can be used to account for non-independent samples, such as technical replicates or paired samples. You can use the <code class="language-plaintext highlighter-rouge">duplicateCorrelation()</code> function to model the correlation between samples within the same block.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1">#------Model 1: Treatment as the only predictor variable------# </span><span class="w">
    </span><span class="c1"># Create model matrix (with treatment as the only predictor variable)  </span><span class="w">
    </span><span class="n">design_1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">model.matrix</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">treatment</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expression_data</span><span class="p">)</span><span class="w"> 
    </span><span class="c1"># Fit the linear model</span><span class="w">
    </span><span class="n">fit_1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lmFit</span><span class="p">(</span><span class="n">expression_data</span><span class="p">,</span><span class="w"> </span><span class="n">design_1</span><span class="p">)</span><span class="w">  
    </span><span class="c1"># Apply empirical Bayes moderation</span><span class="w">
    </span><span class="n">fit_1_ebayes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">eBayes</span><span class="p">(</span><span class="n">fit_1</span><span class="p">)</span><span class="w">


    </span><span class="c1">#------Model 2: Treatment and Gender as covariates------# </span><span class="w">
    </span><span class="c1"># Create design matrix (treatment and gender as covariates)</span><span class="w">
    </span><span class="n">design_2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">model.matrix</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">treatment</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">gender</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expression_data</span><span class="p">)</span><span class="w">
    </span><span class="c1"># Fit the linear model for each gene</span><span class="w">
    </span><span class="n">fit_2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lmFit</span><span class="p">(</span><span class="n">expression_data</span><span class="p">,</span><span class="w"> </span><span class="n">design_2</span><span class="p">)</span><span class="w">
    </span><span class="c1"># Apply empirical Bayes moderation</span><span class="w">
    </span><span class="n">fit_2_ebayes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">eBayes</span><span class="p">(</span><span class="n">fit_2</span><span class="p">)</span><span class="w">


    </span><span class="c1">#------Model 3: Treatment and Gender as covariates with repeated measures------# </span><span class="w">
    </span><span class="c1"># Model the correlation between samples within the same block (repeated measures) </span><span class="w">
    </span><span class="n">corfit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">limma</span><span class="o">::</span><span class="n">duplicateCorrelation</span><span class="p">(</span><span class="n">gene_expression</span><span class="p">,</span><span class="w"> </span><span class="n">design_2</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">people</span><span class="p">)</span><span class="w"> 
    </span><span class="c1"># Incorprate the block effect in the model </span><span class="w">
    </span><span class="n">fit_3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lmFit</span><span class="p">(</span><span class="n">gene_expression</span><span class="p">,</span><span class="w"> </span><span class="n">design_2</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">people</span><span class="p">,</span><span class="w"> </span><span class="n">correlation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">corfit</span><span class="o">$</span><span class="n">consensus</span><span class="p">)</span><span class="w">
    </span><span class="c1"># Apply empirical Bayes moderation</span><span class="w">
    </span><span class="n">fit_3_ebayes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">eBayes</span><span class="p">(</span><span class="n">fit_3</span><span class="p">)</span><span class="w"> 
</span></code></pre></div></div> <p>The <code class="language-plaintext highlighter-rouge">corfit$consensus</code> object contains the correlation structure of the repeated measures, which is used in the <code class="language-plaintext highlighter-rouge">lmFit</code> function to account for the correlation between samples from the same individual. It is an estimate of the average intra-block correlation. If the value is close to zero, the block effect is weak or negligible. A higher value (closer to 1) indicates a stronger correlation within blocks, meaning the block effect is significant.</p> <p>In this case, the block effect is not significant, as the correlation is close to zero (approximately, 0.01).</p> <h2 id="step-3---evaluate-the-block-effect">Step 3 - Evaluate the Block Effect</h2> <p><strong>Extract top differentially expressed genes</strong></p> <p>In this step, we will extract the top differentially expressed genes from the fitted models. We will use the <code class="language-plaintext highlighter-rouge">topTable</code> function to extract the results, including the log fold change, moderated t-statistic, raw p-value, adjusted p-value (FDR), and log-odds that the gene is differentially expressed.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Extract top differentially expressed genes</span><span class="w">
    </span><span class="n">topTable</span><span class="p">(</span><span class="n">fit_1_ebayes</span><span class="p">,</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">Inf</span><span class="p">,</span><span class="w"> </span><span class="n">adjust.method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"BH"</span><span class="p">,</span><span class="w"> </span><span class="n">sort.by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"P"</span><span class="p">)</span><span class="w"> 

    </span><span class="c1">## Removing intercept from test coefficients</span><span class="w">

    </span><span class="c1">##           logFC  AveExpr         t      P.Value    adj.P.Val         B</span><span class="w">
    </span><span class="c1">## Gene4 -6.171139 7.706142 -7.430413 5.986052e-11 2.993026e-10 20.276398</span><span class="w">
    </span><span class="c1">## Gene1 -5.026098 7.751662 -6.051717 3.234941e-08 7.859775e-08 11.366624</span><span class="w">
    </span><span class="c1">## Gene5 -4.954939 7.753734 -5.966037 4.715865e-08 7.859775e-08 10.873058</span><span class="w">
    </span><span class="c1">## Gene2 -4.701290 7.558999 -5.660628 1.776199e-07 2.220249e-07  9.170996</span><span class="w">
    </span><span class="c1">## Gene3 -4.555676 7.163048 -5.485301 3.752867e-07 3.752867e-07  8.234286</span><span class="w">

    </span><span class="c1"># Show results</span><span class="w">
    </span><span class="n">topTable</span><span class="p">(</span><span class="n">fit_2_ebayes</span><span class="p">)</span><span class="w">

    </span><span class="c1">## Removing intercept from test coefficients</span><span class="w">

    </span><span class="c1">##       treatment1  genderMale  AveExpr        F      P.Value    adj.P.Val</span><span class="w">
    </span><span class="c1">## Gene4  -6.174442 -0.03303168 7.706142 27.05854 1.772654e-12 8.863272e-12</span><span class="w">
    </span><span class="c1">## Gene1  -4.913836  1.12261968 7.751662 18.82582 6.668838e-09 1.667210e-08</span><span class="w">
    </span><span class="c1">## Gene5  -5.047809 -0.92870157 7.753734 18.04422 1.457123e-08 2.428538e-08</span><span class="w">
    </span><span class="c1">## Gene2  -4.660927  0.40362347 7.558999 15.81690 1.351472e-07 1.689340e-07</span><span class="w">
    </span><span class="c1">## Gene3  -4.570297 -0.14621287 7.163048 14.76065 3.886259e-07 3.886259e-07</span><span class="w">

    </span><span class="c1"># Show results</span><span class="w">
    </span><span class="n">topTable</span><span class="p">(</span><span class="n">fit_3_ebayes</span><span class="p">)</span><span class="w"> 

    </span><span class="c1">## Removing intercept from test coefficients</span><span class="w">

    </span><span class="c1">##       treatment1  genderMale  AveExpr        F      P.Value    adj.P.Val</span><span class="w">
    </span><span class="c1">## Gene4  -6.173634 -0.02495011 7.706142 26.77375 2.356711e-12 1.178356e-11</span><span class="w">
    </span><span class="c1">## Gene1  -4.914731  1.11367369 7.751662 18.62289 8.169239e-09 2.042310e-08</span><span class="w">
    </span><span class="c1">## Gene5  -5.047331 -0.92392051 7.753734 17.85445 1.761614e-08 2.936023e-08</span><span class="w">
    </span><span class="c1">## Gene2  -4.660333  0.40956206 7.558999 15.65513 1.588780e-07 1.985975e-07</span><span class="w">
    </span><span class="c1">## Gene3  -4.570291 -0.14614599 7.163048 14.60561 4.538018e-07 4.538018e-07</span><span class="w">
</span></code></pre></div></div> <p>Parameters Interpretation: - logFC: Log fold change of the gene expression between conditions. - AveExpr: Average expression of the gene across all samples. - t: Moderated t-statistic. - P.Value: Raw p-value. - adj.P.Val: Adjusted p-value (FDR). - B: Log-odds that the gene is differentially expressed.</p> <p>If including the block effect changes the results substantially (e.g., differentially expressed genes, p-values), then the block effect is important in your model. Otherwise, if there is minimal change, the block effect may not significantly impact the model.</p> <p>In this case, the block effect does not significantly affect the results, as the top differentially expressed genes are similar across the models. In contrast, the covariate, gender has a significant impact on the results, as the top differentially expressed genes differ between Model 1 and Model 2.</p> <p><strong>Visualize the coefficients and CI</strong></p> <p>In this step, we will visualize the coefficients and confidence intervals for the fixed effects of treatment on gene expression. We will compare the results from Model 1, Model 2, and Model 3.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Define a function to extract the coefficients and confidence intervals </span><span class="w">
    </span><span class="n">extract_coef_ci</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="n">coef_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="w">
        </span><span class="n">Gene</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rownames</span><span class="p">(</span><span class="n">fit</span><span class="o">$</span><span class="n">coefficients</span><span class="p">),</span><span class="w">
        </span><span class="n">Estimate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[,</span><span class="w"> </span><span class="s2">"treatment1"</span><span class="p">],</span><span class="w">
        </span><span class="n">CI_Lower</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[,</span><span class="w"> </span><span class="s2">"treatment1"</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1.96</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">stdev.unscaled</span><span class="p">[,</span><span class="w"> </span><span class="s2">"treatment1"</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">sigma</span><span class="p">,</span><span class="w">
        </span><span class="n">CI_Upper</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[,</span><span class="w"> </span><span class="s2">"treatment1"</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1.96</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">stdev.unscaled</span><span class="p">[,</span><span class="w"> </span><span class="s2">"treatment1"</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">sigma</span><span class="w">
      </span><span class="p">)</span><span class="w">
      </span><span class="nf">return</span><span class="p">(</span><span class="n">coef_df</span><span class="p">)</span><span class="w">
    </span><span class="p">}</span><span class="w">

    </span><span class="c1"># Extract coefficients and confidence intervals for Model 1 - 3 </span><span class="w">
    </span><span class="n">coef_df_1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">extract_coef_ci</span><span class="p">(</span><span class="n">fit_1_ebayes</span><span class="p">)</span><span class="w">
    </span><span class="n">coef_df_2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">extract_coef_ci</span><span class="p">(</span><span class="n">fit_2_ebayes</span><span class="p">)</span><span class="w">
    </span><span class="n">coef_df_3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">extract_coef_ci</span><span class="p">(</span><span class="n">fit_3_ebayes</span><span class="p">)</span><span class="w">

    </span><span class="c1"># Prepare the data for plotting </span><span class="w">
    </span><span class="n">coef_df_1</span><span class="o">$</span><span class="n">model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s2">"Model_1"</span><span class="w">
    </span><span class="n">coef_df_2</span><span class="o">$</span><span class="n">model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s2">"Model_2"</span><span class="w"> 
    </span><span class="n">coef_df_3</span><span class="o">$</span><span class="n">model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s2">"Model_3"</span><span class="w"> 

    </span><span class="n">coef_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rbind</span><span class="p">(</span><span class="n">coef_df_1</span><span class="p">,</span><span class="w"> </span><span class="n">coef_df_2</span><span class="p">,</span><span class="w"> </span><span class="n">coef_df_3</span><span class="p">)</span><span class="w"> 
    </span><span class="n">print</span><span class="p">(</span><span class="n">coef_df</span><span class="p">)</span><span class="w">  

    </span><span class="c1">##         Gene  Estimate  CI_Lower  CI_Upper   model</span><span class="w">
    </span><span class="c1">## Gene1  Gene1 -5.026098 -6.710451 -3.341746 Model_1</span><span class="w">
    </span><span class="c1">## Gene2  Gene2 -4.701290 -6.404071 -2.998508 Model_1</span><span class="w">
    </span><span class="c1">## Gene3  Gene3 -4.555676 -6.179768 -2.931585 Model_1</span><span class="w">
    </span><span class="c1">## Gene4  Gene4 -6.171139 -7.610268 -4.732010 Model_1</span><span class="w">
    </span><span class="c1">## Gene5  Gene5 -4.954939 -6.629405 -3.280472 Model_1</span><span class="w">
    </span><span class="c1">## Gene11 Gene1 -4.913836 -6.572943 -3.254729 Model_2</span><span class="w">
    </span><span class="c1">## Gene21 Gene2 -4.660927 -6.411613 -2.910241 Model_2</span><span class="w">
    </span><span class="c1">## Gene31 Gene3 -4.570297 -6.248554 -2.892041 Model_2</span><span class="w">
    </span><span class="c1">## Gene41 Gene4 -6.174442 -7.662748 -4.686136 Model_2</span><span class="w">
    </span><span class="c1">## Gene51 Gene5 -5.047809 -6.722954 -3.372663 Model_2</span><span class="w">
    </span><span class="c1">## Gene12 Gene1 -4.914731 -6.578634 -3.250828 Model_3</span><span class="w">
    </span><span class="c1">## Gene22 Gene2 -4.660333 -6.417573 -2.903094 Model_3</span><span class="w">
    </span><span class="c1">## Gene32 Gene3 -4.570291 -6.258486 -2.882096 Model_3</span><span class="w">
    </span><span class="c1">## Gene42 Gene4 -6.173634 -7.668705 -4.678563 Model_3</span><span class="w">
    </span><span class="c1">## Gene52 Gene5 -5.047331 -6.737661 -3.357000 Model_3</span><span class="w">
</span></code></pre></div></div> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Plot the fixed effects with confidence intervals, comparing Model 1 - 3 </span><span class="w">
    </span><span class="n">pd</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">position_dodge</span><span class="p">(</span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.2</span><span class="p">)</span><span class="w"> </span><span class="c1"># Position dodge for better visualization </span><span class="w">

    </span><span class="n">ggplot</span><span class="p">(</span><span class="n">coef_df</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Gene</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Estimate</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
      </span><span class="n">geom_point</span><span class="p">(</span><span class="n">position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pd</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
      </span><span class="n">geom_errorbar</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">ymin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CI_Lower</span><span class="p">,</span><span class="w"> </span><span class="n">ymax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CI_Upper</span><span class="p">),</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.2</span><span class="p">,</span><span class="w"> </span><span class="n">position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pd</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="c1"># Error bars for confidence intervals </span><span class="w">
      </span><span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Fixed Effects of Treatment on Gene Expression"</span><span class="p">,</span><span class="w">
           </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Gene"</span><span class="p">,</span><span class="w">
           </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Estimate (Treatment Effect)"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
      </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
      </span><span class="n">theme</span><span class="p">(</span><span class="n">legend.position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"top"</span><span class="p">)</span><span class="w"> 
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/linear-mixed-model_files/figure-markdown_strict/unnamed-chunk-3-1.png" sizes="95vw"/> <img src="/assets/img/linear-mixed-model_files/figure-markdown_strict/unnamed-chunk-3-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>The plot shows the fixed effects of treatment on gene expression, with confidence intervals for Model 1 - 3. The coefficients represent the estimated treatment effect on gene expression, and the confidence intervals indicate the uncertainty around the estimates.</p> <p>The gene expression of Genes 1 - 5 are significantly downregulated in the treatment group compared to the control group, as the confidence interval does not include zero. The confidence intervals provide a range of plausible values for the treatment effect, taking into account the uncertainty in the estimates.</p> <h2 id="step-4---evaluate-model-robustness">Step 4 - Evaluate model robustness</h2> <p>This step evaluates the assumptions of homoscedasticity and linearity by examining the residuals. If the residuals are randomly distributed around zero and show no clear patterns, the assumptions are met. If there are patterns or trends in the residuals, further investigation may be needed to address model assumptions.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Plot the residuals</span><span class="w">

    </span><span class="c1"># Create a functiont to plot fitted values vs residuals </span><span class="w">
    </span><span class="n">plot_residuals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="n">residuals_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="w">
        </span><span class="n">Residuals</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">as.vector</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data</span><span class="p">)),</span><span class="w"> 
        </span><span class="n">Fitted</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">as.vector</span><span class="p">(</span><span class="n">fitted</span><span class="p">(</span><span class="n">fit</span><span class="p">))</span><span class="w">
      </span><span class="p">)</span><span class="w"> 
      
      </span><span class="n">ggplot</span><span class="p">(</span><span class="n">residuals_df</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Fitted</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Residuals</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
        </span><span class="n">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
        </span><span class="n">geom_hline</span><span class="p">(</span><span class="n">yintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"dashed"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
        </span><span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Residuals vs Fitted Values"</span><span class="p">,</span><span class="w">
             </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Fitted Values"</span><span class="p">,</span><span class="w">
             </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Residuals"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
        </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w">
    </span><span class="p">}</span><span class="w">

    </span><span class="c1"># Combine the residual plots for Model 1 - 3</span><span class="w">
    </span><span class="n">grid.arrange</span><span class="p">(</span><span class="n">plot_residuals</span><span class="p">(</span><span class="n">fit_1</span><span class="p">,</span><span class="w"> </span><span class="n">expression_data</span><span class="p">),</span><span class="w"> 
                 </span><span class="n">plot_residuals</span><span class="p">(</span><span class="n">fit_2</span><span class="p">,</span><span class="w"> </span><span class="n">expression_data</span><span class="p">),</span><span class="w"> 
                 </span><span class="n">plot_residuals</span><span class="p">(</span><span class="n">fit_3</span><span class="p">,</span><span class="w"> </span><span class="n">gene_expression</span><span class="p">),</span><span class="w"> 
                 </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w"> 
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/linear-mixed-model_files/figure-markdown_strict/unnamed-chunk-4-1.png" sizes="95vw"/> <img src="/assets/img/linear-mixed-model_files/figure-markdown_strict/unnamed-chunk-4-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>In this case, the residual plots show no clear patterns or trends, indicating that the assumptions of homoscedasticity and linearity are met for Model 1 - 3.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="c1"># Check the normality of residuals using Q-Q plots </span><span class="w">
    </span><span class="n">par</span><span class="p">(</span><span class="n">mfrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">))</span><span class="w"> 
    </span><span class="n">qqnorm</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit_1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expression_data</span><span class="p">))</span><span class="w"> 
    </span><span class="n">qqline</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit_1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expression_data</span><span class="p">))</span><span class="w"> 

    </span><span class="n">qqnorm</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit_2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expression_data</span><span class="p">))</span><span class="w"> 
    </span><span class="n">qqline</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit_2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expression_data</span><span class="p">))</span><span class="w">

    </span><span class="n">qqnorm</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit_3</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gene_expression</span><span class="p">))</span><span class="w"> 
    </span><span class="n">qqline</span><span class="p">(</span><span class="n">residuals</span><span class="p">(</span><span class="n">fit_3</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gene_expression</span><span class="p">))</span><span class="w"> 
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/linear-mixed-model_files/figure-markdown_strict/unnamed-chunk-5-1.png" sizes="95vw"/> <img src="/assets/img/linear-mixed-model_files/figure-markdown_strict/unnamed-chunk-5-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>The residuals are randomly distributed around zero, with no systematic deviations from the assumptions.</p> <h1 id="conclusion">Conclusion</h1> <p>In this tutorial, we demonstrated how to fit linear mixed-effect models with the <code class="language-plaintext highlighter-rouge">limma</code> package in R. We simulated example data with repeated measures and applied linear models with different covariates and block effects. We evaluated the block effect, extracted differentially expressed genes, visualized the coefficients, and assessed model robustness.</p> <p>Linear mixed-effect models are useful for analyzing data with repeated measures or nested structures, where samples are not independent. By incorporating random effects and block effects, we can account for the correlation between samples and improve the accuracy of the statistical analysis.</p> <p>This tutorial is for demonstration purpose, although the block efffect is not significant. You can apply similar steps to analyze your own data with linear mixed-effect models using the <code class="language-plaintext highlighter-rouge">limma</code> package in R.</p> <h1 id="sessoin-info">Sessoin Info</h1> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="n">sessionInfo</span><span class="p">()</span><span class="w">

    </span><span class="c1">## R version 4.3.3 (2024-02-29)</span><span class="w">
    </span><span class="c1">## Platform: aarch64-apple-darwin20 (64-bit)</span><span class="w">
    </span><span class="c1">## Running under: macOS 15.0</span><span class="w">
    </span><span class="c1">## </span><span class="w">
    </span><span class="c1">## Matrix products: default</span><span class="w">
    </span><span class="c1">## BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib </span><span class="w">
    </span><span class="c1">## LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0</span><span class="w">
    </span><span class="c1">## </span><span class="w">
    </span><span class="c1">## locale:</span><span class="w">
    </span><span class="c1">## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8</span><span class="w">
    </span><span class="c1">## </span><span class="w">
    </span><span class="c1">## time zone: America/Edmonton</span><span class="w">
    </span><span class="c1">## tzcode source: internal</span><span class="w">
    </span><span class="c1">## </span><span class="w">
    </span><span class="c1">## attached base packages:</span><span class="w">
    </span><span class="c1">## [1] stats     graphics  grDevices utils     datasets  methods   base     </span><span class="w">
    </span><span class="c1">## </span><span class="w">
    </span><span class="c1">## other attached packages:</span><span class="w">
    </span><span class="c1">## [1] rmarkdown_2.26 gridExtra_2.3  limma_3.58.1   shiny_1.9.1    ggplot2_3.5.0  bookdown_0.41 </span><span class="w">
    </span><span class="c1">## </span><span class="w">
    </span><span class="c1">## loaded via a namespace (and not attached):</span><span class="w">
    </span><span class="c1">##  [1] sass_0.4.9          utf8_1.2.4          generics_0.1.3      digest_0.6.35       magrittr_2.0.3      evaluate_0.23       grid_4.3.3          fastmap_1.2.0      </span><span class="w">
    </span><span class="c1">##  [9] jsonlite_1.8.8      promises_1.2.1      BiocManager_1.30.25 fansi_1.0.6         scales_1.3.0        jquerylib_0.1.4     cli_3.6.2           rlang_1.1.3        </span><span class="w">
    </span><span class="c1">## [17] munsell_0.5.0       withr_3.0.0         cachem_1.1.0        yaml_2.3.8          tools_4.3.3         memoise_2.0.1       dplyr_1.1.4         colorspace_2.1-1   </span><span class="w">
    </span><span class="c1">## [25] httpuv_1.6.15       vctrs_0.6.5         R6_2.5.1            mime_0.12           lifecycle_1.0.4     pkgconfig_2.0.3     pillar_1.9.0        bslib_0.6.2        </span><span class="w">
    </span><span class="c1">## [33] later_1.3.2         gtable_0.3.4        glue_1.7.0          Rcpp_1.0.12         statmod_1.5.0       xfun_0.48           tibble_3.2.1        tidyselect_1.2.1   </span><span class="w">
    </span><span class="c1">## [41] highr_0.10          rstudioapi_0.16.0   knitr_1.45          farver_2.1.1        xtable_1.8-4        htmltools_0.5.8     labeling_0.4.3      compiler_4.3.3</span><span class="w">
</span></code></pre></div></div>]]></content><author><name></name></author><category term="statistics"/><category term="data-analysis,"/><category term="limma,"/><category term="linear-mixed-models,"/><category term="gene-expression"/><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Choosing the Right Dimensionality Reduction in Metabolomics: Navigating Common Pitfalls</title><link href="https://davidzhao1015.github.io/blog/2024/choose-dimension-reduction/" rel="alternate" type="text/html" title="Choosing the Right Dimensionality Reduction in Metabolomics: Navigating Common Pitfalls"/><published>2024-10-18T00:00:00+00:00</published><updated>2024-10-18T00:00:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2024/choose-dimension-reduction</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2024/choose-dimension-reduction/"><![CDATA[<h2 id="challenges-of-dimensionality-reduction-in-metabolomics-studies">Challenges of Dimensionality Reduction in Metabolomics Studies</h2> <p>Struggling to choose the right dimensionality reduction method for your metabolomics data? You’re not alone. One of the biggest challenges in data analysis is selecting an appropriate technique to handle high-dimensional datasets without losing valuable information. In this post, we’ll dive into practical solutions to make that decision easier and more effective.</p> <h2 id="types-of-metabolomics-studies">Types of Metabolomics Studies</h2> <p>Metabolomics research typically serves three primary purposes: <strong>exploration</strong>, <strong>association</strong>, and <strong>prediction</strong>.</p> <ul> <li> <p><strong>Exploration</strong> aims to discover patterns in high-dimensional datasets using unsupervised methods like Principal Component Analysis (PCA) and clustering techniques.</p> </li> <li> <p><strong>Association</strong> category focuses on identifying relationships between metabolites and biological factors, employing statistical methods such as correlation analysis, ANOVA, and linear regression.</p> </li> <li> <p><strong>Prediction</strong> involves developing models to classify or predict outcomes based on metabolite profiles, utilizing supervised methods like logistic regression and Random Forest.</p> </li> </ul> <p>These classifications guide study design and the selection of appropriate statistical techniques.</p> <hr/> <h2 id="overview-of-popular-methods-in-chemometrics-analysis">Overview of Popular Methods in Chemometrics Analysis</h2> <p>This table provides a comprehensive overview of each method’s essential characteristics, facilitating a clearer understanding of their applications and limitations in the context of chemometrics and other fields.</p> <table> <thead> <tr> <th style="text-align: left"><strong>Method</strong></th> <th style="text-align: left"><strong>Description</strong></th> <th style="text-align: left"><strong>Purpose</strong></th> <th style="text-align: left"><strong>Assumptions</strong></th> <th style="text-align: left"><strong>Advantages</strong></th> <th style="text-align: left"><strong>Disadvantages</strong></th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><strong>Principal Component Analysis (PCA)</strong></td> <td style="text-align: left">A linear technique that reduces dimensionality by transforming original variables into a smaller set of uncorrelated components.</td> <td style="text-align: left">Dimensionality Reduction</td> <td style="text-align: left">Linearity, Multivariate normality</td> <td style="text-align: left">Effective in simplifying data, capturing variance.</td> <td style="text-align: left">Assumes linear relationships; sensitive to outliers.</td> </tr> <tr> <td style="text-align: left"><strong>Partial Least Squares (PLS)</strong></td> <td style="text-align: left">A regression technique that models relationships between predictor and response variables, reducing dimensionality.</td> <td style="text-align: left">Supervised Regression &amp; Dimensionality Reduction</td> <td style="text-align: left">Linearity, Multicollinearity</td> <td style="text-align: left">Handles collinearity well; good for small sample sizes.</td> <td style="text-align: left">Can overfit with small datasets; requires careful model validation.</td> </tr> <tr> <td style="text-align: left"><strong>Sparse Partial Least Squares (sPLS)</strong></td> <td style="text-align: left">A variant of PLS that incorporates sparsity for feature selection along with dimensionality reduction.</td> <td style="text-align: left">Supervised Regression &amp; Feature Selection</td> <td style="text-align: left">Linearity, Multicollinearity</td> <td style="text-align: left">Simultaneously reduces dimensionality and selects features.</td> <td style="text-align: left">May overlook relevant features if sparsity is too high.</td> </tr> <tr> <td style="text-align: left"><strong>Independent Component Analysis (ICA)</strong></td> <td style="text-align: left">A method that separates a multivariate signal into additive independent components.</td> <td style="text-align: left">Signal Processing &amp; Dimensionality Reduction</td> <td style="text-align: left">Statistical independence of components</td> <td style="text-align: left">Captures non-Gaussian features, useful for separating signals.</td> <td style="text-align: left">Sensitive to noise; requires independent sources.</td> </tr> <tr> <td style="text-align: left"><strong>Multivariate Curve Resolution (MCR)</strong></td> <td style="text-align: left">A method for resolving overlapping signals in complex data matrices into pure components.</td> <td style="text-align: left">Signal Resolution</td> <td style="text-align: left">Linearity, Known number of components</td> <td style="text-align: left">Effective for spectral data; interpretable results.</td> <td style="text-align: left">Requires prior knowledge about the number of components.</td> </tr> <tr> <td style="text-align: left"><strong>Orthogonal Partial Least Squares (OPLS)</strong></td> <td style="text-align: left">An extension of PLS that separates predictive variance from orthogonal (noise) variance.</td> <td style="text-align: left">Supervised Regression &amp; Dimensionality Reduction</td> <td style="text-align: left">Linearity, Multicollinearity</td> <td style="text-align: left">Improved interpretability by filtering out noise.</td> <td style="text-align: left">Still sensitive to overfitting; complex model selection.</td> </tr> <tr> <td style="text-align: left"><strong>Non-negative Matrix Factorization (NMF)</strong></td> <td style="text-align: left">A matrix factorization technique that decomposes data into non-negative components.</td> <td style="text-align: left">Dimensionality Reduction &amp; Feature Extraction</td> <td style="text-align: left">Non-negativity of data</td> <td style="text-align: left">Produces interpretable, additive components.</td> <td style="text-align: left">Sensitive to initialization; may not converge to global optimum.</td> </tr> <tr> <td style="text-align: left"><strong>Factor Analysis (FA)</strong></td> <td style="text-align: left">A technique for modeling the underlying factors that explain observed correlations among variables.</td> <td style="text-align: left">Exploratory Data Analysis</td> <td style="text-align: left">Linearity, Multivariate normality</td> <td style="text-align: left">Identifies latent structures; interpretable results.</td> <td style="text-align: left">Requires a large sample size; assumes linearity.</td> </tr> <tr> <td style="text-align: left"><strong>Multidimensional Scaling (MDS)</strong></td> <td style="text-align: left">A technique that visualizes the similarity or dissimilarity of data points in lower-dimensional space.</td> <td style="text-align: left">Visualization</td> <td style="text-align: left">Preservation of distances</td> <td style="text-align: left">Effective for visualizing high-dimensional data.</td> <td style="text-align: left">Sensitive to noise; may produce misleading results with many dimensions.</td> </tr> <tr> <td style="text-align: left"><strong>Kernel Principal Component Analysis (Kernel PCA)</strong></td> <td style="text-align: left">An extension of PCA that uses kernel methods to capture non-linear relationships.</td> <td style="text-align: left">Dimensionality Reduction</td> <td style="text-align: left">Non-linear structure in data</td> <td style="text-align: left">Captures complex structures not visible in linear PCA.</td> <td style="text-align: left">Computationally intensive; choice of kernel can affect results.</td> </tr> <tr> <td style="text-align: left"><strong>t-Distributed Stochastic Neighbor Embedding (t-SNE)</strong></td> <td style="text-align: left">A non-linear dimensionality reduction technique primarily used for visualization.</td> <td style="text-align: left">Visualization</td> <td style="text-align: left">Locality preservation in high-dimensional space</td> <td style="text-align: left">Excellent for visualizing clusters in high dimensions.</td> <td style="text-align: left">Computationally expensive; not suitable for large datasets.</td> </tr> <tr> <td style="text-align: left"><strong>Autoencoders (Neural Network-based)</strong></td> <td style="text-align: left">Neural networks used for unsupervised learning that compress data into lower dimensions.</td> <td style="text-align: left">Dimensionality Reduction &amp; Feature Extraction</td> <td style="text-align: left">Non-linearity, sufficient data for training</td> <td style="text-align: left">Captures complex patterns; can be tailored for specific tasks.</td> <td style="text-align: left">Requires careful tuning; sensitive to overfitting.</td> </tr> <tr> <td style="text-align: left"><strong>Self-Organizing Maps (SOM)</strong></td> <td style="text-align: left">An unsupervised neural network that projects high-dimensional data onto a lower-dimensional grid.</td> <td style="text-align: left">Clustering &amp; Visualization</td> <td style="text-align: left">Topological preservation of data relationships</td> <td style="text-align: left">Intuitive visualizations; good for exploring data structure.</td> <td style="text-align: left">Can be sensitive to parameters; requires preprocessing</td> </tr> </tbody> </table> <hr/> <h2 id="practical-guide-to-choosing-a-suitable-method">Practical Guide to Choosing a Suitable Method</h2> <p>When selecting a dimensionality reduction method for metabolomics studies, consider the following criteria:</p> <ol> <li> <p><strong>Data Type and Structure:</strong> Choose methods based on whether the data has linear or non-linear relationships and the type of variables involved.</p> <ul> <li>Linear Data: Use PCA, PLS, or FA for linear relationships.</li> <li>Non-linear Data: Apply Kernel PCA, t-SNE, or autoencoders for non-linear patterns.</li> <li>Variable Type: Use PCA/PLS for continuous variables. For categorical variables, first use Random Forest for feature selection.</li> </ul> </li> <li> <p><strong>Interpretability:</strong> Some methods offer easier-to-interpret results, while others are better suited for complex visualizations.</p> <ul> <li>High Interpretability: PCA, FA, and NMF (for non-negative data) offer clearer results.</li> <li>Low Interpretability: t-SNE and autoencoders excel at visualization but are harder to explain.</li> </ul> </li> <li> <p><strong>Goal of the Analysis:</strong> Select methods based on whether you’re exploring data, selecting features, or reducing noise.</p> <ul> <li>Exploratory Analysis: Use PCA, MDS, or t-SNE to visualize clusters and trends.</li> <li>Feature Selection: Apply sPLS, Random Forest, or NMF to identify key features (e.g., biomarkers).</li> <li>Noise Filtering: Opt for PLS, OPLS, or MCR for noisy data.</li> </ul> </li> <li> <p><strong>Scalability and Dataset Size:</strong> Different methods work better with large datasets or small datasets with many variables.</p> <ul> <li>Large Datasets: Use PCA, PLS, or NMF for computational efficiency. Non-linear methods (t-SNE, Kernel PCA) may struggle.</li> <li>Small Datasets with Many Variables: Use PLS, sPLS, or OPLS to prevent overfitting.</li> </ul> </li> <li> <p><strong>Handling of Missing Data:</strong> Some methods are flexible with missing data, while others require complete datasets.</p> <ul> <li>Missing Data: Use PCA/PLS with imputation. Avoid ICA, which requires complete data. NMF works well for sparse, non-negative data.</li> </ul> </li> <li> <p><strong>Assumptions of the Method:</strong> Each method relies on specific assumptions about the data, which can impact performance.</p> <ul> <li>Linear Assumptions: PCA/FA assume normality and linearity.</li> <li>Non-negative Data: NMF works best with non-negative data.</li> <li>Non-linear Assumptions: Kernel PCA/t-SNE assume non-linear structures.</li> </ul> </li> <li> <p><strong>Overfitting and Generalization:</strong> Overfitting can be a risk, especially with supervised methods and small sample sizes.</p> <ul> <li>High Overfitting Risk: Supervised methods (PLS, OPLS) require cross-validation for small datasets.</li> <li>Low Overfitting Risk: Unsupervised methods (PCA, MDS) are safer but may struggle with complex classification.</li> </ul> </li> <li> <p><strong>Dimensionality and Sparsity:</strong> High-dimensional and sparse datasets require specific methods to reduce dimensionality and select features.</p> <ul> <li>High-Dimensional/Sparse Data: Use sPLS or NMF for dimensionality reduction and feature selection.</li> <li>Non-linear Data: Autoencoders are great for compressing high-dimensional, non-linear datasets.</li> </ul> </li> </ol> <p>By considering these factors, you can choose the most suitable dimensionality reduction method for your metabolomics study, ensuring optimal results and insights from your data.</p> <p>By integrating charactersitics of each method (shown in the table above) with the practical guide, the following table summarizes the key aspects of each method to help you make an informed decision:</p> <table> <thead> <tr> <th><strong>Method</strong></th> <th><strong>Interpretability</strong></th> <th><strong>Goal of analysis</strong></th> <th><strong>Overfitting</strong></th> <th><strong>Missing Data Handling</strong></th> <th><strong>Data Linearity</strong></th> <th><strong>Type of Variables</strong></th> <th><strong>Scalability &amp; Dataset Size</strong></th> <th><strong>Dimensionality &amp; Sparsity</strong></th> </tr> </thead> <tbody> <tr> <td><strong>PCA</strong></td> <td>Moderate</td> <td>Dimensionality reduction</td> <td>Low</td> <td>Imputation</td> <td>Linear</td> <td>Continuous</td> <td>Efficient for large data</td> <td>Reduces dimensions, handles sparsity</td> </tr> <tr> <td><strong>PLS</strong></td> <td>Moderate</td> <td>Regression &amp; Dimensionality</td> <td>High, needs cross-validation</td> <td>Imputation</td> <td>Linear</td> <td>Continuous</td> <td>Good for large data</td> <td>Reduces dimensions, handles multicollinearity</td> </tr> <tr> <td><strong>sPLS</strong></td> <td>High</td> <td>Regression &amp; Feature Selection</td> <td>Low</td> <td>Imputation</td> <td>Linear with sparsity</td> <td>Continuous</td> <td>Efficient in high-dimensions</td> <td>Selects key features, handles sparsity</td> </tr> <tr> <td><strong>ICA</strong></td> <td>Moderate</td> <td>Signal separation</td> <td>Low</td> <td>Imputation needed</td> <td>Non-Gaussian, Independent</td> <td>Continuous</td> <td>Moderate datasets</td> <td>Separates signals, handles sparsity</td> </tr> <tr> <td><strong>MCR</strong></td> <td>High</td> <td>Signal resolution</td> <td>High</td> <td>ALS optimization</td> <td>Linear</td> <td>Continuous (spectral)</td> <td>Smaller datasets</td> <td>Resolves complex mixtures</td> </tr> <tr> <td><strong>OPLS</strong></td> <td>High</td> <td>Regression &amp; Dimensionality</td> <td>High, needs cross-validation</td> <td>Imputation</td> <td>Linear</td> <td>Continuous</td> <td>Effective for large data</td> <td>Focuses on response-related variation</td> </tr> <tr> <td><strong>NMF</strong></td> <td>High</td> <td>Dimensionality &amp; Feature Extraction</td> <td>Low with regularization</td> <td>Non-negative imputation</td> <td>Non-negative</td> <td>Non-negative continuous</td> <td>Moderate datasets</td> <td>Retains interpretability, non-negative data</td> </tr> <tr> <td><strong>FA</strong></td> <td>Moderate</td> <td>Exploratory analysis</td> <td>High</td> <td>Imputation</td> <td>Linear</td> <td>Continuous</td> <td>Moderate datasets</td> <td>Identifies latent factors</td> </tr> <tr> <td><strong>MDS</strong></td> <td>High</td> <td>Visualization</td> <td>Low</td> <td>Imputation needed</td> <td>Non-linear</td> <td>Continuous &amp; Categorical</td> <td>Moderate datasets</td> <td>Visualizes high-dimensional data</td> </tr> <tr> <td><strong>Kernel PCA</strong></td> <td>Low</td> <td>Dimensionality reduction</td> <td>High</td> <td>Imputation needed</td> <td>Non-linear</td> <td>Continuous</td> <td>Moderate datasets</td> <td>Captures non-linear structure</td> </tr> <tr> <td><strong>t-SNE</strong></td> <td>Low</td> <td>Visualization</td> <td>High</td> <td>Imputation needed</td> <td>Non-linear</td> <td>Continuous</td> <td>Small datasets</td> <td>Visualizes high-dimensional data</td> </tr> <tr> <td><strong>Autoencoders</strong></td> <td>Low</td> <td>Dimensionality &amp; Feature Extraction</td> <td>High</td> <td>Direct reconstruction</td> <td>Linear &amp; Non-linear</td> <td>Continuous</td> <td>Large datasets</td> <td>Compresses and reduces dimensionality</td> </tr> <tr> <td><strong>SOM</strong></td> <td>High</td> <td>Clustering &amp; Visualization</td> <td>Low</td> <td>Imputation needed</td> <td>Non-linear</td> <td>Continuous &amp; Categorical</td> <td>Moderate datasets</td> <td>Preserves relationships, handles sparsity</td> </tr> </tbody> </table> <hr/> <h2 id="take-home-message">Take-Home Message</h2> <p>By understanding the strengths and limitations of each method, you can navigate common pitfalls and make informed decisions to extract meaningful insights from your metabolomics data.</p> <p>Selecting the right method depends on your specific data type, goals (dimensionality reduction, visualization, or feature selection), and the need for interpretability versus capturing complex patterns. Keep these factors in mind when choosing your approach.</p>]]></content><author><name></name></author><category term="statistics"/><category term="metabolomics,"/><category term="data-analysis,"/><category term="dimensionality-reduction"/><summary type="html"><![CDATA[Challenges of Dimensionality Reduction in Metabolomics Studies]]></summary></entry><entry><title type="html">displaying beautiful tables with Bootstrap Tables</title><link href="https://davidzhao1015.github.io/blog/2023/tables/" rel="alternate" type="text/html" title="displaying beautiful tables with Bootstrap Tables"/><published>2023-03-20T18:37:00+00:00</published><updated>2023-03-20T18:37:00+00:00</updated><id>https://davidzhao1015.github.io/blog/2023/tables</id><content type="html" xml:base="https://davidzhao1015.github.io/blog/2023/tables/"><![CDATA[<p>Using markdown to display tables is easy.</p> <h2 id="simple-example">Simple Example</h2> <p>First, add the following to the post’s front matter</p> <div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">pretty_table</span><span class="pi">:</span> <span class="kc">true</span>
</code></pre></div></div> <p>Then, the following syntax</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>| Left aligned | Center aligned | Right aligned |
| :----------- | :------------: | ------------: |
| Left 1       |    center 1    |       right 1 |
| Left 2       |    center 2    |       right 2 |
| Left 3       |    center 3    |       right 3 |
</code></pre></div></div> <p>will generate</p> <table> <thead> <tr> <th style="text-align: left">Left aligned</th> <th style="text-align: center">Center aligned</th> <th style="text-align: right">Right aligned</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">Left 1</td> <td style="text-align: center">center 1</td> <td style="text-align: right">right 1</td> </tr> <tr> <td style="text-align: left">Left 2</td> <td style="text-align: center">center 2</td> <td style="text-align: right">right 2</td> </tr> <tr> <td style="text-align: left">Left 3</td> <td style="text-align: center">center 3</td> <td style="text-align: right">right 3</td> </tr> </tbody> </table> <p></p> <h2 id="html-example">HTML Example</h2> <p>It is also possible to use HTML to display tables. For example, the following HTML code will display a table with <a href="https://bootstrap-table.com/">Bootstrap Table</a>, loaded from a JSON file:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;table</span> <span class="na">id=</span><span class="s">"table"</span> <span class="na">data-toggle=</span><span class="s">"table"</span> <span class="na">data-url=</span><span class="s">"{{ '/assets/json/table_data.json' | relative_url }}"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;thead&gt;</span>
    <span class="nt">&lt;tr&gt;</span>
      <span class="nt">&lt;th</span> <span class="na">data-field=</span><span class="s">"id"</span><span class="nt">&gt;</span>ID<span class="nt">&lt;/th&gt;</span>
      <span class="nt">&lt;th</span> <span class="na">data-field=</span><span class="s">"name"</span><span class="nt">&gt;</span>Item Name<span class="nt">&lt;/th&gt;</span>
      <span class="nt">&lt;th</span> <span class="na">data-field=</span><span class="s">"price"</span><span class="nt">&gt;</span>Item Price<span class="nt">&lt;/th&gt;</span>
    <span class="nt">&lt;/tr&gt;</span>
  <span class="nt">&lt;/thead&gt;</span>
<span class="nt">&lt;/table&gt;</span>
</code></pre></div></div> <table data-toggle="table" data-url="/assets/json/table_data.json"> <thead> <tr> <th data-field="id">ID</th> <th data-field="name">Item Name</th> <th data-field="price">Item Price</th> </tr> </thead> </table> <p></p> <h2 id="more-complex-example">More Complex Example</h2> <p>By using <a href="https://bootstrap-table.com/">Bootstrap Table</a> it is possible to create pretty complex tables, with pagination, search, and more. For example, the following HTML code will display a table, loaded from a JSON file, with pagination, search, checkboxes, and header/content alignment. For more information, check the <a href="https://examples.bootstrap-table.com/index.html">documentation</a>.</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;table</span>
  <span class="na">data-click-to-select=</span><span class="s">"true"</span>
  <span class="na">data-height=</span><span class="s">"460"</span>
  <span class="na">data-pagination=</span><span class="s">"true"</span>
  <span class="na">data-search=</span><span class="s">"true"</span>
  <span class="na">data-toggle=</span><span class="s">"table"</span>
  <span class="na">data-url=</span><span class="s">"{{ '/assets/json/table_data.json' | relative_url }}"</span>
<span class="nt">&gt;</span>
  <span class="nt">&lt;thead&gt;</span>
    <span class="nt">&lt;tr&gt;</span>
      <span class="nt">&lt;th</span> <span class="na">data-checkbox=</span><span class="s">"true"</span><span class="nt">&gt;&lt;/th&gt;</span>
      <span class="nt">&lt;th</span> <span class="na">data-field=</span><span class="s">"id"</span> <span class="na">data-halign=</span><span class="s">"left"</span> <span class="na">data-align=</span><span class="s">"center"</span> <span class="na">data-sortable=</span><span class="s">"true"</span><span class="nt">&gt;</span>ID<span class="nt">&lt;/th&gt;</span>
      <span class="nt">&lt;th</span> <span class="na">data-field=</span><span class="s">"name"</span> <span class="na">data-halign=</span><span class="s">"center"</span> <span class="na">data-align=</span><span class="s">"right"</span> <span class="na">data-sortable=</span><span class="s">"true"</span><span class="nt">&gt;</span>Item Name<span class="nt">&lt;/th&gt;</span>
      <span class="nt">&lt;th</span> <span class="na">data-field=</span><span class="s">"price"</span> <span class="na">data-halign=</span><span class="s">"right"</span> <span class="na">data-align=</span><span class="s">"left"</span> <span class="na">data-sortable=</span><span class="s">"true"</span><span class="nt">&gt;</span>Item Price<span class="nt">&lt;/th&gt;</span>
    <span class="nt">&lt;/tr&gt;</span>
  <span class="nt">&lt;/thead&gt;</span>
<span class="nt">&lt;/table&gt;</span>
</code></pre></div></div> <table data-click-to-select="true" data-height="460" data-pagination="true" data-search="true" data-toggle="table" data-url="/assets/json/table_data.json"> <thead> <tr> <th data-checkbox="true"></th> <th data-field="id" data-halign="left" data-align="center" data-sortable="true">ID</th> <th data-field="name" data-halign="center" data-align="right" data-sortable="true">Item Name</th> <th data-field="price" data-halign="right" data-align="left" data-sortable="true">Item Price</th> </tr> </thead> </table>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="tables"/><summary type="html"><![CDATA[an example of how to use Bootstrap Tables]]></summary></entry></feed>